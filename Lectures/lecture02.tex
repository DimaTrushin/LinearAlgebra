\ProvidesFile{lecture02.tex}[Лекция 2]


\newpage

\section{Матрицы}

\subsection{Определение матриц}

Матрица -- это прямоугольная таблица чисел
\[
A=
\begin{pmatrix}
a_{11}&\ldots& a_{1n}\\
\vdots&\ddots&\vdots\\
a_{m1}& \ldots &a_{mn}
\end{pmatrix},\text{ где } a_{ij}\in \mathbb R
\]
Множество всех матриц с $m$ строками и $n$ столбцами обозначается $\MatrixDim{m}{n}$.
Множество квадратных матриц размера $n$ будем обозначать $\Matrix{n}$.
Матрицы с одним столбцом или одной строкой называются векторами (вектор-столбцами и вектор-строками соответственно).
Множество всех векторов с $n$ координатами обозначается через $\Vector{n}$.
Мы по умолчанию считаем, что наши вектора -- вектор-столбцы.%
\footnote{Важно, directX и openGL используют вектор-строки!
Потому часть инженерной литературы на английском связанной с трехмерной графикой оперирует со строками.
Это важно учитывать, так как нужно вносить поправки в соответствующие формулы.}

\subsection{Операции над матрицами}

\paragraph{Сложение}

Пусть $A,B\in \MatrixDim{m}{n}$.
Тогда сумма $A+B$ определяется покомпонентно, т.е. $C = A + B$, то $c_{ij} = a_{ij} + b_{ij}$ или
\[
\begin{pmatrix}
a_{11}&\ldots& a_{1n}\\
\vdots&\ddots&\vdots\\
a_{m1}& \ldots &a_{mn}
\end{pmatrix}
+
\begin{pmatrix}
b_{11}&\ldots& b_{1n}\\
\vdots&\ddots&\vdots\\
b_{m1}& \ldots &b_{mn}
\end{pmatrix}
=
\begin{pmatrix}
a_{11}+b_{11}&\ldots& a_{1n} + b_{1n}\\
\vdots&\ddots&\vdots\\
a_{m1}+b_{m1}& \ldots &a_{mn} + b_{mn}
\end{pmatrix}
\]
Складывать можно только матрицы одинакового размера.%
\footnote{Можно по аналогии определить и вычитание матриц, но в этом нет необходимости.
Например, потому что вычитание можно определить как $A + (-1)B$, где $(-1)B$ -- умножение на скаляр.
Либо можно определить аксиоматически, как это сделано ниже в следующем разделе.}

\paragraph{Умножение на скаляр}

Если $\lambda\in \mathbb R$ и $A\in \MatrixDim{m}{n}$, то $\lambda A$ определяется так: $\lambda A = C$, где $c_{ij} = \lambda a_{ij}$ или
\[
\lambda
\begin{pmatrix}
a_{11}&\ldots& a_{1n}\\
\vdots&\ddots&\vdots\\
a_{m1}& \ldots &a_{mn}
\end{pmatrix}
=
\begin{pmatrix}
\lambda a_{11}&\ldots& \lambda a_{1n}\\
\vdots&\ddots&\vdots\\
\lambda a_{m1}& \ldots &\lambda a_{mn}
\end{pmatrix}
\]

\paragraph{Умножение матриц}

Пусть $A\in\MatrixDim{m}{n}$ и $B\in\MatrixDim{n}{k}$, то произведение $AB\in\MatrixDim{m}{k}$ определяется так: $AB = C$, где $c_{ij} = \sum_{t=1}^n a_{it}b_{tj}$ или
\[
\begin{pmatrix}
a_{11}&\ldots& a_{1n}\\
\vdots&\ddots&\vdots\\
a_{m1}& \ldots &a_{mn}
\end{pmatrix}
\begin{pmatrix}
b_{11}&\ldots& b_{1k}\\
\vdots&\ddots&\vdots\\
b_{n1}& \ldots &b_{nk}
\end{pmatrix}
=\begin{pmatrix}
\sum_{t=1}^n a_{1t}b_{t1}&\ldots& \sum_{t=1}^n a_{1t}b_{tk}\\
\vdots&\ddots&\vdots\\
\sum_{t=1}^n a_{mt}b_{t1}& \ldots &\sum_{t=1}^n a_{mt}b_{tk}
\end{pmatrix}
\]
Умножение матриц полезно как-то визуализировать у себя в голове.
Предположим мы хотим посчитать коэффициент $c_{ij}$.
Тогда надо из матрицы $A$ взять $i$-ю строку (она имеет длину $n$), а из матрицы $B$ взять $j$-ый столбец (он тоже имеет длину $n$).
Тогда их надо скалярно перемножить и результат подставить в $c_{ij}$, как показано ниже на картинке.
\[
\left(
\begin{array}{ccc}
{
\begin{array}{cc}
{a_{11}}&{\ldots}\\
{\vdots}&{\ddots}\\
\end{array}
}&{}&{
\begin{array}{cc}
{\ldots}&{a_{1n}}\\
{}&{\vdots}
\end{array}
}\\
\hline
\multicolumn{1}{|c}{
\begin{array}{cc}
{a_{i1}}&{\hphantom{\ldots}}
\end{array}
}&{\ldots}&\multicolumn{1}{c|}{
\begin{array}{cc}
{\hphantom{\ldots}}&{a_{in}}
\end{array}
}\\
\hline
{
\begin{array}{cc}
{\vdots}&{}\\
{a_{m1}}&{\ldots}
\end{array}
}&{}&{
\begin{array}{cc}
{\ddots}&{\vdots}\\
{\ldots}&{a_{mn}}
\end{array}
}
\end{array}
\right)
\left(
\begin{array}{c|c|c}
\cline{2-2}
{
\begin{array}{cc}
{b_{11}}&{\ldots}\\
{\vdots}&{\ddots}\\
\end{array}
}&{
\begin{array}{c}
{b_{1j}}\\
{\vphantom{\vdots}}
\end{array}
}&{
\begin{array}{cc}
{\ldots}&{b_{1k}}\\
{}&{\vdots}
\end{array}
}\\
{}&{\vdots}&{}\\
{
\begin{array}{cc}
{\vdots}&{}\\
{b_{n1}}&{\ldots}
\end{array}
}&{
\begin{array}{c}
{\vphantom{\vdots}}\\
{b_{nj}}
\end{array}
}&{
\begin{array}{cc}
{\ddots}&{\vdots}\\
{\ldots}&{b_{nk}}
\end{array}
}\\
\cline{2-2}
\end{array}
\right)
=
\left(
\begin{array}{ccc}
{
\begin{array}{cc}
{*}&{{\ldots}}\\
{{\vdots}}&{\ddots}
\end{array}
}&{}&{
\begin{array}{cc}
{\ldots}&{*}\\
{}&{\vdots}
\end{array}
}\\
\cline{2-2}
{}&\multicolumn{1}{|c|}{\vphantom{\sqrt{d}}\sum_{t=1}^n a_{it}b_{tj}}&{}\\
\cline{2-2}
{
\begin{array}{cc}
{\vdots}&{}\\
{*}&{\ldots}
\end{array}
}&{}&{
\begin{array}{cc}
{\ddots}&{\vdots}\\
{\ldots}&{*}
\end{array}
}
\end{array}
\right)
\]
При этом умножение строки на столбец можно себе представлять так: мы приставляем строку к столбцу, потом поэлементно перемножаем их, а затем складываем все произведения вместе.
\begin{gather*}
\begin{array}{ccc}
\hline
\multicolumn{1}{|c}{
\begin{array}{cc}
{a_{i1}}&{\hphantom{\ldots}}
\end{array}
}&{\ldots}&\multicolumn{1}{c|}{
\begin{array}{cc}
{\hphantom{\ldots}}&{a_{in}}
\end{array}
}\\
\hline
\end{array}
\cdot
\begin{array}{|c|}
\hline
{
\begin{array}{c}
{b_{1j}}\\
{\vphantom{\vdots}}
\end{array}
}\\
{\vdots}\\
{
\begin{array}{c}
{\vphantom{\vdots}}\\
{b_{nj}}
\end{array}
}\\
\hline
\end{array}
\mapsto
\begin{array}{c}
{
\begin{array}{ccc}
\hline
\multicolumn{1}{|c}{
\begin{array}{cc}
{a_{i1}}&{\hphantom{\ldots}}
\end{array}
}&{\ldots}&\multicolumn{1}{c|}{
\begin{array}{cc}
{\hphantom{\ldots}}&{a_{in}}
\end{array}
}\\
\hline
\end{array}
}\\
{}\\
{
\begin{array}{ccc}
\hline
\multicolumn{1}{|c}{
\begin{array}{cc}
{b_{1j}}&{\hphantom{\ldots}}
\end{array}
}&{\ldots}&\multicolumn{1}{c|}{
\begin{array}{cc}
{\hphantom{\ldots}}&{b_{nj}}
\end{array}
}\\
\hline
\end{array}
}
\end{array}\mapsto
\\
\mapsto
\begin{array}{ccccc}
{
\begin{array}{|c|}
\hline
{a_{i1}}\\{\cdot}\\{b_{1j}}\\
\hline
\end{array}
}&{+}&{\ldots}&{+}&{
\begin{array}{|c|}
\hline
{a_{in}}\\{\cdot}\\{b_{nj}}\\
\hline
\end{array}
}\\
\end{array}
=
a_{i1} b_{1j} + \ldots + a_{in} b_{nj}
\end{gather*}

\paragraph{Транспонирование}

Пусть $A$ -- матрица вида
\[
\begin{pmatrix}
{a_{11}}&{\ldots}&{a_{1n}}\\
{\vdots}&{\ddots}&{\vdots}\\
{a_{m1}}&{\ldots}&{a_{mn}}\\
\end{pmatrix}\quad \text{или}\quad
\begin{pmatrix}
{a_{11}}&{a_{12}}&{a_{13}}\\
{a_{21}}&{a_{22}}&{a_{23}}
\end{pmatrix}\quad \text{или}\quad
\begin{pmatrix}
{x_1}\\
{x_2}\\
{x_3}\\
\end{pmatrix}
\]
Определим транспонированную матрицу $A^t = (a'_{ij})$ так: $a'_{ij} = a_{ji}$.
Наглядно, транспонированная матрица для приведенных выше
\[
\begin{pmatrix}
{a_{11}}&{\ldots}&{a_{m1}}\\
{\vdots}&{\ddots}&{\vdots}\\
{a_{1n}}&{\ldots}&{a_{mn}}\\
\end{pmatrix}\quad\text{или}\quad
\begin{pmatrix}
{a_{11}}&{a_{21}}\\
{a_{12}}&{a_{22}}\\
{a_{13}}&{a_{23}}\\
\end{pmatrix}\quad \text{или}\quad
\begin{pmatrix}
{x_1}&{x_2}&{x_3}\\
\end{pmatrix}
\]

\paragraph{След матрицы}

Пусть $A\in\Matrix{n}$, тогда определим след матрицы $A$, как сумму ее диагональных элементов: $\tr A = \sum_{i=1}^n a_{ii}$.
Давайте отметим следующие свойства следа:
\begin{enumerate}
\item Для любых матриц $A, B\in \Matrix{n}$ верно $\tr(A + B) = \tr(A) + \tr(B)$.

\item Для любой матрицы $A\in \Matrix{n}$ и $\lambda \in \mathbb R$ выполнено $\tr(\lambda A) = \lambda \tr(A)$.

\item Для любых матриц $A\in \MatrixDim{m}{n}$ и $B\in \MatrixDim{n}{m}$ выполнено $\tr(AB) = \tr(BA)$.
\end{enumerate}
Все эти свойства проверяются непосредственным вычислением по определению.

\subsection{Специальные виды матриц}

Ниже мы перечислим названия некоторых специальных классов матриц:
\begin{itemize}
\item 
$A = 
\begin{pmatrix}
{\lambda_1}&{\ldots}&{0}\\
{\vdots}&{\ddots}&{\vdots}\\
{0}&{\ldots}&{\lambda_n}\\
\end{pmatrix}$ -- диагональная матрица.
Все ненулевые элементы стоят на главной диагонали, то есть в позиции, где номер строки равен номеру столбца.

\item
$A = 
\begin{pmatrix}
{\lambda}&{\ldots}&{0}\\
{\vdots}&{\ddots}&{\vdots}\\
{0}&{\ldots}&{\lambda}\\
\end{pmatrix}$ -- скалярная матрица.
Диагональная матрица с одинаковыми элементами на диагонали.
\end{itemize}

\subsection{Свойства операций}

Все операции на матрицах обладают <<естественными свойствами>> и согласованы друг с другом.
Вот перечень базовых свойств операций над матрицами:%
\footnote{Все эти свойства объединяет то, что они являются аксиомами в различных определениях для алгебраических структур.
Позже мы столкнемся с такими структурами.}
\begin{enumerate}
\item {\bf Ассоциативность сложения}
$(A + B) + C = A + (B + C)$ для любых $A,B,C\in \MatrixDim{m}{n}$

\item {\bf Существование нейтрального элемента для сложения}
Существует единственная матрица $0$ обладающая следующим свойством $A + 0 = 0 + A = A$ для всех $A\in\MatrixDim{m}{n}$.
Такая матрица целиком заполнена нулями.

\item {\bf Коммутативность сложения}
$A + B = B + A$ для любых $A,B\in\MatrixDim{m}{n}$.

\item {\bf Наличие обратного по сложению}
Для любой матрицы $A\in\MatrixDim{m}{n}$ существует матрица $-A$ такая, что $A + (-A) = (-A) + A = 0$.
Такая матрица единственная и состоит из элементов $-a_{ij}$.

\item {\bf Ассоциативность умножения}
Для любых матриц $A\in\MatrixDim{m}{n}$, $B\in\MatrixDim{n}{k}$ и $C\in\MatrixDim{k}{t}$ верно $(AB)C = A(BC)$.

\item {\bf Существование нейтрального элемента для умножения}
Для каждого $k$ существует единственная матрица $E\in\Matrix{k}$ такая, что для любой $A\in\MatrixDim{m}{n}$ верно $E A = A E = A$.
У такой матрицы $E_{ii} = 1$, а $E_{ij} = 0$.
Когда нет путаницы, матрицу $E$ обозначают через $1$.

\item {\bf Дистрибутивность умножения относительно сложения}
Для любых матриц $A,B\in\MatrixDim{m}{n}$ и $C\in\MatrixDim{n}{k}$ верно $(A + B)C = AC + B C$.
Аналогично, для любых $A\in\MatrixDim{m}{n}$ и $B,C\in\MatrixDim{n}{k}$ верно $A(B+C) = AB + AC$.

\item {\bf Умножение на числа ассоциативно}
Для любых $\lambda,\mu \in\mathbb R$ и любой матрицы $A\in\MatrixDim{m}{n}$ верно $\lambda(\mu A) = (\lambda \mu) A$.
Аналогично для любого $\lambda \in \mathbb R$ и любых $A\in\MatrixDim{m}{n}$ и $B\in \MatrixDim{n}{k}$ верно $\lambda(AB) = (\lambda A) B$.

\item {\bf Умножение на числа дистрибутивно относительно сложения матриц и сложения чисел}
Для любых $\lambda,\mu\in \mathbb R$ и $A\in \MatrixDim{m}{n}$ верно $(\lambda + \mu)A = \lambda A +\mu A$.
Аналогично, для любого $\lambda\in\mathbb R$ и $A,B\in\MatrixDim{m}{n}$ верно $\lambda(A+B) = \lambda A + \lambda B$.

\item {\bf Умножение на скаляр нетривиально}
Если $1\in\mathbb R$, то для любой матрицы $A\in \MatrixDim{m}{n}$ верно $1 A = A$.

\item {\bf Умножение на скаляр согласовано с умножением матриц}
Для любого $\lambda \in \mathbb R$ и любых $A\in\MatrixDim{m}{n}$ и $B\in\MatrixDim{n}{k}$ верно $\lambda(AB) = (\lambda A)B = A (\lambda B)$.

\item {\bf Транспонирование согласовано с суммой}
Для любых матриц $A, B\in\MatrixDim{m}{n}$ верно $(A+B)^t = A^t + B^t$.

\item {\bf Транспонирование согласовано с умножением на скаляр}
Для любой матрицы $A\in\MatrixDim{m}{n}$ и любого $\lambda\in\mathbb R$ верно $(\lambda A)^t = \lambda A^t$.

\item {\bf Транспонирование согласовано с умножением}
Для любых матриц $A, B\in\MatrixDim{m}{n}$ верно $(AB)^t = B^t A^t$.
\end{enumerate}

К этим свойствам надо относиться так.
Доказывая что-то про матрицы, можно лезть внутрь определений операций над ними, а можно пользоваться свойствами операций.
Так вот, список выше -- это минимальный набор свойств операций, из которых можно вытащить базовую информацию про эти операции и при этом не лезть внутрь определений.

\paragraph{Нулевые строки и столбцы}

Пусть в матрице $A\in \MatrixDim{m}{k}$ $i$-я строка полностью состоит из нулей и нам дана матрица $B\in \MatrixDim{k}{n}$.
Тогда в произведении $AB$ $i$-я строка тоже будет нулевая.
Изобразим это ниже графически
\[
AB =
\begin{pmatrix}
{*}&{*}&{\ldots}&{*}\\
{*}&{*}&{\ldots}&{*}\\
{0}&{0}&{\ldots}&{0}\\
{*}&{*}&{\ldots}&{*}\\
\end{pmatrix}
\begin{pmatrix}
{*}&{*}&{\ldots}&{*}\\
{*}&{*}&{\ldots}&{*}\\
{*}&{*}&{\ldots}&{*}\\
{*}&{*}&{\ldots}&{*}\\
\end{pmatrix}
=
\begin{pmatrix}
{*}&{*}&{\ldots}&{*}\\
{*}&{*}&{\ldots}&{*}\\
{0}&{0}&{\ldots}&{0}\\
{*}&{*}&{\ldots}&{*}\\
\end{pmatrix}
\]
Действительно, $i$-я строка произведения зависит от $i$-ой строки левого смножителя (матрицы $A$) и всех столбцов $B$.
Но умножая нулевую строку $A$ на что угодно, получим нули в $i$-ой строке результата.
Аналогичное утверждение верно для столбцов в матрице $B$, а именно.
Пусть в матрице $B\in \MatrixDim{k}{n}$ $i$-ый столбец полностью состоит из нулей и нам дана матрица $A\in \MatrixDim{m}{k}$.
Тогда в произведении $AB$ $i$-ый столбец тоже будет нулевой.
\[
AB =
\begin{pmatrix}
{*}&{*}&{*}&{*}\\
{*}&{*}&{*}&{*}\\
{\vdots}&{\vdots}&{\vdots}&{\vdots}\\
{*}&{*}&{*}&{*}\\
\end{pmatrix}
\begin{pmatrix}
{*}&{*}&{0}&{*}\\
{*}&{*}&{0}&{*}\\
{\vdots}&{\vdots}&{\vdots}&{\vdots}\\
{*}&{*}&{0}&{*}\\
\end{pmatrix}
=
\begin{pmatrix}
{*}&{*}&{0}&{*}\\
{*}&{*}&{0}&{*}\\
{\vdots}&{\vdots}&{\vdots}&{\vdots}\\
{*}&{*}&{0}&{*}\\
\end{pmatrix}
\]

\subsection{Связь с системами линейных уравнений}

Пусть нам дана система линейных уравнений соответствующая матрицам
\[
A= 
\begin{pmatrix}
a_{11}&\ldots& a_{1n}\\
\vdots&\ddots&\vdots\\
a_{m1}& \ldots &a_{mn}
\end{pmatrix}\quad
b = 
\begin{pmatrix}
b_1\\
\vdots\\
b_m
\end{pmatrix} \quad
x =
\begin{pmatrix}
x_1\\
\vdots\\
x_n
\end{pmatrix}\quad
(A|b) =
\left(\left.
\begin{matrix}
a_{11}&\ldots&a_{1n}\\
\vdots&\ddots&\vdots\\
a_{m1}&\ldots&a_{mn}\\
\end{matrix}
\:\right|\:
\begin{matrix}
b_1\\
\vdots\\
b_m\\
\end{matrix}\right)
\]
Мы кратко записывали такую систему $Ax = b$, а ее однородную версию через $Ax = 0$.
Но теперь, когда мы знаем умножение матриц, видно, что $Ax$ -- это произведение матрицы $A$, на вектор неизвестных $x$.

Главный бонус от матриц и операций над ними заключается вот в чем.
У нас исходно была большая и неуклюжая система линейных уравнений, в которой участвовали очень знакомые и простые для использования числа.
Теперь же мы заменили много линейных уравнений с кучей неизвестных на одно линейное матричное уравнение $Ax = b$.
Однако, теперь вместо приятных в использовании чисел у нас встретились более сложные объекты -- матрицы.
Потому к матрицам надо относиться как к более продвинутой версии чисел.

\paragraph{Линейная структура}

Пусть у нас дана система $Ax = b$ как выше.
Тогда $y\in\Vector{n}$ является решением этой системы, если выполнено матричное равенство $Ay = b$.
Аналогично и для однородной системы.
Теперь заметим следующее:
\begin{enumerate}
\item Если $y_1, y_2\in \Vector{n}$ -- решения системы $Ax = 0$, то $y_1 + y_2$ тоже является решением системы $Ax = 0$.
Действительно, надо показать, что $A(y_1 + y_2) = 0$.
Но $A(y_1 + y_2) = A y_1 + Ay_2 = 0 + 0 = 0$.

\item Если $y\in\Vector{n}$ -- решение системы $Ax = 0$ и $\lambda\in \mathbb R$, то $\lambda y$ -- тоже решение $Ax = 0$.
Действительно, $A(\lambda y) = \lambda Ay = 0$.
\end{enumerate}

Теперь сравним решения систем $Ax = b$ и $Ax = 0$.
Прежде всего заметим, что однородная система всегда имеет решение $x = 0$.
И вообще говоря, может так оказаться, что $Ax = b$ не имеет решений.
Например, $(A|b) = (0|1)$.
Однако, если $Ax = b$ совместна, то обе системы имеют <<одинаковое число>> решений.

\begin{claim*}
Пусть система $Ax = b$ имеет хотя бы одно решение $z\in\Vector{n}$ и пусть $E_b\subseteq \Vector{n}$ -- множество решений $Ax = b$ и $E_0\subseteq \Vector{n}$ -- множество решений $Ax = 0$.
Тогда $E_b = z + E_0 = \{z +y\mid y\in E_0\}$.
\end{claim*}
\begin{proof}
Для доказательства $z + E_0 \subseteq E_b$ надо заметить, что если $y\in E_0$, то $z+y\in E_b$.
Для обратного включения проверяется, что если $z'\in E_b$, то $z' - z\in E_0$.
\end{proof}

\subsection{Дефекты матричных операций}

\paragraph{Матрицы как новые числа}

Рассмотрим множество квадратных матриц с введенными выше операциями: $(\Matrix{n}, +, -, \cdot, {}^t)$.
Про это множество стоит думать как про новый вид чисел со своими операциями.
Принципиальное отличие -- нельзя делить на любую ненулевую матрицу, как это можно было делать с числами.
Однако, это не единственное отличие.

\paragraph{Аномалии матричных операций}

Матричные операции обладают несколькими аномалиями по сравнению со свойствами операций над обычными числами.
\begin{enumerate}
\item Существование вычитания следует из <<хорошести>> операции сложения.
Она позволяет определить вычитание без проблем.
Однако, операция умножения уже хуже, чем на обычных числах, потому не получится просто так определить на матрицах операцию деления.
Про деление и как его можно было бы обобщать мы поговорим ниже.

\item Давайте обсудим порядок матриц в произведении.
Тут может быть несколько проблем.
Может так оказаться, что матрицы можно перемножить в одном порядке, но нельзя в другом.
Например, $A\in \MatrixDim{m}{n}$, $B\in \MatrixDim{n}{k}$ и при этом $m\neq k$.
В этом случае $AB\in \MatrixDim{m}{k}$, однако, произведение $BA$ просто не определено из-за отсутствия условия согласованности матриц.
Если мы рассмотрим матрицы, которые можно перемножить в обоих порядках, то есть $A\in \MatrixDim{m}{n}$, $B\in \MatrixDim{n}{m}$, то результаты будут $AB\in \Matrix{m}$ и $BA\in \Matrix{n}$.
А значит при разных $m$ и $n$ это будут матрицы разного размера и не могут быть одинаковыми.
Таким образом, чтобы $AB$ могло совпасть с $BA$ нам надо, чтобы матрицы $A$ и $B$ были квадратными.
Но даже в этом случае умножение матриц НЕ коммутативно.
Действительно, вот простой пример в малой размерности
\[
\begin{pmatrix}
{0}&{1}\\
{0}&{0}
\end{pmatrix}
\begin{pmatrix}
{0}&{0}\\
{1}&{0}
\end{pmatrix}
=
\begin{pmatrix}
{1}&{0}\\
{0}&{0}
\end{pmatrix}\quad\text{но}\quad
\begin{pmatrix}
{0}&{0}\\
{1}&{0}
\end{pmatrix}
\begin{pmatrix}
{0}&{1}\\
{0}&{0}
\end{pmatrix}
=\begin{pmatrix}
{0}&{0}\\
{0}&{1}
\end{pmatrix}
\]

\item В матрицах есть <<делители нуля>>, т.е. существуют две ненулевые матрицы $A$ и $B$ такие, что $AB = 0$.%
\footnote{На самом деле, это очень <<хорошая>> аномалия, так как она связана с тем, что ОСЛУ имеют решения.
Действительно, вопрос решения ОСЛУ $Ax = 0$ -- это в точности вопрос существования правых делителей нуля для $A$ в множестве $\Vector{n}$.}
Пример:
\[
\begin{pmatrix}
{1}&{0}\\
{0}&{0}
\end{pmatrix}
\begin{pmatrix}
{0}&{0}\\
{0}&{1}
\end{pmatrix}
=0
\]

\item В матрицах есть <<нильпотенты>>, то есть можно найти такую ненулевую матрицу $A$, что $A^n=0$.
Пример, 
\[
\begin{pmatrix}
{0}&{1}\\
{0}&{0}
\end{pmatrix}^2
=
\begin{pmatrix}
{0}&{1}\\
{0}&{0}
\end{pmatrix}
\begin{pmatrix}
{0}&{1}\\
{0}&{0}
\end{pmatrix}
=0
\]
\end{enumerate}

\subsection{Деление}

\paragraph{Деление и некоммутативность}

Теперь мы хотим научиться делить матрицы друг на друга.
Прежде чем это делать, обратим внимание, что умножение в матрицах у нас не коммутативно.
Это значит умножать можно на матрицу слева или справа.
А значит и делить надо уметь и слева и справа, то есть вместо одной операции деления, надо иметь целых две операции деления.
Кроме того, надо будет установить, как эти операции связаны друг с другом, например, разделить сначала справа, а потом слева или наоборот сначала слева, а потом справа дают один и тот же результат или нет?
Возникает куча сложностей работы с двумя операциями деления.
Таким путем пойти можно, и есть тексты, которые делают именно так, но это не очень удобно.
Вместо этого предлагается пойти другим путем, но для этого надо переосмыслить понятие деления.

\paragraph{Что значит деление в числах?}

Предположим, что у нас есть два числа $a,b\in\mathbb R$.
Тогда деление $a/b = a \cdot b^{-1}$ -- это просто умножение на обратный элемент, а обратный элемент $b^{-1}$ определяется свойством $b b^{-1} = 1$.
Данное наблюдение дает ключ к распространению деления и обращения на случай матриц.
А именно, вместо деления, мы будем рассматривать обратные матрицы и умножение на них.
И вот сразу преимущество такого подхода.
Нам не надо вводить два вида деления: левое и правое.
Вместо этого, намного проще изучать обратные матрицы и умножать на них слева и справа с помощью обычного умножения.

\paragraph{Односторонняя обратимость}

Пусть $A\in\MatrixDim{m}{n}$, будем говорить, что $B\in\MatrixDim{n}{m}$ является левым обратным к $A$, если $BA = E\in\Matrix{n}$.
Аналогично, $B\in\MatrixDim{n}{m}$ -- правый обратный к $A$, если $AB = E\in\Matrix{m}$.
Надо иметь в виду, что вообще говоря левые и правые обратные между собой никак не связаны и их может быть много.
Например, пусть $A = (1, 0)\in\MatrixDim{1}{2}$.
Тогда у такой матрицы нет левого обратного, а любая матрица вида $(1, a)^t$ является правым обратным.
Если для матрицы $A$ существует левый обратный, то она называется обратимой слева.
Аналогично, при существовании правого обратного -- обратимой справа.

\paragraph{Обратимые матрицы}

Матрица $A\in\MatrixDim{m}{n}$ называется обратимой, если к ней существует левый и правый обратный.%
\footnote{Ниже мы покажем, что из двусторонней обратимости следует, что матрица $A$ обязана быть квадратной.}

\begin{claim}
Пусть матрица $A\in\MatrixDim{m}{n}$ обратима.
Тогда
\begin{enumerate}
\item Левый обратный и правый обратный единственны и совпадают друг с другом.

\item Матрица $A$ обязательно квадратная, то есть $m = n$.
\end{enumerate}
\end{claim}
\begin{proof}
(1) Пусть $L\in\MatrixDim{n}{m}$ -- произвольный левый обратный к $A$, а $R\in\MatrixDim{n}{m}$ -- произвольный правый обратный.
Тогда рассмотрим выражение $LAR$, расставляя по разному скобки имеем:
\[
R = ER = (LA)R = L (AR) = LE = L
\]
Теперь, если $L$ и $L'$ -- два разных левых обратных.
Зафиксируем произвольный правый обратный $R$.
Из выше сказанного следует, что $L = R$ и $L' = R$.
Значит все левые обратные равны между собой.
Аналогично для правых.

(2) Теперь покажем, что двусторонний обратный есть только у квадратных матриц.
Пусть $B\in \MatrixDim{n}{m}$ -- двусторонний обратный к $A$, то есть $AB = E_m\in\Matrix{m}$ и $BA = E_n\in \Matrix{n}$.%
\footnote{Тут $E_n$ означает единичную матрицу размера $n$.}
Тогда по свойствам следа получим
\[
m = \tr(E_m) = \tr(AB) = \tr(BA) = \tr(E_n) = n
\]
\end{proof}

Значит, если матрица $A$ обратима, то она как минимум квадратная и существует единственная матрица $B$, удовлетворяющая свойствам $AB = BA = E$.
Такую матрицу $B$ обозначают $A^{-1}$ и называют обратной к матрице $A$.

\begin{claim}
Пусть $A, B\in \Matrix{n}$ -- обратимые матрицы.
Тогда 
\begin{enumerate}
\item $AB$ тоже обратима и при этом $(AB)^{-1} = B^{-1}A^{-1}$.

\item  $A^t$ также будет обратима и $(A^t)^{-1} = (A^{-1})^t$ и обозначается $A^{-t}$.
\end{enumerate}
\end{claim}
\begin{proof}
1) Действительно, надо проверить, что для $AB$ существует двусторонняя обратная.
Заметим, что $B^{-1}A^{-1}$ является таковой:
\[
AB B^{-1}A^{-1} = E \quad\text{и}\quad B^{-1}A^{-1} AB = E
\]
В частности, последнее означает, что $(AB)^{-1} = B^{-1}A^{-1}$.

2) Пусть матрица $A$ обратима, тогда
\[
A A^{-1} = E\quad \text{и}\quad A^{-1}A = E
\]
Транспонируем оба равенства, получим
\[
(A^{-1})^t A^t = E\quad \text{и}\quad A^t (A^{-1})^t = E
\]
Это означает, что $A^t$ обратима и при этом $(A^t)^{-1} = (A^{-1})^t$.
\end{proof}

\paragraph{Обратимые преобразования над СЛУ} 

% TO DO
% Оформить это как выделенное утверждение

Пусть у нас есть $A\in\MatrixDim{m}{n}$ и $b\in \Vector{m}$, которые задают систему линейных уравнений $Ax = b$, где $x\in \Vector{n}$.
Возьмем произвольную обратимую матрицу $C\in\Matrix{m}$.
Тогда система $Ax = b$ эквивалентна системе $CAx = Cb$.
Действительно, если для некоторого $y\in\Vector{n}$ имеем $Ay = b$, то, умножая обе части на $C$ слева, получим $CAy = Cb$, значит $y$ решение второй системы.
Наоборот, пусть $CA y = Cb$, тогда, умножая обе части на $C^{-1}$ слева, получим $Ay =b$, значит $y$ решение первой системы.

Сказанное выше значит, что мы можем менять СЛУ на эквивалентные с помощью умножения слева на любую обратимую матрицу.
Мы уже знаем, что есть другая процедура преобразования СЛУ с таким же свойством -- применение элементарных преобразований.
Возникает резонный вопрос: какая процедура лучше?
Оказывается, что между ними нет разницы в том смысле, что умножение на обратимую матрицу всегда совпадает с некоторой последовательностью элементарных преобразований и наоборот любое элементарное преобразование можно выразить с помощью умножения на обратимую матрицу.
Этому свойству и будет посвящен остаток лекции.

\subsection{Матрицы элементарных преобразований}
\label{section::ElemMat}

\paragraph{Тип I}

Пусть $S_{ij}(\lambda)\in\Matrix{n}$ -- матрица, полученная из единичной вписыванием в ячейку $i$ $j$ числа $\lambda$ (при этом $i\neq j$, то есть ячейка берется не на диагонали).
Эта матрица имеет следующий вид:
\[
\begin{tabular}{cc}
{}&{\quad \quad $j$}\\
{
$
\begin{matrix}
{}\\{i}\\{}\\{}
\end{matrix}
$}&{
$
\begin{pmatrix}
{1}&{0}&{\ldots}&{0}\\
{0}&{\ddots}&{\lambda}&{\vdots}\\
{\vdots}&{}&{\ddots}&{0}\\
{0}&{\ldots}&{0}&{1}\\
\end{pmatrix}
$
}
\end{tabular}
\]
Тогда прямая проверка показывает, умножение $A\in\MatrixDim{n}{m}$ на $S_{ij}(\lambda)$ слева прибавляет $j$ строку умноженную на $\lambda$ к $i$ строке матрицы $A$, а умножение $B\in\MatrixDim{m}{n}$ на $S_{ij}(\lambda)$ справа прибавляет $i$ столбец умноженный на $\lambda$ к $j$ столбцу матрицы $B$.
Заметим, что $S_{ij}(\lambda)^{-1} = S_{ij}(-\lambda)$.

\paragraph{Тип II}

Пусть $T_{ij}\in\Matrix{n}$ -- матрица, полученная из единичной перестановкой $i$ и $j$ ($i\neq j$) столбцов (или что то же самое -- строк).
Эта матрица имеет следующий вид
\[
\begin{tabular}{cc}
{}&{$i$\quad \quad\quad $j$}\\
{
$
\begin{matrix}
{}\\{i}\\{}\\{j}\\{}
\end{matrix}
$}&{
$
\begin{pmatrix}
{1}&{}&{}&{}&{}\\
{}&{0}&{}&{1}&{}\\
{}&{}&{\ddots}&{}&{}\\
{}&{1}&{}&{0}&{}\\
{}&{}&{}&{}&{1}\\
\end{pmatrix}
$
}
\end{tabular}
\]
Тогда прямая проверка показывает, умножение $A\in\MatrixDim{n}{m}$ на $T_{ij}$ слева переставляет $i$ и $j$ строки матрицы $A$, а умножение $B\in\MatrixDim{m}{n}$ на $T_{ij}$ справа переставляет $i$ и $j$ столбцы матрицы $B$.
Заметим, что $T_{ij}^{-1} = T_{ij}$.


\paragraph{Тип III}

Пусть $D_i(\lambda)\in\Matrix{n}$ -- матрица, полученная из единичной умножением $i$ строки на $\lambda\in\mathbb R\setminus 0$ (или что то же самое -- столбца).
Эта матрица имеет следующий вид
\[
\begin{tabular}{cc}
{}&{$i$}\\
{
$
\begin{matrix}
{}\\{}\\{i}\\{}\\{}
\end{matrix}
$}&{
$
\begin{pmatrix}
{1}&{}&{}&{}&{}\\
{}&{\ddots}&{}&{}&{}\\
{}&{}&{\lambda}&{}&{}\\
{}&{}&{}&{\ddots}&{}\\
{}&{}&{}&{}&{1}\\
\end{pmatrix}
$
}
\end{tabular}
\]
Тогда прямая проверка показывает, умножение $A\in\MatrixDim{n}{m}$ на $D_i(\lambda)$ слева умножает $i$ строку $A$ на $\lambda$, а умножение $B\in\MatrixDim{m}{n}$ на $D_i(\lambda)$ справа умножает $i$ столбец матрицы $B$ на $\lambda$.
Заметим, что $D_i(\lambda)^{-1}= D_i(\lambda^{-1})$.

\subsection{Невырожденные матрицы}

Начнем с полезного утверждения.

\begin{claim}
\label{claim::InvertibleDiscription}
Пусть $A\in\Matrix{n}$ -- произвольная квадратная матрица.
Тогда следующие условия эквивалентны:
\begin{enumerate}
\item Система $Ax = 0$ имеет только нулевое решение.

\item Система $A^ty = 0$ имеет только нулевое решение.

\item Матрица $A$ представляется в виде $A = U_1\cdot \ldots \cdot U_k$, где $U_i$ -- матрицы элементарных преобразований.

\item Матрица $A$ обратима.

\item Матрица $A$ обратима слева, т.е. существует $L$ такая, что $LA = E$.

\item Матрица $A$ обратима справа, т.е. существует $R$ такая, что $AR = E$.
\end{enumerate}
\end{claim}

