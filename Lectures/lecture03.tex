\ProvidesFile{lecture03.tex}[Лекция 3]


\begin{proof}
[Доказательство Утверждения~\ref{claim::InvertibleDiscription}]
(1)$\Rightarrow$(3).
Приведем $A$ к улучшенному ступенчатому виду с помощью Гаусса.
Так как $Ax = 0$ имеет только нулевое решение, то ступенчатый вид -- это единичная матрица $E$.
Пусть $S_1, \ldots, S_k$ -- матрицы элементарных преобразований, которые мы совершили во время Гаусса.
Это значит, что мы произвели следующие манипуляции
\[
A \mapsto S_1 A \mapsto S_2 S_1 A \mapsto \ldots \mapsto (S_k \ldots S_1 A) = E
\]
То есть $A = S_1^{-1}\ldots S_k^{-1}$.
Заметим, что $S_i^{-1}$ -- это матрица обратного элементарного преобразования к $S_i$.
Обозначим $U_i = S_i^{-1}$ и получим требуемое.

(2)$\Rightarrow$(3).
Проведем предыдущее рассуждение для матрицы $A^t$ вместо $A$.
Получим, что $A^t = U_1\ldots U_k$.
Тогда $A = U_k^t \ldots U_1^t$.
Теперь осталось заметить, что $U_i^t$ тоже является матрицей элементарного преобразования.

(3)$\Rightarrow$(4).
Мы имеем $A=U_1\ldots U_k$, причем каждая из $U_i$ обратима.
Так как произведение обратимых обратимо, то $A$ также обратима.

(4)$\Rightarrow$(5) и (4)$\Rightarrow$(6) очевидно, так это переход от более сильного условия к более слабому.

(5)$\Rightarrow$(1).
Пусть $A$ обратима слева и нам надо решить систему $Ax = 0$.
Умножим ее слева на левый обратный к $A$, получим $x = 0$, что и требовалось.

(6)$\Rightarrow$(2).
Пусть $A$ обратима справа и нам надо решить систему $A^ty = 0$.
Умножим эту систему слева на $R^t$, где $R$ -- правый обратный к $A$.
Тогда $R^t A^t x = 0$.
Но $R^t A^t x = (AR)^tx = Ex = x = 0$, что и требовалось.
\end{proof}

В силу этого утверждения, мы не будем различать невырожденные и обратимые матрицы между собой.

\begin{definition}
Пусть $A\in\Matrix{n}$ -- произвольная квадратная матрица.
Будем говорить, что $A$ невырождена%
\footnote{Классически невырожденные матрицы определяются совсем по-другому, однако, все эти определения между собой эквивалентны.
Будьте готовы к тому, что в литературе вы увидите совсем другое определение.},
если удовлетворяет любому из перечисленных в предыдущем утверждении условий.
\end{definition}


\paragraph{Делители нуля}

Пусть $A\in\Matrix{n}$ -- некоторая ненулевая матрица и пусть $B\in\MatrixDim{n}{m}$.
Матрица $B$ называется правым делителем нуля для $A$, если $AB = 0$.
Условие~(1) предыдущего утверждения эквивалентно отсутствию правых делителей нуля.
Условие~(1) не сильнее, значит надо показать, что оно влечет отсутствие делителей нуля.
Если $B$ -- правый делитель нуля для $A$, то любой столбец $b$ матрицы $B$ удовлетворяет условию $Ab = 0$, а значит нулевой.

Аналогично определяются левые делители нуля для $A$ и показывается, что их отсутствие равносильно условию~(2) предыдущего результата.

\paragraph{Элементарные преобразования и обратимость}

Пусть $A\in\MatrixDim{m}{n}$ и $b\in\mathbb R^m$.
Тогда у нас есть две процедуры преобразования СЛУ $Ax = b$:
\begin{enumerate}
\item Применение элементарных преобразований к строкам системы.

\item Умножение обеих частей равенства на обратимую матрицу: $Ax=b$ меняем на $CAx = Cb$, где $C\in\Matrix{n}$ -- обратимая.
\end{enumerate}

Так как любое элементарное преобразование сводится к умножению слева на обратимую матрицу, то мы видим, что первый вид модификации систем является частным случаем второго.
В обратную сторону, из доказанного утверждения следует, что любая обратимая матрица может быть расписана как произведение матриц элементарных преобразований.
Значит, умножить на обратимую матрицу слева -- это все равно что сделать последовательность элементарных преобразований.

Главный плюс элементарных преобразований -- у них простые матрицы, а минус -- их нужно много, очень много, чтобы преобразовать одну систему в другую.
С обратимыми матрицами все наоборот: сами матрицы устроены непонятно как, но зато нужно всего одно умножение матриц, чтобы перевести систему из одной в другую.
Именно на это надо обращать внимание при выборе подхода по преобразованию систем.


\paragraph{Насыщенность обратимых}

Я хочу продемонстрировать еще одно полезное следствие из Утверждения~\ref{claim::InvertibleDiscription}.
Предположим у нас есть две матрицы $A, B\in \Matrix{n}$.
Тогда $AB$ обратима тогда и только тогда, когда $A$ и $B$ обратимы.
Действительно, справа налево мы уже знаем, обратимость обеих матриц $A$ и $B$ влечет обратимость произведения, мы даже знаем, что при этом $(AB)^{-1} = B^{-1}A^{-1}$.
Надо лишь показать в обратную сторону.
Предположим, что $AB$ обратима, это значит, что для некоторой матрицы $D\in \Matrix{n}$ выполнено
\[
ABD = E\quad\text{и}\quad DAB = E
\]
Тогда первое равенство говорит, что $BD$ является правым обратным к $A$.
А в силу эквивалентности пунктов~(4) и~(6) Утверждения~\ref{claim::InvertibleDiscription} это означает, что $A$ обратима.
Аналогично, $DA$ является левым обратным к $B$ и в силу эквивалентности пунктов~(4) и~(5) Утверждения~\ref{claim::InvertibleDiscription}, матрица $B$ обратима.
Так что произведение матриц обратимо тогда и только тогда, когда каждый сомножитель обратим.

\subsection{Блочное умножение матриц}

\paragraph{Формулы блочного умножения}

Пусть даны две матрицы, которые разбиты на блоки как показано ниже:
\[
\begin{matrix}
{}&{
\begin{matrix}
{k}&{s}
\end{matrix}}\\
{
\begin{matrix}
{m}\\
{n}
\end{matrix}}&{
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}}
\end{matrix}
\quad\quad
\begin{matrix}
{}&{
\begin{matrix}
{u}&{v}
\end{matrix}}\\
{
\begin{matrix}
{k}\\
{s}
\end{matrix}}&{
\begin{pmatrix}
{X}&{Y}\\
{W}&{Z}
\end{pmatrix}}
\end{matrix}
\]
Числа $m$, $n$, $k$, $s$, $u$, $v$ -- размеры соответствующих блоков.
Наша цель понять, что эти матрицы можно перемножать блочно.
А именно, увидеть, что результат умножения этих матриц имеет вид
\[
\begin{matrix}
{}&{
u\quad\quad\quad\quad\quad v
}\\
{
\begin{matrix}
{m}\\
{n}
\end{matrix}}&{
\begin{pmatrix}
{A X + B W}&{A Y + B Z}\\
{C X + D W}&{C Y + D Z}
\end{pmatrix}}
\end{matrix}
\]
Делается это таким трюком.
В начале заметим, что
\[
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}
=
\begin{pmatrix}
{A}&{0}\\
{0}&{0}
\end{pmatrix}
+
\begin{pmatrix}
{0}&{B}\\
{0}&{0}
\end{pmatrix}
+
\begin{pmatrix}
{0}&{0}\\
{C}&{0}
\end{pmatrix}
+
\begin{pmatrix}
{0}&{0}\\
{0}&{D}
\end{pmatrix}
\]
После чего методом <<пристального взгляда>> перемножаем матрицы с большим количеством нулей (попробуйте проделать это!).

На этот факт можно смотреть вот как.
Матрица -- это прямоугольная таблица заполненная числами.
А можно составлять прямоугольные таблица заполненные другими объектами, например матрицами.
Тогда они складываются и перемножаются так же как и обычные матрицы из чисел.
Единственное надо учесть, что в блочном умножении есть разница между $AX + BW$ и $XA + BW$, так как $A$, $B$, $X$ и $W$ не числа, а матрицы, то их нельзя переставлять местами, порядок теперь важен.

Вот полезный пример.
Пусть дана матрица из $\Matrix{n+1}$ вида
\[
\begin{pmatrix}
{A}&{v}\\
{0}&{\lambda}
\end{pmatrix},
\quad\text{где}\quad
A\in\Matrix{n},\quad
v\in\Vector{n},\quad
\lambda\in\mathbb R
\]
Тогда
\[
\begin{pmatrix}
{A}&{v}\\
{0}&{\lambda}
\end{pmatrix}
\begin{pmatrix}
{A}&{v}\\
{0}&{\lambda}
\end{pmatrix}
=
\begin{pmatrix}
{A^2}&{Av + v\lambda}\\
{0}&{\lambda^2}
\end{pmatrix}
=
\begin{pmatrix}
{A^2}&{Av + \lambda v}\\
{0}&{\lambda^2}
\end{pmatrix}
=
\begin{pmatrix}
{A^2}&{(A + \lambda E) v}\\
{0}&{\lambda^2}
\end{pmatrix}
\]
Предпоследнее равенство верно, так как не важно с какой стороны умножать $v$ на скаляр $\lambda$.

Вот еще один полезный пример блочного умножения.
Пусть $x_1,\ldots,x_m\in \Vector{n}$ и $y_1,\ldots,y_m\in\Vector{n}$ -- столбцы.
Составим из этих столбцов матрицы $X =(x_1|\ldots|x_m)$ и $Y = (y_1|\ldots|y_m)$.%
\footnote{Данная запись означает, что мы берем столбцы $x_i$ и записываем их подряд в одну большую таблицу.}
Заметим, что $X,Y \in \MatrixDim{n}{m}$.
Тогда
\[
XY^t = (x_1|\ldots|x_m)(y_1|\ldots|y_m)^t = \sum_{i=1}^m x_iy_i^t
\]

\subsection{Блочные элементарные преобразования}

\paragraph{Преобразования первого типа}

Пусть у нас дана матрица
\[
\begin{matrix}
{}&{
\begin{matrix}
{k}&{s}
\end{matrix}}\\
{
\begin{matrix}
{m}\\
{n}
\end{matrix}}&{
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}}
\end{matrix}
\]
Я хочу взять первую <<строку>> из матриц $(A, B)$ умножить ее на некую матрицу $R$ слева и прибавить результат к <<строке>> $(C, D)$.
Для этого матрица $R$ должна иметь $n$ строк и $m$ столбцов.
То есть процедура будет выглядеть следующим образом
\[
\begin{matrix}
{}&{
\begin{matrix}
{k}&{s\phantom{dd}}
\end{matrix}}\\
{
\begin{matrix}
{m}\\
{n}
\end{matrix}}&{
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}\mapsto}
\end{matrix}
\begin{matrix}
{
\begin{matrix}
{k\phantom{dddddd}}&{s}
\end{matrix}
}&{
}\\
{
\begin{pmatrix}
{A}&{B}\\
{C+RA}&{D+RB}
\end{pmatrix}
}&{
\begin{matrix}
{m}\\
{n}
\end{matrix}
}
\end{matrix}
\]
Оказывается, что такая процедура является умножением на обратимую матрицу слева, а именно
\[
\begin{matrix}
{}&{
\begin{matrix}
{m}&{n}
\end{matrix}}\\
{
\begin{matrix}
{m}\\
{n}
\end{matrix}}&{
\begin{pmatrix}
{E}&{0}\\
{R}&{E}
\end{pmatrix}}
\end{matrix}
\;
\begin{matrix}
{
\begin{matrix}
{k}&{s}
\end{matrix}
}&{
}\\
{
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}
}&{
\begin{matrix}
{m}\\
{n}
\end{matrix}
}
\end{matrix}
\;\;
\begin{matrix}
{
\begin{matrix}
{\phantom{dd}k\phantom{dddddd}}&{s}
\end{matrix}
}&{
}\\
{
=
\begin{pmatrix}
{A}&{B}\\
{C+RA}&{D+RB}
\end{pmatrix}
}&{
\begin{matrix}
{m}\\
{n}
\end{matrix}
}
\end{matrix}
\]
Заметим, что
\[
\begin{pmatrix}
{E}&{0}\\
{R}&{E}
\end{pmatrix}^{-1}
=
\begin{pmatrix}
{E}&{0}\\
{-R}&{E}\\
\end{pmatrix}
\]
В частности из этого наблюдения следует, что блочные элементарные преобразования строк не меняют множества решений соответствующей системы.

Аналогично можно делать блочные элементарные преобразования столбцов.
А именно
\[
\begin{matrix}
{}&{
\begin{matrix}
{k}&{s\phantom{dd}}
\end{matrix}}\\
{
\begin{matrix}
{m}\\
{n}
\end{matrix}}&{
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}\mapsto}
\end{matrix}
\begin{matrix}
{
\begin{matrix}
{k}&{\phantom{ddd}s\phantom{dd}}
\end{matrix}
}&{
}\\
{
\begin{pmatrix}
{A}&{B + AT}\\
{C}&{D + CT}
\end{pmatrix}
}&{
\begin{matrix}
{m}\\
{n}
\end{matrix}
}
\end{matrix}
\]
где $T$ матрица с $k$ строками и $s$ столбцами.
Как и в случае преобразований со строками, эта процедура сводится к операции умножения на обратимую матрицу справа
\[
\begin{matrix}
{}&{
\begin{matrix}
{k}&{s}
\end{matrix}}\\
{
\begin{matrix}
{m}\\
{n}
\end{matrix}}&{
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}}
\end{matrix}
\;
\begin{matrix}
{
\begin{matrix}
{k}&{s}
\end{matrix}
}&{
}\\
{
\begin{pmatrix}
{E}&{T}\\
{0}&{E}
\end{pmatrix}
}&{
\begin{matrix}
{k}\\
{s}
\end{matrix}
}
\end{matrix}
\;\;
\begin{matrix}
{
\begin{matrix}
{\phantom{d}k}&{\phantom{ddd}s\phantom{dd}}
\end{matrix}
}&{
}\\
{
=
\begin{pmatrix}
{A}&{B + AT}\\
{C}&{D + CT}
\end{pmatrix}
}&{
\begin{matrix}
{m}\\
{n}
\end{matrix}
}
\end{matrix}
\]
Как и раньше
\[
\begin{pmatrix}
{E}&{T}\\
{0}&{E}
\end{pmatrix}^{-1}
=
\begin{pmatrix}
{E}&{-T}\\
{0}&{E}
\end{pmatrix}
\]

\paragraph{Замечание}

Обратите внимание, что при блочных преобразованиях строк умножение на матрицу-коэффициент $R$ происходит слева, а при преобразованиях столбцов умножение на матрицу-коэффициент $T$ происходит справа.

\paragraph{Преобразования второго типа}

Преобразование вида
\[
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}
\mapsto
\begin{pmatrix}
{C}&{D}\\
{A}&{B}
\end{pmatrix}
\]
сводится к умножению на обратимую блочную матрицу слева
\[
\begin{pmatrix}
{0}&{E}\\
{E}&{0}
\end{pmatrix}
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}
=
\begin{pmatrix}
{C}&{D}\\
{A}&{B}
\end{pmatrix}
\]
А преобразование
\[
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}
\mapsto
\begin{pmatrix}
{B}&{A}\\
{D}&{C}
\end{pmatrix}
\]
сводится к умножению на обратимую блочную матрицу справа
\[
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}
\begin{pmatrix}
{0}&{E}\\
{E}&{0}
\end{pmatrix}
=
\begin{pmatrix}
{B}&{A}\\
{D}&{C}
\end{pmatrix}
\]
При этом
\[
\begin{pmatrix}
{0}&{E}\\
{E}&{0}
\end{pmatrix}^{-1}
=
\begin{pmatrix}
{0}&{E}\\
{E}&{0}
\end{pmatrix}
\]

\paragraph{Преобразования третьего типа}

Если $R\in \Matrix{m}$ -- обратимая матрица, то
\[
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}
\mapsto
\begin{pmatrix}
{RA}&{RB}\\
{C}&{D}
\end{pmatrix}
\]
является преобразованием умножения на обратимую матрицу слева, а именно
\[
\begin{pmatrix}
{R}&{0}\\
{0}&{E}
\end{pmatrix}
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}
=
\begin{pmatrix}
{RA}&{RB}\\
{C}&{D}
\end{pmatrix}
\]
при этом
\[
\begin{pmatrix}
{R}&{0}\\
{0}&{E}
\end{pmatrix}^{-1}
=
\begin{pmatrix}
{R^{-1}}&{0}\\
{0}&{E}
\end{pmatrix}
\]
Аналогично, для обратимой матрицы $T\in\Matrix{k}$, преобразование
\[
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}
\mapsto
\begin{pmatrix}
{AT}&{B}\\
{CT}&{D}
\end{pmatrix}
\]
является преобразованием умножения на обратимую матрицу справа, а именно
\[
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}
\begin{pmatrix}
{T}&{0}\\
{0}&{E}
\end{pmatrix}
=
\begin{pmatrix}
{AT}&{B}\\
{CT}&{D}
\end{pmatrix}
\]
Как и раньше, при работе со строками умножение на матрицу-коэффициент происходит слева, а при работе со столбцами -- справа.


\subsection{Массовое решение систем}

Пусть нам надо решить сразу несколько систем $Ax_1 = b_1$, \ldots, $Ax_k = b_k$, где $A\in \MatrixDim{m}{n}$, $b_i\in \Vector{m}$ и $x_i\in \Vector{n}$.
Определим матрицы $X = (x_1|\ldots|x_k)\in \MatrixDim{n}{k}$ и $B = (b_1|\ldots|b_k)\in \MatrixDim{m}{k}$ составленные из столбцов $x_i$ и $b_i$ соответственно.
Тогда по формулам блочного умножения матриц
\[
AX = A(x_1|\ldots|x_k) = (Ax_1|\ldots|Ax_k) = (b_1|\ldots|b_k) = B
\]
То есть массовое решение системы уравнений равносильно решению матричного уравнения $AX = B$.

\paragraph{Решение матричных уравнений}

\paragraph{Дано}

$A\in \MatrixDim{m}{n}$, $B\in \MatrixDim{m}{k}$.

\paragraph{Задача}

Найти $X\in \MatrixDim{n}{k}$ такую, что $AX = B$.

\paragraph{Алгоритм}

\begin{enumerate}
\item Составить расширенную матрицу $(A|B)$.
Например, если $A\in \MatrixDim{3}{3}$, а $B\in \MatrixDim{3}{2}$, то получим
\[
(A|B) = 
\left(
\left.
\begin{matrix}
{a_{11}}&{a_{12}}&{a_{13}}\\
{a_{21}}&{a_{22}}&{a_{23}}\\
{a_{31}}&{a_{32}}&{a_{33}}\\
\end{matrix}
\:\right|\:
\begin{matrix}
{b_{11}}&{b_{12}}\\
{b_{21}}&{b_{22}}\\
{b_{31}}&{b_{32}}\\
\end{matrix}
\right)
\]

\item Привести расширенную матрицу $(A|B)$ к улучшенному ступенчатому виду.
В примере выше, может получиться
\[
\left(
\left.
\begin{matrix}
{1}&{a_{12}}&{0}\\
{0}&{0}&{1}\\
{0}&{0}&{0}\\
\end{matrix}
\:\right|\:
\begin{matrix}
{b_{11}}&{0}\\
{b_{21}}&{0}\\
{0}&{1}\\
\end{matrix}
\right)\text{ или }
\left(
\left.
\begin{matrix}
{1}&{0}&{a_{13}}\\
{0}&{1}&{a_{23}}\\
{0}&{0}&{0}\\
\end{matrix}
\:\right|\:
\begin{matrix}
{b_{11}}&{b_{12}}\\
{b_{21}}&{b_{22}}\\
{0}&{0}\\
\end{matrix}
\right)
\]

\item Для каждого столбца матрицы $X$ выразить его главные переменные через свободные и записать ответ в виде матрицы.
Если для какого-то столбца решений  нет, то нет решений и у матричного уравнения $AX = B$.
В примере выше, в первом случае нет решения для второго столбца, потому решений нет в этом случае.
Во втором случае, 
\[
X = 
\begin{pmatrix}
{b_{11}}&{b_{12}}\\
{b_{21}}&{b_{22}}\\
{0}&{0}\\
\end{pmatrix}
+
\begin{pmatrix}
{-a_{13}}\\{-a_{23}}\\{1}
\end{pmatrix}
\begin{pmatrix}
{t}&{u}
\end{pmatrix},\text{ где } t,u\in \mathbb R
\]
\end{enumerate}

Если нужно решить матричное уравнение $XA = B$ для матриц соответствующего размера, то можно его транспонировать и свести задачу к рассмотренной.
А именно, это уравнение равносильно уравнению $A^t X^t = B^t$.
Тогда его можно решать относительно $X^t$, а потом транспонировать ответ.

\paragraph{Нахождение обратной матрицы методом Гаусса}

\paragraph{Дано}

Матрица $A\in \Matrix{n}$.

\paragraph{Задача}

Понять обратима ли матрица $A$ и если она обратима, то найти ее обратную $A^{-1}$.

\paragraph{Алгоритм} 

\begin{enumerate}
\item Нам надо по сути решить систему $AX = E$, где $E$ -- единичная матрица.
Потому составим расширенную матрицу системы $(A|E)$.

\item Приведем эту матрицу к улучшенному ступенчатому виду.

\item В результате возможны $2$ случая:
\begin{enumerate}
\item После приведения получили матрицу $(E|B)$.
Тогда $A$ обратима и $A^{-1} = B$.

\item После приведения получили матрицу $(D|B)$ и у матрицы $D$ есть свободные позиции.
Тогда матрица $A$ не обратима.
\end{enumerate}
\end{enumerate}
Заметим, что если в процессе алгоритма, мы слева от черты в расширенной матрице нашли свободную переменную, то на этом можно остановиться -- матрица $A$ необратима.

\paragraph{Корректность алгоритма}

Давайте я поясню почему алгоритм работает корректно.
Пусть у нас есть система $AX  = B$ с краткой записью $(A|B)$.
Если мы применим элементарное преобразование строк к краткой записи, то это будет означать умножение на матрицу элементарного преобразования слева, то есть при переходе $(A|B)\mapsto (UA|UB)$ мы меняем систему $AX = B$ на $UAX = UB$.
А значит, если матрица $X$ была решением $AX = B$, то мы имеем верное равенство двух матриц $AX = B$.
Если две одинаковые матрицы слева домножить на одну и ту же матрицу, то результат получится равным, то есть отсюда следует, что $UAX = UB$.
То есть любое решение системы $AX = B$ превращается в решение системы $UAX = UB$.
Так как матрица элементарного преобразования $U$ обратима, то мы можем домножить второе на $U^{-1}$, а значит работает рассуждение в обратную сторону и все решения второй являются решениями первой.

Теперь мы знаем, что меняя по алгоритму систему, мы не меняем множество решений.
Кроме того, по алгоритму, у нас в результате работы бывают две ситуации, либо мы приходим к ситуации $(E|B)$ либо к $(D|B)$ и в $D$ есть свободная позиция.
Давайте разберем их отдельно.
\begin{enumerate}
\item Пусть мы привели систему к виду $(E|B)$.
Эта запись соответствует системе $E X = B$, то есть $X = B$.
Более того, полученная система эквивалента исходное $AX = E$.
Теперь мы видим, что у системы $X = B$ единственное решение $B$, а это значит что и у системы $AX = E$ единственное решение $B$ (так как они эквивалентны).
А значит в этом случае $B$ -- это правая обратная к $A$, а следовательно и просто обратная.

\item Теперь предположим, что мы получим $(D|B)$, где у $D$ есть свободная переменная.
Так как мы переходили от $(A|E)$ к $(D|B)$ элементарными преобразованиями строк, то для некоторой обратимой матрицы $C\in \Matrix{n}$ выполнено $D = CA$.
Так как у матрицы $D$ есть свободная позиция и она квадратная~%
\footnote{Вот то место, где мы пользуемся квадратностью матрицы.},
то обязательно найдется нулевая строка.
А раз так, то матрица $D$ не может быть обратима справа.
Действительно, тогда в произведении $D R$ для любой $R\in \Matrix{n}$ будет иметь нулевую строку там же, где нулевая строка у $D$.
А значит, не может быть $E$.
Раз матрица $D$ не обратима, то и матрица $A$ не обратима, иначе $D$ была бы обратима, как произведение обратимых матриц.
\end{enumerate}

\subsection{Классификация СЛУ}

\paragraph{Единственность улучшенного ступенчатого вида}

Давайте в начале ответим на очень важный вопрос: а единственный ли у матрицы улучшенный ступенчатый вид?
Очевидно, что ступенчатый вид не единственный.
Однако, улучшенный ступенчатый вид окажется однозначно определенным.
Это означает, что у ступенчатого вида однозначно определена его форма (количество и длины ступенек).
В частности у любой СЛУ однозначно определены главные и свободные переменные.
Все это не бросается сразу в глаза и требует доказательства.
Давайте начнем со сравнения ступенчатых видов.

\begin{claim}
Пусть $A\in\MatrixDim{m}{n}$ и $B\in\MatrixDim{k}{n}$ -- матрицы в ступенчатом виде и системы $Ax = 0$ и $Bx = 0$ эквивалентны.%
\footnote{То есть имеют одинаковое множество решений.}
Тогда набор главных и свободных переменных у этих систем совпадает.
\end{claim}
\begin{proof}

Пусть $E_A, E_B\subseteq \mathbb R^n$ -- множества решений систем $Ax = 0$ и $Bx = 0$, соответственно.
Теперь для системы $Ax = 0$ и номера $1\leqslant i \leqslant n$ введем следующее свойство 
\[
P_i(A) = \text{<<Для любого решения $x\in E_A$ из условия $x_{i+1} = \ldots = x_n = 0$ следует, что $x_i = 0$.>>}
\]
Я утверждаю, что свойство $P_i(A)$ выполнено тогда и только тогда, когда $x_i$ является главное переменной для $Ax = 0$.
Если это так, то отсюда следует наше утверждение.
Действительно, так как системы $Ax = 0$ и $Bx = 0$ имеет одинаковое множество решений, то и свойство $P_i(A)$ выполняется тогда и только тогда, когда выполняется свойство $P_i(B)$.
Значит множество главных переменных совпадает, и как следствие совпадает множество свободных переменных.

Теперь докажем требуемое перебором.
Пусть $x_i$ является главной переменной для $Ax = 0$.
Рассмотрим множество
\[
E_A^0 = \{x\in E_A\mid x_k = 0\text{ при }k>i\}
\]
Но в ступенчатом виде переменная $x_i$ выражается через переменные с более высоким индексом, раз все переменные правее равны нулю, то и $x_i = 0$.
То есть для главное переменной свойство выполняется.

Теперь покажем, что если $x_i$ свободная, то можно предъявить решение $x\in E_A^0$ такое, что $ x_i \neq 0$.
Действительно, зададим все свободные переменные кроме $x_i$ нулями, а $x_i = 1$.
Тогда главные восстанавливаются однозначно по свободным и мы получим какое-то решение $x$.
По построению $x_i\neq 0$.
И надо лишь проверить, что $x_{i+1} = \ldots = x_n = 0$.
Действительно, все свободные переменные правее $x_i$ заданы нулями.
Но все главные переменные правее $x_i$ зависят от еще более правых переменных, то есть они то же должны быть нулями, что и требовалось.
\end{proof}


\begin{claim}
Пусть $S_1\in\MatrixDim{m}{n}$ и $S_2\in\MatrixDim{k}{n}$ -- произвольные матрицы в улучшенном ступенчатом виде.
Если $S_1x = 0$ эквивалентно $S_2x=0$, то после удаления нулевых строк матрицы $S_1$ и $S_2$ совпадут.
\end{claim}
\begin{proof}
Из предыдущего утверждения мы уже знаем, что у систем $S_1x = 0$ и $S_2 x = 0$ одинаковый набор главных и свободных переменных.
То есть у них одинаковая ступенчатая форма и надо лишь показать, что ненулевые числа в ней одинаковые.
Пусть для определенности матрицы $S_1$  и $S_2$ имеют следующий вид:
\[
S_1 = 
\begin{pmatrix}
{1}&{*}&{0}&{*}&{0}&{0}&{*}&{*}&{*}\\
{}&{}&{1}&{*}&{0}&{0}&{*}&{*}&{*}\\
{}&{}&{}&{}&{1}&{0}&{*}&{*}&{*}\\
{}&{}&{}&{}&{}&{1}&{*}&{*}&{*}\\
\end{pmatrix}\quad
S_2 = 
\begin{pmatrix}
{1}&{\bullet}&{0}&{\bullet}&{0}&{0}&{\bullet}&{\bullet}&{\bullet}\\
{}&{}&{1}&{\bullet}&{0}&{0}&{\bullet}&{\bullet}&{\bullet}\\
{}&{}&{}&{}&{1}&{0}&{\bullet}&{\bullet}&{\bullet}\\
{}&{}&{}&{}&{}&{1}&{\bullet}&{\bullet}&{\bullet}\\
\end{pmatrix}
\]
Теперь для каждого свободного столбца покажем, что они совпадают.
Рассмотрим произвольный $i$-ый свободный столбец
\[
S_1 = 
\begin{pmatrix}
{1}&{*}&{0}&{*}&{0}&{0}&{a_1}&{*}&{*}\\
{}&{}&{1}&{*}&{0}&{0}&{a_2}&{*}&{*}\\
{}&{}&{}&{}&{1}&{0}&{a_3}&{*}&{*}\\
{}&{}&{}&{}&{}&{1}&{a_4}&{*}&{*}\\
\end{pmatrix}\quad
S_2 = 
\begin{pmatrix}
{1}&{\bullet}&{0}&{\bullet}&{0}&{0}&{b_1}&{\bullet}&{\bullet}\\
{}&{}&{1}&{\bullet}&{0}&{0}&{b_2}&{\bullet}&{\bullet}\\
{}&{}&{}&{}&{1}&{0}&{b_3}&{\bullet}&{\bullet}\\
{}&{}&{}&{}&{}&{1}&{b_4}&{\bullet}&{\bullet}\\
\end{pmatrix}
\]
Давайте построим решение системы $S_1 x = 0$, где все свободные переменные кроме $x_i$ равны нулю, а $x_i = 1$.
Тогда получится одно единственное решение вида%
\footnote{Тут красным обозначены значения главных переменных, а синим -- свободных.}
\[
({\color{red} -a_1}, {\color{blue} 0}, {\color{red} -a_2}, {\color{blue} 0}, {\color{red} -a_3}, {\color{red} -a_4}, {\color{blue} 1}, {\color{blue} 0}, {\color{blue} 0})
\]
С другой стороны, давайте построим решение системы $S_2 x = 0$, где все свободные переменные кроме $x_i$ равны нулю, а $x_i = 1$.
Тогда получится одно единственное решение вида
\[
({\color{red} -b_1}, {\color{blue} 0}, {\color{red} -b_2}, {\color{blue} 0}, {\color{red} -b_3}, {\color{red} -b_4}, {\color{blue} 1}, {\color{blue} 0}, {\color{blue} 0})
\]
Так как эти системы эквивалентны, то оба решения являются решениями, например, $S_1x = 0$.
А раз это решения одной системы с одинаковыми значениями свободных переменных, то и значения главных будут совпадать.
А это и значит, что $i$-ые столбцы в системах $S_1$ и $S_2$ будут одинаковые.
\end{proof}

Из этого утверждения следует, что матрица улучшенного ступенчатого вида для любой матрицы $A\in\MatrixDim{m}{n}$ определена однозначно.
Так как если матрица $A$ приводится к двум разным ступенчатым видам, то их однородные системы эквивалентны, а значит они совпадают.
Потому, говоря о матрице $A$, можно говорить и о ее улучшенном ступенчатом виде без какой-либо неоднозначности.

\paragraph{Классификация}

\begin{claim}
Пусть $A,B\in\MatrixDim{m}{n}$ и пусть $E_A, E_B\subseteq \mathbb R^n$ -- множества решений систем $Ax = 0$ и $Bx = 0$, соответственно.
Тогда следующее эквивалентно:
\begin{enumerate}
\item $E_A = E_B$, т.е. системы эквивалентны.

\item $A$ приводится к $B$ элементарными преобразованиями строк.

\item Существует обратимая $C\in\Matrix{m}$ такая, что $B = CA$.

\item Матрица улучшенного ступенчатого вида для $A$ совпадает с матрицей улучшенного ступенчатого вида для $B$.
\end{enumerate}
\end{claim}

