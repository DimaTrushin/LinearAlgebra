\ProvidesFile{lecture03.tex}[Лекция 3]


\paragraph{Делители нуля}

Пусть $A\in\Matrix{n}$ -- некоторая ненулевая матрица и пусть $B\in\MatrixDim{n}{m}$.
Матрица $B$ называется правым делителем нуля для $A$, если $AB = 0$.
Условие~(1) предыдущего утверждения эквивалентно отсутствию правых делителей нуля.
Условие~(1) не сильнее, значит надо показать, что оно влечет отсутствие делителей нуля.
Если $B$ -- правый делитель нуля для $A$, то любой столбец $b$ матрицы $B$ удовлетворяет условию $Ab = 0$, а значит нулевой.

Аналогично определяются левые делители нуля для $A$ и показывается, что их отсутствие равносильно условию~(2) предыдущего результата.

\paragraph{Элементарные преобразования и обратимость}

Пусть $A\in\MatrixDim{m}{n}$ и $b\in\mathbb R^m$.
Тогда у нас есть две процедуры преобразования СЛУ $Ax = b$:
\begin{enumerate}
\item Применение элементарных преобразований к строкам системы.

\item Умножение обеих частей равенства на обратимую матрицу: $Ax=b$ меняем на $CAx = Cb$, где $C\in\Matrix{n}$ -- обратимая.
\end{enumerate}

Так как любое элементарное преобразование сводится к умножению слева на обратимую матрицу, то мы видим, что первый вид модификации систем является частным случаем второго.
В обратную сторону, из доказанного утверждения следует, что любая обратимая матрица может быть расписана как произведение матриц элементарных преобразований.
Значит, умножить на обратимую матрицу слева -- это все равно что сделать последовательность элементарных преобразований.

Главный плюс элементарных преобразований -- у них простые матрицы, а минус -- их нужно много, очень много, чтобы преобразовать одну систему в другую.
С обратимыми матрицами все наоборот: сами матрицы устроены непонятно как, но зато нужно всего одно умножение матриц, чтобы перевести систему из одной в другую.
Именно на это надо обращать внимание при выборе подхода по преобразованию систем.


\paragraph{Насыщенность обратимых}

Я хочу продемонстрировать еще одно полезное следствие из Утверждения~\ref{claim::InvertibleDiscription}.
Предположим у нас есть две матрицы $A, B\in \Matrix{n}$.
Тогда $AB$ обратима тогда и только тогда, когда $A$ и $B$ обратимы.
Действительно, справа налево мы уже знаем, обратимость обеих матриц $A$ и $B$ влечет обратимость произведения, мы даже знаем, что при этом $(AB)^{-1} = B^{-1}A^{-1}$.
Надо лишь показать в обратную сторону.
Предположим, что $AB$ обратима, это значит, что для некоторой матрицы $D\in \Matrix{n}$ выполнено
\[
ABD = E\quad\text{и}\quad DAB = E
\]
Тогда первое равенство говорит, что $BD$ является правым обратным к $A$.
А в силу эквивалентности пунктов~(4) и~(6) Утверждения~\ref{claim::InvertibleDiscription} это означает, что $A$ обратима.
Аналогично, $DA$ является левым обратным к $B$ и в силу эквивалентности пунктов~(4) и~(5) Утверждения~\ref{claim::InvertibleDiscription}, матрица $B$ обратима.
Так что произведение матриц обратимо тогда и только тогда, когда каждый сомножитель обратим.

\subsection{Блочное умножение матриц}

\paragraph{Формулы блочного умножения}

Пусть даны две матрицы, которые разбиты на блоки как показано ниже:
\[
\begin{matrix}
{}&{
\begin{matrix}
{k}&{s}
\end{matrix}}\\
{
\begin{matrix}
{m}\\
{n}
\end{matrix}}&{
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}}
\end{matrix}
\quad\quad
\begin{matrix}
{}&{
\begin{matrix}
{u}&{v}
\end{matrix}}\\
{
\begin{matrix}
{k}\\
{s}
\end{matrix}}&{
\begin{pmatrix}
{X}&{Y}\\
{W}&{Z}
\end{pmatrix}}
\end{matrix}
\]
Числа $m$, $n$, $k$, $s$, $u$, $v$ -- размеры соответствующих блоков.
Наша цель понять, что эти матрицы можно перемножать блочно.
А именно, увидеть, что результат умножения этих матриц имеет вид
\[
\begin{matrix}
{}&{
u\quad\quad\quad\quad\quad v
}\\
{
\begin{matrix}
{m}\\
{n}
\end{matrix}}&{
\begin{pmatrix}
{A X + B W}&{A Y + B Z}\\
{C X + D W}&{C Y + D Z}
\end{pmatrix}}
\end{matrix}
\]
Делается это таким трюком.
В начале заметим, что
\[
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}
=
\begin{pmatrix}
{A}&{0}\\
{0}&{0}
\end{pmatrix}
+
\begin{pmatrix}
{0}&{B}\\
{0}&{0}
\end{pmatrix}
+
\begin{pmatrix}
{0}&{0}\\
{C}&{0}
\end{pmatrix}
+
\begin{pmatrix}
{0}&{0}\\
{0}&{D}
\end{pmatrix}
\]
После чего методом <<пристального взгляда>> перемножаем матрицы с большим количеством нулей (попробуйте проделать это!).

На этот факт можно смотреть вот как.
Матрица -- это прямоугольная таблица заполненная числами.
А можно составлять прямоугольные таблица заполненные другими объектами, например матрицами.
Тогда они складываются и перемножаются так же как и обычные матрицы из чисел.
Единственное надо учесть, что в блочном умножении есть разница между $AX + BW$ и $XA + BW$, так как $A$, $B$, $X$ и $W$ не числа, а матрицы, то их нельзя переставлять местами, порядок теперь важен.

Вот полезный пример.
Пусть дана матрица из $\Matrix{n+1}$ вида
\[
\begin{pmatrix}
{A}&{v}\\
{0}&{\lambda}
\end{pmatrix},
\quad\text{где}\quad
A\in\Matrix{n},\quad
v\in\Vector{n},\quad
\lambda\in\mathbb R
\]
Тогда
\[
\begin{pmatrix}
{A}&{v}\\
{0}&{\lambda}
\end{pmatrix}
\begin{pmatrix}
{A}&{v}\\
{0}&{\lambda}
\end{pmatrix}
=
\begin{pmatrix}
{A^2}&{Av + v\lambda}\\
{0}&{\lambda^2}
\end{pmatrix}
=
\begin{pmatrix}
{A^2}&{Av + \lambda v}\\
{0}&{\lambda^2}
\end{pmatrix}
=
\begin{pmatrix}
{A^2}&{(A + \lambda E) v}\\
{0}&{\lambda^2}
\end{pmatrix}
\]
Предпоследнее равенство верно, так как не важно с какой стороны умножать $v$ на скаляр $\lambda$.

Вот еще один полезный пример блочного умножения.
Пусть $x_1,\ldots,x_m\in \Vector{n}$ и $y_1,\ldots,y_m\in\Vector{n}$ -- столбцы.
Составим из этих столбцов матрицы $X =(x_1|\ldots|x_m)$ и $Y = (y_1|\ldots|y_m)$.%
\footnote{Данная запись означает, что мы берем столбцы $x_i$ и записываем их подряд в одну большую таблицу.}
Заметим, что $X,Y \in \MatrixDim{n}{m}$.
Тогда
\[
XY^t = (x_1|\ldots|x_m)(y_1|\ldots|y_m)^t = \sum_{i=1}^m x_iy_i^t
\]

\subsection{Блочные элементарные преобразования}

\paragraph{Преобразования первого типа}

Пусть у нас дана матрица
\[
\begin{matrix}
{}&{
\begin{matrix}
{k}&{s}
\end{matrix}}\\
{
\begin{matrix}
{m}\\
{n}
\end{matrix}}&{
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}}
\end{matrix}
\]
Я хочу взять первую <<строку>> из матриц $(A, B)$ умножить ее на некую матрицу $R$ слева и прибавить результат к <<строке>> $(C, D)$.
Для этого матрица $R$ должна иметь $n$ строк и $m$ столбцов.
То есть процедура будет выглядеть следующим образом
\[
\begin{matrix}
{}&{
\begin{matrix}
{k}&{s\phantom{dd}}
\end{matrix}}\\
{
\begin{matrix}
{m}\\
{n}
\end{matrix}}&{
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}\mapsto}
\end{matrix}
\begin{matrix}
{
\begin{matrix}
{k\phantom{dddddd}}&{s}
\end{matrix}
}&{
}\\
{
\begin{pmatrix}
{A}&{B}\\
{C+RA}&{D+RB}
\end{pmatrix}
}&{
\begin{matrix}
{m}\\
{n}
\end{matrix}
}
\end{matrix}
\]
Оказывается, что такая процедура является умножением на обратимую матрицу слева, а именно
\[
\begin{matrix}
{}&{
\begin{matrix}
{m}&{n}
\end{matrix}}\\
{
\begin{matrix}
{m}\\
{n}
\end{matrix}}&{
\begin{pmatrix}
{E}&{0}\\
{R}&{E}
\end{pmatrix}}
\end{matrix}
\;
\begin{matrix}
{
\begin{matrix}
{k}&{s}
\end{matrix}
}&{
}\\
{
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}
}&{
\begin{matrix}
{m}\\
{n}
\end{matrix}
}
\end{matrix}
\;\;
\begin{matrix}
{
\begin{matrix}
{\phantom{dd}k\phantom{dddddd}}&{s}
\end{matrix}
}&{
}\\
{
=
\begin{pmatrix}
{A}&{B}\\
{C+RA}&{D+RB}
\end{pmatrix}
}&{
\begin{matrix}
{m}\\
{n}
\end{matrix}
}
\end{matrix}
\]
Заметим, что
\[
\begin{pmatrix}
{E}&{0}\\
{R}&{E}
\end{pmatrix}^{-1}
=
\begin{pmatrix}
{E}&{0}\\
{-R}&{E}\\
\end{pmatrix}
\]
В частности из этого наблюдения следует, что блочные элементарные преобразования строк не меняют множества решений соответствующей системы.

Аналогично можно делать блочные элементарные преобразования столбцов.
А именно
\[
\begin{matrix}
{}&{
\begin{matrix}
{k}&{s\phantom{dd}}
\end{matrix}}\\
{
\begin{matrix}
{m}\\
{n}
\end{matrix}}&{
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}\mapsto}
\end{matrix}
\begin{matrix}
{
\begin{matrix}
{k}&{\phantom{ddd}s\phantom{dd}}
\end{matrix}
}&{
}\\
{
\begin{pmatrix}
{A}&{B + AT}\\
{C}&{D + CT}
\end{pmatrix}
}&{
\begin{matrix}
{m}\\
{n}
\end{matrix}
}
\end{matrix}
\]
где $T$ матрица с $k$ строками и $s$ столбцами.
Как и в случае преобразований со строками, эта процедура сводится к операции умножения на обратимую матрицу справа
\[
\begin{matrix}
{}&{
\begin{matrix}
{k}&{s}
\end{matrix}}\\
{
\begin{matrix}
{m}\\
{n}
\end{matrix}}&{
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}}
\end{matrix}
\;
\begin{matrix}
{
\begin{matrix}
{k}&{s}
\end{matrix}
}&{
}\\
{
\begin{pmatrix}
{E}&{T}\\
{0}&{E}
\end{pmatrix}
}&{
\begin{matrix}
{k}\\
{s}
\end{matrix}
}
\end{matrix}
\;\;
\begin{matrix}
{
\begin{matrix}
{\phantom{d}k}&{\phantom{ddd}s\phantom{dd}}
\end{matrix}
}&{
}\\
{
=
\begin{pmatrix}
{A}&{B + AT}\\
{C}&{D + CT}
\end{pmatrix}
}&{
\begin{matrix}
{m}\\
{n}
\end{matrix}
}
\end{matrix}
\]
Как и раньше
\[
\begin{pmatrix}
{E}&{T}\\
{0}&{E}
\end{pmatrix}^{-1}
=
\begin{pmatrix}
{E}&{-T}\\
{0}&{E}
\end{pmatrix}
\]

\paragraph{Замечание}

Обратите внимание, что при блочных преобразованиях строк умножение на матрицу-коэффициент $R$ происходит слева, а при преобразованиях столбцов умножение на матрицу-коэффициент $T$ происходит справа.

\paragraph{Преобразования второго типа}

Преобразование вида
\[
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}
\mapsto
\begin{pmatrix}
{C}&{D}\\
{A}&{B}
\end{pmatrix}
\]
сводится к умножению на обратимую блочную матрицу слева
\[
\begin{pmatrix}
{0}&{E}\\
{E}&{0}
\end{pmatrix}
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}
=
\begin{pmatrix}
{C}&{D}\\
{A}&{B}
\end{pmatrix}
\]
А преобразование
\[
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}
\mapsto
\begin{pmatrix}
{B}&{A}\\
{D}&{C}
\end{pmatrix}
\]
сводится к умножению на обратимую блочную матрицу справа
\[
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}
\begin{pmatrix}
{0}&{E}\\
{E}&{0}
\end{pmatrix}
=
\begin{pmatrix}
{B}&{A}\\
{D}&{C}
\end{pmatrix}
\]
При этом
\[
\begin{pmatrix}
{0}&{E}\\
{E}&{0}
\end{pmatrix}^{-1}
=
\begin{pmatrix}
{0}&{E}\\
{E}&{0}
\end{pmatrix}
\]

\paragraph{Преобразования третьего типа}

Если $R\in \Matrix{m}$ -- обратимая матрица, то
\[
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}
\mapsto
\begin{pmatrix}
{RA}&{RB}\\
{C}&{D}
\end{pmatrix}
\]
является преобразованием умножения на обратимую матрицу слева, а именно
\[
\begin{pmatrix}
{R}&{0}\\
{0}&{E}
\end{pmatrix}
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}
=
\begin{pmatrix}
{RA}&{RB}\\
{C}&{D}
\end{pmatrix}
\]
при этом
\[
\begin{pmatrix}
{R}&{0}\\
{0}&{E}
\end{pmatrix}^{-1}
=
\begin{pmatrix}
{R^{-1}}&{0}\\
{0}&{E}
\end{pmatrix}
\]
Аналогично, для обратимой матрицы $T\in\Matrix{k}$, преобразование
\[
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}
\mapsto
\begin{pmatrix}
{AT}&{B}\\
{CT}&{D}
\end{pmatrix}
\]
является преобразованием умножения на обратимую матрицу справа, а именно
\[
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}
\begin{pmatrix}
{T}&{0}\\
{0}&{E}
\end{pmatrix}
=
\begin{pmatrix}
{AT}&{B}\\
{CT}&{D}
\end{pmatrix}
\]
Как и раньше, при работе со строками умножение на матрицу-коэффициент происходит слева, а при работе со столбцами -- справа.


\subsection{Массовое решение систем}

Пусть нам надо решить сразу несколько систем $Ax_1 = b_1$, \ldots, $Ax_k = b_k$, где $A\in \MatrixDim{m}{n}$, $b_i\in \Vector{m}$ и $x_i\in \Vector{n}$.
Определим матрицы $X = (x_1|\ldots|x_k)\in \MatrixDim{n}{k}$ и $B = (b_1|\ldots|b_k)\in \MatrixDim{m}{k}$ составленные из столбцов $x_i$ и $b_i$ соответственно.
Тогда по формулам блочного умножения матриц
\[
AX = A(x_1|\ldots|x_k) = (Ax_1|\ldots|Ax_k) = (b_1|\ldots|b_k) = B
\]
То есть массовое решение системы уравнений равносильно решению матричного уравнения $AX = B$.

\paragraph{Решение матричных уравнений}

\paragraph{Дано}

$A\in \MatrixDim{m}{n}$, $B\in \MatrixDim{m}{k}$.

\paragraph{Задача}

Найти $X\in \MatrixDim{n}{k}$ такую, что $AX = B$.

\paragraph{Алгоритм}

\begin{enumerate}
\item Составить расширенную матрицу $(A|B)$.
Например, если $A\in \MatrixDim{3}{3}$, а $B\in \MatrixDim{3}{2}$, то получим
\[
(A|B) = 
\left(
\left.
\begin{matrix}
{a_{11}}&{a_{12}}&{a_{13}}\\
{a_{21}}&{a_{22}}&{a_{23}}\\
{a_{31}}&{a_{32}}&{a_{33}}\\
\end{matrix}
\:\right|\:
\begin{matrix}
{b_{11}}&{b_{12}}\\
{b_{21}}&{b_{22}}\\
{b_{31}}&{b_{32}}\\
\end{matrix}
\right)
\]

\item Привести расширенную матрицу $(A|B)$ к улучшенному ступенчатому виду.
В примере выше, может получиться
\[
\left(
\left.
\begin{matrix}
{1}&{a_{12}}&{0}\\
{0}&{0}&{1}\\
{0}&{0}&{0}\\
\end{matrix}
\:\right|\:
\begin{matrix}
{b_{11}}&{0}\\
{b_{21}}&{0}\\
{0}&{1}\\
\end{matrix}
\right)\text{ или }
\left(
\left.
\begin{matrix}
{1}&{0}&{a_{13}}\\
{0}&{1}&{a_{23}}\\
{0}&{0}&{0}\\
\end{matrix}
\:\right|\:
\begin{matrix}
{b_{11}}&{b_{12}}\\
{b_{21}}&{b_{22}}\\
{0}&{0}\\
\end{matrix}
\right)
\]

\item Для каждого столбца матрицы $X$ выразить его главные переменные через свободные и записать ответ в виде матрицы.
Если для какого-то столбца решений  нет, то нет решений и у матричного уравнения $AX = B$.
В примере выше, в первом случае нет решения для второго столбца, потому решений нет в этом случае.
Во втором случае, 
\[
X = 
\begin{pmatrix}
{b_{11}}&{b_{12}}\\
{b_{21}}&{b_{22}}\\
{0}&{0}\\
\end{pmatrix}
+
\begin{pmatrix}
{-a_{13}}\\{-a_{23}}\\{1}
\end{pmatrix}
\begin{pmatrix}
{t}&{u}
\end{pmatrix},\text{ где } t,u\in \mathbb R
\]
\end{enumerate}

Если нужно решить матричное уравнение $XA = B$ для матриц соответствующего размера, то можно его транспонировать и свести задачу к рассмотренной.
А именно, это уравнение равносильно уравнению $A^t X^t = B^t$.
Тогда его можно решать относительно $X^t$, а потом транспонировать ответ.

\paragraph{Нахождение обратной матрицы методом Гаусса}

\paragraph{Дано}

Матрица $A\in \Matrix{n}$.

\paragraph{Задача}

Понять обратима ли матрица $A$ и если она обратима, то найти ее обратную $A^{-1}$.

\paragraph{Алгоритм} 

\begin{enumerate}
\item Нам надо по сути решить систему $AX = E$, где $E$ -- единичная матрица.
Потому составим расширенную матрицу системы $(A|E)$.

\item Приведем эту матрицу к улучшенному ступенчатому виду.

\item В результате возможны $2$ случая:
\begin{enumerate}
\item После приведения получили матрицу $(E|B)$.
Тогда $A$ обратима и $A^{-1} = B$.

\item После приведения получили матрицу $(D|B)$ и у матрицы $D$ есть свободные позиции.
Тогда матрица $A$ не обратима.
\end{enumerate}
\end{enumerate}
Заметим, что если в процессе алгоритма, мы слева от черты в расширенной матрице нашли свободную переменную, то на этом можно остановиться -- матрица $A$ необратима.

\paragraph{Корректность алгоритма}

Давайте я поясню почему алгоритм работает корректно.
Пусть у нас есть система $AX  = B$ с краткой записью $(A|B)$.
Если мы применим элементарное преобразование строк к краткой записи, то это будет означать умножение на матрицу элементарного преобразования слева, то есть при переходе $(A|B)\mapsto (UA|UB)$ мы меняем систему $AX = B$ на $UAX = UB$.
А значит, если матрица $X$ была решением $AX = B$, то мы имеем верное равенство двух матриц $AX = B$.
Если две одинаковые матрицы слева домножить на одну и ту же матрицу, то результат получится равным, то есть отсюда следует, что $UAX = UB$.
То есть любое решение системы $AX = B$ превращается в решение системы $UAX = UB$.
Так как матрица элементарного преобразования $U$ обратима, то мы можем домножить второе на $U^{-1}$, а значит работает рассуждение в обратную сторону и все решения второй являются решениями первой.

Теперь мы знаем, что меняя по алгоритму систему, мы не меняем множество решений.
Кроме того, по алгоритму, у нас в результате работы бывают две ситуации, либо мы приходим к ситуации $(E|B)$ либо к $(D|B)$ и в $D$ есть свободная позиция.
Давайте разберем их отдельно.
\begin{enumerate}
\item Пусть мы привели систему к виду $(E|B)$.
Эта запись соответствует системе $E X = B$, то есть $X = B$.
Более того, полученная система эквивалента исходное $AX = E$.
Теперь мы видим, что у системы $X = B$ единственное решение $B$, а это значит что и у системы $AX = E$ единственное решение $B$ (так как они эквивалентны).
А значит в этом случае $B$ -- это правая обратная к $A$, а следовательно и просто обратная.

\item Теперь предположим, что мы получим $(D|B)$, где у $D$ есть свободная переменная.
Так как мы переходили от $(A|E)$ к $(D|B)$ элементарными преобразованиями строк, то для некоторой обратимой матрицы $C\in \Matrix{n}$ выполнено $D = CA$.
Так как у матрицы $D$ есть свободная позиция и она квадратная~%
\footnote{Вот то место, где мы пользуемся квадратностью матрицы.},
то обязательно найдется нулевая строка.
А раз так, то матрица $D$ не может быть обратима справа.
Действительно, тогда в произведении $D R$ для любой $R\in \Matrix{n}$ будет иметь нулевую строку там же, где нулевая строка у $D$.
А значит, не может быть $E$.
Раз матрица $D$ не обратима, то и матрица $A$ не обратима, иначе $D$ была бы обратима, как произведение обратимых матриц.
\end{enumerate}

\subsection{Классификация СЛУ}

\paragraph{Единственность улучшенного ступенчатого вида}

Давайте в начале ответим на очень важный вопрос: а единственный ли у матрицы улучшенный ступенчатый вид?
Очевидно, что ступенчатый вид не единственный.
Однако, улучшенный ступенчатый вид окажется однозначно определенным.
Это означает, что у ступенчатого вида однозначно определена его форма (количество и длины ступенек).
В частности у любой СЛУ однозначно определены главные и свободные переменные.
Все это не бросается сразу в глаза и требует доказательства.
Давайте начнем с простого наблюдения.

\begin{claim}
Пусть $A\in\MatrixDim{m}{n}$ и $B\in\MatrixDim{k}{n}$ -- матрицы в ступенчатом виде, причем $B$ получена из $A$ выкидыванием одного ненулевого уравнения.
Тогда системы $Ax = 0$ и $Bx = 0$ не эквивалентны.%
\footnote{То есть имеют разное множество решений.}
\end{claim}
\begin{proof}
Пусть для определенности $A$ и $B$ имеют следующий вид (все незаполненные места предполагаются нулями):
\[
A = 
\begin{matrix}
{k\quad\quad\quad\quad\;}\\
\begin{pmatrix}
{*}&{*}&{*}&{*}&{*}&{*}&{*}&{*}\\
{}&{}&{*}&{*}&{*}&{*}&{*}&{*}\\
{}&{}&{}&{}&{*}&{*}&{*}&{*}\\
{}&{}&{}&{}&{}&{}&{*}&{*}\\
\end{pmatrix}
\end{matrix}
\quad
B =
\begin{matrix}
{k\quad\quad\quad\quad\;}\\
\begin{pmatrix}
{*}&{*}&{*}&{*}&{*}&{*}&{*}&{*}\\
{}&{}&{}&{}&{}&{}&{}&{}\\
{}&{}&{}&{}&{*}&{*}&{*}&{*}\\
{}&{}&{}&{}&{}&{}&{*}&{*}\\
\end{pmatrix}
\end{matrix}
\]
И пусть уравнение, которым они различаются начинается с $k$-ой позиции, т.е. $x_k$ -- главная переменная в $A$, но неглавная в $B$.

Пусть $E_A, E_B\subseteq \mathbb R^n$ -- множества решений систем $Ax = 0$ и $Bx = 0$, соответственно.
Так как в $A$ уравнений больше, чем в $B$, то $E_A \subseteq E_B$.

Чтобы показать неравенство, предположим, что наоборот $E_A = E_B$.
Рассмотрим следующие подмножества в них:
\begin{align*}
E_A^0 &= \{x\in E_A\mid x_i = 0\text{ при }i>k\}\\
E_B^0 &= \{x\in E_B\mid x_i = 0\text{ при }i>k\}
\end{align*}
То есть среди всех решений в $E_A$ и $E_B$, соответственно, рассмотрим только те, у которых координаты с номерами больше $k$ обращаются в ноль.
Это не пустые подмножества, например, там есть нулевое решение.
Если $E_A = E_B$, то и $E_A^0 = E_B^0$, так как последние задаются одинаковыми условиями.
Значит, чтобы прийти к противоречию, достаточно показать, что в $E_B^0$ есть элемент, которого нет в $E_A^0$.

Рассмотрим $E_A^0$.
Так как для $Ax = 0$ переменная $x_k$ -- главная, то она выражается через предыдущие.
А значит, если предыдущие ноль, то и она ноль.
Это значит, что для $x\in E_A^0$ автоматически $x_k = 0$.
С другой стороны, для системы $Bx = 0$ переменная $x_k$ является свободной.
Тогда сделаем так: положим все свободные переменные кроме $x_k$ равными нулю, а $x_k=1$.
Тогда все главные переменные правее $x_k$ (с большими номерами) автоматически станут нулями.
Таким образом мы получили точку $x\in E_B^0$, у которой $x_k\neq 0$.
Последнее приводит к противоречию с предположением, что $E_A = E_B$.
\end{proof}


\begin{claim}
Пусть $S_1\in\MatrixDim{m}{n}$ и $S_2\in\MatrixDim{k}{n}$ -- произвольные матрицы в улучшенном ступенчатом виде.
Если $S_1x = 0$ эквивалентно $S_2x=0$, то после удаления нулевых строк матрицы $S_1$ и $S_2$ совпадут.
\end{claim}
\begin{proof}
Так как $S_1 x = 0$ и $S_2x = 0$ эквивалентны между собой, то если мы возьмем любое уравнение $l$ из системы $S_1 x = 0$ и добавим его к системе $S_2 x = 0$, получив систему $\left(\frac{S_2}{l}\right)x=0$, то новая система будет эквивалентна всем трем.
Аналогично, можно перекладывать уравнения из второй системы в первую, не меняя множества решений.

Пусть для определенности матрицы $S_1$  и $S_2$ имеют следующий вид:
\[
S_1 = 
\begin{pmatrix}
{1}&{*}&{0}&{*}&{0}&{0}&{*}&{*}&{*}\\
{}&{}&{1}&{*}&{0}&{0}&{*}&{*}&{*}\\
{}&{}&{}&{}&{1}&{0}&{*}&{*}&{*}\\
{}&{}&{}&{}&{}&{1}&{*}&{*}&{*}\\
\end{pmatrix}\quad
S_2 = 
\begin{pmatrix}
{1}&{\bullet}&{\bullet}&{0}&{\bullet}&{\bullet}&{0}&{\bullet}&{\bullet}\\
{}&{}&{}&{1}&{\bullet}&{\bullet}&{0}&{\bullet}&{\bullet}\\
{}&{}&{}&{}&{}&{}&{1}&{\bullet}&{\bullet}\\
\end{pmatrix}
\]
Они вообще говоря могут содержать разное количество ненулевых строк, пока мы ничего про это не знаем.

Давайте докажем, что в системах совпадают последние уравнения, потом следующие и так далее.
Будем двигаться снизу вверх от коротких к более длинным.
Нам надо показать три вещи: почему совпадают самые короткие уравнения, объяснить как показать совпадение для произвольного промежуточного уравнения и почему у одной из системы уравнения не закончатся раньше, чем у другой.

Пусть для определенности последнее уравнение $S_2$ не длиннее последнего уравнения $S_1$, как на картинке.
Добавим это уравнение к системе $S_1$.
Тогда возможны два случая: уравнение либо строго короче, либо имеет такую же длину.
В первом случае получим две эквивалентные системы с матрицами
\[
S_1 = 
\begin{pmatrix}
{1}&{*}&{0}&{*}&{0}&{0}&{*}&{*}&{*}\\
{}&{}&{1}&{*}&{0}&{0}&{*}&{*}&{*}\\
{}&{}&{}&{}&{1}&{0}&{*}&{*}&{*}\\
{}&{}&{}&{}&{}&{1}&{*}&{*}&{*}\\
\end{pmatrix}\quad
S_1' = 
\begin{pmatrix}
{1}&{*}&{0}&{*}&{0}&{0}&{*}&{*}&{*}\\
{}&{}&{1}&{*}&{0}&{0}&{*}&{*}&{*}\\
{}&{}&{}&{}&{1}&{0}&{*}&{*}&{*}\\
{}&{}&{}&{}&{}&{1}&{*}&{*}&{*}\\
{}&{}&{}&{}&{}&{}&{1}&{\bullet}&{\bullet}\\
\end{pmatrix}\quad
\]
Но по предыдущему утверждению это невозможно.
Значит уравнения имеют одинаковую длину, потому эквивалентны системы
\[
S_1 = 
\begin{pmatrix}
{1}&{*}&{0}&{*}&{0}&{0}&{*}&{*}&{*}\\
{}&{}&{1}&{*}&{0}&{0}&{*}&{*}&{*}\\
{}&{}&{}&{}&{1}&{0}&{*}&{*}&{*}\\
{}&{}&{}&{}&{}&{1}&{*}&{*}&{*}\\
\end{pmatrix}\quad
S_1' = 
\begin{pmatrix}
{1}&{*}&{0}&{*}&{0}&{0}&{*}&{*}&{*}\\
{}&{}&{1}&{*}&{0}&{0}&{*}&{*}&{*}\\
{}&{}&{}&{}&{1}&{0}&{*}&{*}&{*}\\
{}&{}&{}&{}&{}&{1}&{*}&{*}&{*}\\
{}&{}&{}&{}&{}&{1}&{\bullet}&{\bullet}&{\bullet}\\
\end{pmatrix}\quad
\]
В матрице $S_1'$ вычтем предпоследнее уравнение из последнего.
Новая система  $S_1''x=0$ будет эквивалентна $S_1x =0$.
Если уравнения не совпадают, то разность даст новую ступеньку и по предыдущему утверждению системы не могут быть эквивалентными.
Значит последние уравнения совпадают.

Теперь мы знаем, что матрицы $S_1$ и $S_2$ имеют вид (где треугольниками отмечены элементы одинаковых строк):
\[
S_1 = 
\begin{pmatrix}
{1}&{*}&{0}&{*}&{0}&{0}&{*}&{*}&{*}\\
{}&{}&{1}&{*}&{0}&{0}&{*}&{*}&{*}\\
{}&{}&{}&{}&{1}&{0}&{*}&{*}&{*}\\
{}&{}&{}&{}&{}&{1}&{\blacktriangle}&{\blacktriangle}&{\blacktriangle}\\
\end{pmatrix}\quad
S_2 = 
\begin{pmatrix}
{1}&{\bullet}&{\bullet}&{0}&{\bullet}&{0}&{\bullet}&{\bullet}&{\bullet}\\
{}&{}&{}&{1}&{\bullet}&{0}&{\bullet}&{\bullet}&{\bullet}\\
{}&{}&{}&{}&{}&{1}&{\blacktriangle}&{\blacktriangle}&{\blacktriangle}\\
\end{pmatrix}
\]
Теперь посмотрим на следующую пару уравнений.
Пусть для определенности уравнение в $S_1$ будет не длиннее, чем уравнение в $S_2$.
Добавим второе уравнение из $S_1$ в $S_2$ и получим эквивалентную систему.
У нас как и выше два варианта: либо длина уравнения строго меньше, либо длины одинаковые.
Рассмотрим случай первый:
\[
S_2' = 
\begin{pmatrix}
{1}&{\bullet}&{\bullet}&{0}&{\bullet}&{0}&{\bullet}&{\bullet}&{\bullet}\\
{}&{}&{}&{1}&{\bullet}&{0}&{\bullet}&{\bullet}&{\bullet}\\
{}&{}&{}&{}&{1}&{0}&{*}&{*}&{*}\\
{}&{}&{}&{}&{}&{1}&{\blacktriangle}&{\blacktriangle}&{\blacktriangle}\\
\end{pmatrix}\quad
S_2 = 
\begin{pmatrix}
{1}&{\bullet}&{\bullet}&{0}&{\bullet}&{0}&{\bullet}&{\bullet}&{\bullet}\\
{}&{}&{}&{1}&{\bullet}&{0}&{\bullet}&{\bullet}&{\bullet}\\
{}&{}&{}&{}&{}&{1}&{\blacktriangle}&{\blacktriangle}&{\blacktriangle}\\
\end{pmatrix}
\]
В этом случае по предыдущему утверждению системы не эквивалентны, чего быть не может.
Значит у нас второй случай:
\[
S_2' = 
\begin{pmatrix}
{1}&{\bullet}&{\bullet}&{0}&{\bullet}&{0}&{\bullet}&{\bullet}&{\bullet}\\
{}&{}&{}&{1}&{\bullet}&{0}&{\bullet}&{\bullet}&{\bullet}\\
{}&{}&{}&{1}&{*}&{0}&{*}&{*}&{*}\\
{}&{}&{}&{}&{}&{1}&{\blacktriangle}&{\blacktriangle}&{\blacktriangle}\\
\end{pmatrix}\quad
S_2 = 
\begin{pmatrix}
{1}&{\bullet}&{\bullet}&{0}&{\bullet}&{0}&{\bullet}&{\bullet}&{\bullet}\\
{}&{}&{}&{1}&{\bullet}&{0}&{\bullet}&{\bullet}&{\bullet}\\
{}&{}&{}&{}&{}&{1}&{\blacktriangle}&{\blacktriangle}&{\blacktriangle}\\
\end{pmatrix}
\]
Как и раньше, в $S_2'$ вычтем из нового уравнения вышестоящее.
Предположим, что уравнения были разные и получилась ненулевая строка.
Вопрос: где не может начинаться эта строка?
Ответ: там, где у обеих строк были нули.
Теперь воспользуемся тем, что все нижестоящие уравнения у нас одинаковые.
Это значит, что нули у обеих строк в одних и тех же местах (это места где начинаются нижестоящие строки).
Значит, может получится что-то вроде
\[
S_2'' = 
\begin{pmatrix}
{1}&{\bullet}&{\bullet}&{0}&{\bullet}&{0}&{\bullet}&{\bullet}&{\bullet}\\
{}&{}&{}&{1}&{\bullet}&{0}&{\bullet}&{\bullet}&{\bullet}\\
{}&{}&{}&{}&{*}&{0}&{*}&{*}&{*}\\
{}&{}&{}&{}&{}&{1}&{\blacktriangle}&{\blacktriangle}&{\blacktriangle}\\
\end{pmatrix}\quad\text{или}\quad
S_2'' = 
\begin{pmatrix}
{1}&{\bullet}&{\bullet}&{0}&{\bullet}&{0}&{\bullet}&{\bullet}&{\bullet}\\
{}&{}&{}&{1}&{\bullet}&{0}&{\bullet}&{\bullet}&{\bullet}\\
{}&{}&{}&{}&{}&{}&{*}&{*}&{*}\\
{}&{}&{}&{}&{}&{1}&{\blacktriangle}&{\blacktriangle}&{\blacktriangle}\\
\end{pmatrix}\quad\text{и т.д.}
\]
Но по предыдущему утверждению такого опять быть не может, так как новая система не эквивалентна $S_2 x = 0$.
Продолжая аналогично, мы показываем, что все уравнения у систем совпадают.

Осталось объяснить почему уравнения в одной из систем не могут закончиться раньше, чем в другой.
Но тогда у нас они обе в ступенчатом виде и одна получена из другой добавлением нескольких уравнений.
Добавление одного уменьшает множество решений, как показано в предыдущем утверждении, а добавление нескольких -- тем более.
\end{proof}

Из этого утверждения следует, что матрица улучшенного ступенчатого вида для любой матрицы $A\in\MatrixDim{m}{n}$ определена однозначно.
Так как если матрица $A$ приводится к двум разным ступенчатым видам, то их однородные системы эквивалентны, а значит они совпадают.
Потому, говоря о матрице $A$, можно говорить и о ее улучшенном ступенчатом виде без какой-либо неоднозначности.

\paragraph{Классификация}

\begin{claim}
Пусть $A,B\in\MatrixDim{m}{n}$ и пусть $E_A, E_B\subseteq \mathbb R^n$ -- множества решений систем $Ax = 0$ и $Bx = 0$, соответственно.
Тогда следующее эквивалентно:
\begin{enumerate}
\item $E_A = E_B$, т.е. системы эквивалентны.

\item $A$ приводится к $B$ элементарными преобразованиями строк.

\item Существует обратимая $C\in\Matrix{m}$ такая, что $B = CA$.

\item Матрица улучшенного ступенчатого вида для $A$ совпадает с матрицей улучшенного ступенчатого вида для $B$.
\end{enumerate}
\end{claim}
\begin{proof}
Мы все это уже доказали по сути, потому напомним, что откуда следует.
(2)$\Rightarrow$(1) Так как элементарные преобразования меняют систему на эквивалентную.
(1)$\Rightarrow$(4)  Предыдущее утверждение.
(4)$\Rightarrow$(2) Если матрицы $A$ и $B$ приводятся элементарными преобразованиями к одной и той же матрице (улучшенного ступенчатого вида), то они переводятся и друг в друга.
Эквивалентность (2)$\Leftrightarrow$(3) следует из Утверждения~\ref{claim::InvertibleDiscription} о том, что матрица обратима тогда и только тогда, когда она раскладывается в произведение элементарных.
\end{proof}

Смысл этого утверждения в следующем.
Возьмем множество всех однородных систем фиксированного размера, которое описывается матрицами $\MatrixDim{m}{n}$.
Тогда на этом множестве есть отношение эквивалентности: системы эквиваленты если они имеют одинаковое множество решений.
Это полезное свойство, потому что нам не важно какую из систем решать среди эквивалентных.
Однако, это свойство сложно проверяется.
С другой стороны, у нас есть процедура изменения системы (элементарные преобразования), которая меняет системы на заведомо эквивалентные.
Сделаем следующие замечания:
\begin{enumerate}
\item Утверждается, что эта процедура эффективная в том смысле, что если уж какие-то системы были эквивалентны, то мы обязательно от одной к другой сможем перейти элементарными преобразованиями.

\item Все то же самое верно и для второй процедуры -- умножение на обратимую матрицу слева (потому что это по сути та же самая процедура).

\item Утверждается, что в каждом классе эквивалентных систем мы можем найти одну единственную матрицу улучшенного ступенчатого вида.
То есть классов попарно неэквивалентных систем ровно столько же, сколько матриц улучшенного ступенчатого вида.

\item Последнее означает, что свойства системы с произвольной матрицей точно такие же, как у какой-то системы в улучшенном ступенчатом виде.
Потому в абстрактных задачах про системы можно всегда предполагать, что система уже имеет улучшенный ступенчатый вид.
\end{enumerate}


