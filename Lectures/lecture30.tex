\ProvidesFile{lecture30.tex}[Лекция 30]


\subsection{Сведение к билинейным формам}

Теперь нам хотелось бы обобщить на случай полуторалинейных форм все те факты, что мы доказали для билинейных форм.
Есть два пути: мучительный и долгий, когда мы по аналогии с билинейными формами все доказываем заново, или мучительный и быстрый, когда мы вводим некую неприятную абстракцию, которая объяснит, как свести полуторалинейные формы к билинейным.
Я считаю, что если уж и мучиться, то лучше по-быстрому, и пойду вторым путем.

\begin{definition}
Пусть $V$ -- векторное пространство над $\mathbb C$.
Определим новое векторное пространство $\bar V$ следующим образом.
Как множество $\bar V = V$.
Теперь на нем надо задать операции сложения и умножения на скаляр.
Сложение зададим так же, как оно было задано на $V$.
А умножение определим по формуле $\lambda *v = \bar \lambda v$, где справа стоит исходная операция умножения на скаляр в $V$.
\end{definition}

Обратите внимание, что пространства $V$ и $\bar V$ имеют одинаковую размерность.
Более того, набор векторов $e_1,\ldots,e_n$ является базисом в $V$ тогда и только тогда, когда он является базисом в $\bar V$.

\paragraph{Пример}

Пусть $V = \mathbb C^n$, тогда в пространстве $\bar V$ операции заданы следующим образом
\[
\begin{pmatrix}
{x_1}\\{\vdots}\\{x_n}
\end{pmatrix}
+
\begin{pmatrix}
{y_1}\\{\vdots}\\{y_n}
\end{pmatrix}
=
\begin{pmatrix}
{x_1 + y_1}\\{\vdots}\\{x_n + y_n}
\end{pmatrix}
\quad\text{и}\quad
\lambda
\begin{pmatrix}
{x_1}\\{\vdots}\\{x_n}
\end{pmatrix}
=
\begin{pmatrix}
{\bar \lambda x_1}\\{\vdots}\\{\bar \lambda x_n}
\end{pmatrix}
\]

\paragraph{Замечания}

\begin{itemize}
\item Пусть $\beta\colon V\times V\to \mathbb C$ -- полуторалинейная форма, тогда на нее можно посмотреть как на отображение $\beta\colon \bar V\times V\to \mathbb C$ в этом случае $\beta$ становится билинейной формой.
И наоборот если $\beta\colon \bar V\times V\to \mathbb C$ билинейная форма, то $\beta\colon V\times V\to \mathbb C$ -- полуторалинейная форма.
Таким образом можно пользоваться всеми фактами про билинейные формы, смотря на полуторалинейную форму, как на отображение $\beta\colon \bar V\times V\to \mathbb C$.

\item Заметим, что подмножество $U\subseteq V$ является подпространством в $V$ тогда и только тогда, когда оно является подпространством в $\bar V$.
То есть запас подпространств в $V$ и $\bar V$ одинаковый.
\end{itemize}

\begin{definition}
Пусть $\beta\colon V\times V\to \mathbb C$ -- полуторалинейная форма.
Тогда
\begin{itemize}
\item Для любого подпространства $W\subseteq V$ определим его левое и правое ортогональное дополнение как левое и правое ортогональное дополнение для соответствующей билинейной формы, то есть:
\[
W^\bot = \{v\in V\mid \beta(W,v) = 0\}\quad \text{и} \quad {}^\bot W = \{v\in V\mid \beta(v, W) = 0\}
\]

\item  определим ее левое и правое ядра, как левые и правые ядра соответствующей билинейной формы $\beta\colon \bar V\times V\to \mathbb C$, то есть $\ker^L \beta= {}^\bot V$ и $\ker^R \beta = V^\bot$.

\item Полуторалинейная форма $\beta$ будет называться невырожденной, если соответствующая билинейная форма невырождена.
То есть когда $\ker^L\beta = \ker ^R\beta = 0$.%
\footnote{Так как $\dim \bar V = \dim V$, то это условие равносильно тому, что одно из ядер равно нулю.}
Это равносильно тому, что матрица $B = (\beta(e_i, e_j))$ формы в любом базисе $e_1,\ldots,e_n$ невырождена.
\end{itemize}
\end{definition}

\begin{claim}
Пусть $V$ -- векторное пространство над $\mathbb C$ и $\beta \colon V\times V\to \mathbb C$ -- невырожденная полуторалинейная форма.
Тогда
\begin{enumerate}
\item Для любого подпространства $W\subseteq V$ выполнено
\[
\dim W^\bot + \dim W = \dim V
\]

\item Для любого подпространства $W\subseteq V$ выполнено ${}^\bot(W^\bot) = W$.

\item Для любых подпространств $W\subseteq E\subseteq V$ верно, что $W^\bot \supseteq E^\bot$.
Причем $W = E$ тогда и только тогда, когда $W^\bot = E^\bot$.

\item Для любых подпространств $W, E\subseteq V$ выполнено равенство
\[
(W + E)^\bot = W^\bot \cap E^\bot
\]

\item Для любых подпространств $W, E\subseteq V$ выполнено равенство
\[
(W\cap E)^\bot = W^\bot + E^\bot
\]
\end{enumerate}
Аналогичные свойства выполняются для левых ортогональных дополнений ${}^\bot W$.
\end{claim}
\begin{proof}
Это следует из двойственности для подпространств для билинейных форм (утверждение~\ref{claim::DualitySpaces}) и предыдущего замечания.
\end{proof}

\subsection{Квадратичные формы}

\begin{definition}
Пусть $\beta\colon V\times V\to \mathbb C$ -- полутора линейная форма.
Тогда $Q_\beta\colon V\to \mathbb C$ по правилу $v\mapsto \beta(v,v)$ называется квадратичной формой.%
\footnote{Мы можем рассматривать полуторалинейную форму $\beta$, как билинейную форму $\beta\colon \bar V\times V\to \mathbb C$.
Но билинейная форма получается на разных пространствах, потому у нас нет понятия квадратичной формы для $\beta$, как для билинейной формы.
Потому введенное определение квадратичной формы не должно вызвать путаницы.}
\end{definition}

\paragraph{Замечания}

\begin{itemize}
\item Если $e_1,\ldots,e_n\in V$ -- некоторый базис, в котором полуторалинейная форма задается в виде $\beta(x, y) = \bar x^t B y$, то соответствующая ей квадратичная форма имеет вид $Q_\beta(x) = \bar x^t B x$.
Множество квадратичных форм для полуторалинейных форм на пространстве $V$ будем обозначать через $\Quad_{1\frac{1}{2}}(V)$.%
\footnote{Индекс в виде $1\frac{1}{2}$ нужен, чтобы отличить, мы строим квадратичные формы по билинейным или полуторалинейным.}

\item Ключевое свойство квадратичных форм $Q\colon V\to \mathbb C$ заключается в следующем: для любого $v\in V$ и любого $\lambda\in \mathbb C$ выполнено $Q(\lambda v) = |\lambda|^2Q(v)$.
\end{itemize}

Главное отличие от билинейных форм -- любая полуторалинейная форма (без каких-либо дополнительных требований) восстанавливается по своей квадратичной форме.
Давайте разберемся почему это так.

\begin{claim}
[Поляризационная формула]
\label{claim::CPolarization}
Пусть $\beta\colon V\times V\to \mathbb C$ -- произвольная полуторалинейная форма и $Q_\beta\colon V\to \mathbb C$ -- соответствующая ей квадратичная форма.
Тогда 
\[
\beta(v, u) = \sum_{k=0}^3 \frac{i^k}{4}Q_\beta\left(i^k v + u\right) = \frac{Q_\beta(v+u) + iQ_\beta(iv+u) - Q_\beta(-v + u) -i Q_\beta(-iv+u)}{4}
\]
\end{claim}
\begin{proof}
Рассмотрим следующее выражение
\begin{gather*}
\beta(v + u, v+ u) + i\beta(iv + u, iv+ u) - \beta(-v + u, -v+ u) -i \beta(-iv + u, -iv+ u)=\\
\beta(v,v)+\beta(v,u)+\beta(u,v)+\beta(u,u)+\\
+i\beta(v,v)+\beta(v,u)-\beta(u,v)+i\beta(u,u)-\\
-\beta(v,v)+\beta(v,u)+\beta(u,v)-\beta(u,u)-\\
-i\beta(v,v)+\beta(v,u)-\beta(u,v)-i\beta(u,u)=\\
4 \beta(v, u)
\end{gather*}
Разделив обе части на $4$, получаем требуемое.
\end{proof}

\paragraph{Замечание}

В частности, если $\beta(v, v) = 0$ для любого вектора $v\in V$, то полуторалинейная форма $\beta$ тождественно равна нулю.

\begin{claim}
\label{claim::CBilQuad}
Пусть $V$ векторное пространство над $\mathbb C$, тогда отображения
\begin{itemize}
\item $\phi\colon\Bil_{1\frac{1}{2}}(V)\to \Quad_{1\frac{1}{2}}(V)$ по правилу $\beta\mapsto Q_\beta(v) = \beta(v,v)$ (в координатах $\bar x^t B y$ переходит в $\bar x^t B x$)

\item $\psi\colon\Quad_{1\frac{1}{2}}(V)\to \Bil_{1\frac{1}{2}}(V)$ по поляризационной формуле $Q\mapsto \beta_Q(v,u) = \sum_{k=0}^3 \frac{i^k}{4}Q(i^k v + u)$ (в координатах $\bar x^t A x$ переходит в $\bar x^t A y$)
\end{itemize}
являются взаимно обратными изоморфизмами.
\end{claim}
\begin{proof}
По определению, отображение $\phi$ сюръективно.
Из поляризационной формулы (утверждение~\ref{claim::CPolarization}) следует, что композиция $\psi\phi$ равна тождественному отображению.
А значит $\phi$ инъективно, то есть биекция.
При этом $\psi$ является левым обратным к обратимому отображению, а значит просто обратным.
Получили, что $\phi$ и $\psi$ взаимнообратные биекции.
Тот факт, что они изоморфизмы, то есть линейны, непосредственно следует из определения.
\end{proof}

\paragraph{Замечания}

\begin{itemize}
\item Последнее утверждение означает, что полуторалинейные формы и квадратичные формы -- это одно и то же.
В частности, матрица $A$ в определении квадратичной формы однозначно определена.
Действительно, если $Q(x) = \bar x^t A x$ в координатах, то ей соответствует билинейная форма $\beta_Q(x, y) = \bar x^t A y$.
Матрица билинейной формы $A$ определена правилом $a_{ij} = \beta_Q(e_i, e_j)$.

\item Для любопытных, давайте в лоб проверим, что $\phi\psi = \Identity$.
Пусть $Q\colon V\to \mathbb C$ -- произвольная квадратичная форма, тогда она переходит в
\begin{gather*}
\frac{Q(v+v) + iQ(iv+v) - Q(-v+v) -i Q(-iv + v)}{4} = \frac{Q(2v) + iQ((1+i)v) - i Q((1-i)v) - Q(0)}{4} =\\ =\frac{|2|^2 Q(v)+i|1+i|^2Q(v) - i|1-i|^2Q(v)}{4} = Q(v)
\end{gather*}
\end{itemize}

\subsection{Эрмитовы и косоэрмитовы формы}

Так исторически сложилось, что аналоги симметричных и кососимметричных полуторалинейных форм не принято называть симметричными и кососимметричными (как бы мне этого ни хотелось), у них есть другие более пристойные (с точки зрения математического сообщества) названия.
Однако, очень важно понимать, что мы сейчас будем заниматься не чем иным, как изучением аналогов симметричных  и кососимметричных форм, потому и все результаты будут очень ожидаемыми.

\begin{definition}
Пусть $\beta\colon V\times V\to \mathbb C$ -- полуторалинейная форма.
Тогда 
\begin{itemize}
\item $\beta$ называется эрмитовой если $\beta(v, u) = \overline{\beta(u,v)}$ для любых $v,u\in V$.
Это аналог симметричных форм.

\item $\beta$ называется косоэрмитовой, если $\beta(v, u) = -\overline{\beta(u,v)}$ для любых $v,u\in V$.
Это аналог кососимметричных форм.
\end{itemize}
\end{definition}

\paragraph{Замечания}

\begin{itemize}
\item Обратите внимание, что множество эрмитовых (или косоэрмитовых) форм НЕ является векторным пространством над $\mathbb C$, но является векторным пространством над $\mathbb R$.
Действительно, если $\beta(v, u) = \overline{\beta(u,v)}$ для любых $v, u \in V$ и $\lambda\in \mathbb C$, то форма $\lambda \beta$ уже не обязательно эрмитова.
Например, если $\lambda = i$, то $\overline{i\beta(v,u)} = -i \beta(u,v)$.
Как видно из этого вычисления, эрмитова форма после умножения на $i$ превращается в косоэрмитову и наоборот.
В этом смысле изучение эрмитовых или косоэрмитовых форм -- это одно и то же.

\item Правильно думать про эрмитовы и косоэрмитовы формы, как про аналоги вещественной и мнимой части (только мнимая часть рассматривается вместе с мнимой единицей).
В данном случае аналогом комплексного сопряжения является операция $\beta(v,u) \mapsto \overline{\beta(u, v)}$.
Тогда неподвижная часть будет аналогом вещественной части, а меняющая знак -- аналогом мнимой домноженной на $i$.
При этом любая полуторалинейная форма представляется единственным способом в виде суммы эрмитовой и косоэрмитовой:
\[
\beta(v,u) = \frac{\beta(v, u) + \overline{\beta(u, v)}}{2} + \frac{\beta(v, u) - \overline{\beta(u, v)}}{2} 
\]
Или в матричной форме
\[
B = \frac{B + B^*}{2} + \frac{B - B^*}{2}
\]
\end{itemize}

\begin{claim}
\label{claim::CSymBil}
Пусть $\beta\colon V\times V\to \mathbb C$ -- полуторалинейная форма.
Тогда
\begin{enumerate}
\item Пусть $e_1,\ldots,e_n$ -- некоторый базис и $B$ -- матриц полуторалинейной формы в этом базисе.
\begin{itemize}
\item Форма $\beta$ эрмитова тогда и только тогда, когда $B^* = B$.

\item Форма $\beta$ косоэрмитова тогда и только тогда, когда $B^* = - B$.
\end{itemize}

\item Форма $\beta$ эрмитова тогда и только тогда, когда $Q_\beta(v) = \beta(v,v)\in\mathbb R$ для любого $v\in V$.

\item Если форма $\beta$ эрмитова или косоэрмитова, то для любого подпространства $W\subseteq V$ верно $W^\bot = {}^\bot W$.
\end{enumerate}
\end{claim}
\begin{proof}
(1) Пусть после выбора базиса в координатах форма имеет вид $\beta(x, y) = \bar x^t B y$.
Тогда эрмитовость равносильна свойству
\[
\bar x^t B y = \overline{\bar y^t B x} = y^t \bar B \bar x = (y^t \bar B \bar x)^t = \bar x^t \bar B^t y = \bar x^t B^* y
\]
Так как это свойство выполнено для любых $x,y\in \mathbb C^n$, то $B = B^*$.
Аналогично показывается для косоэрмитовых форм.

(2) $\Rightarrow$ Пусть $\beta$ эрмитова.
Тогда $\beta(v,v) = \overline{\beta(v,v)}$.
То есть $Q_\beta(v) = \beta(v,v)\in \mathbb R$.

$\Leftarrow$ Наоборот, применим поляризационную формулу, тогда
\begin{gather*}
\beta(v,u) = \frac{Q(v+u) + iQ(iv+u) - Q(-v+u) - iQ(-iv+u)}{4}=\\
\frac{Q(v+u) + iQ(i(v-iu)) - Q(-(v-u)) - iQ(-i(v+iu))}{4}=\\
\frac{Q(v+u) + i|i|^2Q(v-iu) -|-1|^2 Q(v-u) - i|-i|^2Q(v+iu)}{4}=\\
\frac{Q(v+u) + iQ(v-iu) - Q(v-u) - iQ(v+iu)}{4}
\end{gather*}
Если $Q(v)\in \mathbb R$ для любого $v\in V$, то последнее выражение есть
\[
\overline{\frac{Q(v+u) - iQ(v-iu) - Q(v-u) + iQ(v+iu)}{4}} = \overline{\beta(u,v)}
\]
То есть форма эрмитова.

(3) Для эрмитовых форм по определению получаем
\[
W^\bot = \{v\in V\mid \beta(W, v) = 0\} = \{v\in V\mid \overline{\beta(v, W)} = 0\} = \{v\in V\mid \beta(v, W) = 0\} = {}^\bot W
\]
Аналогично для косоэрмитовых.
\end{proof}

\paragraph{Замечание}

Обратите внимание, что в случае полуторалинейных форм, отличительной особенностью эрмитовых является тот факт, что соответствующая им квадратичная форма принимает только вещественные значения.
Именно это явление и позволяет нам проводить с ними те же самые трюки, которые работали с симметричными билинейными формами над полем $\mathbb R$.

\begin{claim}
Пусть $V$ -- векторное пространство над $\mathbb C$ и $\beta\colon V\times V\to \mathbb C$ -- полуторалинейная форма.
Тогда
\begin{enumerate}
\item Если форма $\beta$ эрмитова, то существует базис $e_1,\ldots,e_n$ такой, что матрица формы $B_\beta$ диагональная с вещественными числами на диагонали.

\item Если форма $\beta$ косоэрмитова, то существует базис $e_1,\ldots,e_n$ такой, что матрица формы $B_\beta$ диагональная с чисто мнимыми числами на диагонали.
\end{enumerate}
\end{claim}
\begin{proof}
(1)$\Rightarrow$(2) Если форма $\beta$ косоэрмитова, то $i\beta$ будет эрмитова.
Тогда в каком-то базисе матрица формы $i\beta$ будет диагональна с вещественными числами на диагонали.
То есть матрица формы $\beta$ диагональная с чисто мнимыми числами на диагонали.

(1) Так как на диагонали у эрмитовой формы всегда находятся вещественные числа (утверждение~\ref{claim::CSymBil} пункт~(2)), то достаточно показать, что матрица формы диагонализуется.
Поступать будем так же, как и в случае билинейных форм.
Рассмотрим квадратичную форму $Q_\beta(v)$.
Если она тождественно равна нулю, то $\beta$ тоже тождественно равна нулю (утверждение~\ref{claim::CBilQuad}).
Тогда матрица нулевая и доказывать нечего.
Пусть теперь $v$ -- такой вектор, что $\beta(v,v) = Q_\beta(v) \neq 0$.
Это значит, что $v\notin \langle v\rangle^\bot$, то есть $\langle v\rangle \cap \langle v\rangle^\bot = 0$.
По определению $\langle v\rangle^\bot = \ker \beta(v, {-})$ является ядром ненулевого линейного функционала, то есть имеет размерность $\dim V - 1$.
Значит $V = \langle v\rangle\oplus \langle v\rangle^\bot$.
Теперь берем вектор $v$ в качестве первого базисного вектора $e_1$.
Индукцией по размерности пространства находим ортогональный базис $e_2,\ldots,e_n$ в $\langle v\rangle^\bot$ для формы $\beta|_{\langle v\rangle^\bot}$.
Победа!
\end{proof}

\begin{claim}
Пусть $V$ -- векторное пространство над $\mathbb C$ и $\beta\colon V\times V\to\mathbb C$ -- эрмитова форма.
Тогда существует базис, в котором матрица формы имеет вид
\[
B_\beta = 
\begin{pmatrix}
{E}&{}&{}\\
{}&{-E}&{}\\
{}&{}&{0}\\
\end{pmatrix}
\]
При этом количество единиц, минус единиц и нулей на диагонали не зависит от базиса.
\end{claim}
\begin{proof}
Мы уже знаем, что эрмитова форма в некотором базисе диагонализуется.
То есть существует базис, что $\beta(x, y) = \sum_{i=1}^n d_i \bar x_i y_i$, где $d_i\in \mathbb R$.
Перестановкой базисных элементов будем считать, что сначала идут все положительные коэффициенты, потом отрицательные и только потом нулевые, то есть $\beta(x,y) = \sum_{i=1}^k d_i \bar x_i y_i - \sum_{i=k+1}^r d_i \bar x_i y_i$, где все $d_i > 0$.
В этом случае сделаем замену $x_i' = \sqrt{d_i}x_i$.
Получим $\beta(x_i',y_i') = \sum_{i=1}^k \bar x_i' y_i' - \sum_{i=k+1}^r \bar x_i' y_i'$.
А значит, можно привести к такому виду.

Теперь покажем единственность.
Количество единиц и минус единиц вместе дает ранг матрицы.
А ранг матрицы билинейной формы $\beta\colon \bar V\times V\to \mathbb C$ не меняется при смене базисов (раздел~\ref{subsection::BilChar}).
Значит у нас количество нулей и суммарное количество единиц и минус единиц не зависит от базиса.
Теперь надо показать, что количество единиц и минус единиц одно и то же в каждом базисе.
Для этого надо повторить кусок доказательства соответствующего утверждения для билинейных форм над $\mathbb R$ (утверждения~\ref{claim::SBilReal}).
Я для удобства прочтения повторю его здесь.

Предположим противное -- пусть зависит.
Пусть найдутся два базиса $e_1,\ldots,e_n$ и $f_1,\ldots,f_n$, так что форма в них имеет вид
\begin{align*}
\beta(x, y) &= \bar x_1y_1+\ldots +\bar x_s y_s - \bar x_{s+1}y_{s+1} - \ldots - \bar x_k y_k\\
\beta(x',y') &= \bar x_1'y_1'+\ldots +\bar x_t' y_t' - \bar x_{t+1}' y_{t+1}' - \ldots - \bar x_k' y_k'\\
\end{align*}
Пусть для определенности $s > t$.
Тогда положим $W = \langle e_1,\ldots, e_s\rangle$ и $U = \langle f_{t+1},\ldots, f_n\rangle$.
Теперь вспомним, что для любого $v\in V$ значения $Q_\beta(v)\in \mathbb R$ в силу эрмитовости формы.
Далее заметим, что $Q_\beta(w) > 0$ для любого ненулевого $w\in W$ и $Q_\beta(u) \leqslant 0$ для любого $u\in U$.
Следовательно подпространства $W$ и $U$ могут пересекаться только по нулю.
С другой $\dim W+\dim U = s + n - t > n$, а значит $\dim(W\cap U) > 0$, противоречие.
\end{proof}

\paragraph{Замечание}

Как!
Откуда взялись эти долбаные минус единицы!?
Почему нельзя все сделать единицами как в случае билинейных форм?
Звучат эти вопросы у вас сейчас в голове?
Если да, то это правильное замечание для прочтения.
Давайте рассмотрим пример билинейной формы $\beta(x,y) = \bar x_1 y_1 - \bar x_2 y_2$.
Давайте будем думать в терминах соответствующей билинейной формы $Q_\beta(x) = |x_1|^2 - |x_2|^2$.
Теперь мы хотим сделать замену $x_1 = \lambda x_1'$ и $x_1 = \mu x_2'$.
Но тогда $Q_\beta(x') = |\lambda|^2 |x_1'|^2 - |\mu|^2 |x_2'|^2$.
То есть из под модуля комплексные числа $\lambda$ и $\mu$ вылезут положительными вещественными, потому отрицательный знак поправить так не получится.
Все дело в наличии сопряжения на координатах одного аргумента.

Как и в случае вещественного векторного пространства мы можем определить положительные и отрицательные формы.

\begin{definition}
Пусть $\beta\colon V\times V\to \mathbb C$ -- эрмитова форма.
Тогда количество единиц в ее диагональной форме $\#1$ называется положительным индексом инерции, количество минус единиц $\#-1$ называется отрицательным индексом инерции.
Количество нулей будет обозначаться $\# 0$.

Форма $\beta$ называется положительно определенной, если $Q_\beta(v) > 0$ для любого ненулевого $v\in V$.
Форма $\beta$ называется отрицательно определенной, если $Q_\beta(v)<0$ для любого ненулевого $v\in V$.
\end{definition}

Обратите внимание, что 
\begin{itemize}
\item Форма положительно определена тогда и только тогда, когда ее положительный индекс инерции равен размерности пространства, то есть $\# 1 = \dim V$.

\item Форма отрицательно определена тогда и только тогда, когда ее отрицательный индекс инерции равен размерности пространства, то есть $\#-1 = \dim V$.

\item Форма не вырождена тогда и только тогда, когда $\# 0 = 0$.
\end{itemize}

\subsection{Метод Якоби для полуторалинейных форм}

Здесь я хочу распространить метод Якоби описанный в разделе~\ref{subsection::Jacoby} на случай эрмитовых форм.
Окажется, что полуторалинейность ни на что не повлияет и метод дословно переносится и сюда.

Пусть $V$ -- векторное пространство над $\mathbb C$ и $\beta\colon V\times V\to \mathbb C$ -- эрмитова форма.
Пусть $e_1,\ldots,e_n$ -- некоторый базис $V$, в котором форма записывается в виде $\beta(x, y) = \bar x^t B y$, где $B\in \operatorname{M}_{n}(\mathbb C)$ и $x,y\in \mathbb C^n$.
Эрмитовость формы $\beta$ означает, что $B^* = B$.%
\footnote{Такие матрицы называются самосопряженными.}
Выделим в матрице $B$ верхние левые блоки:
\[
B =
\begin{pmatrix}
{\boxed{
\begin{matrix}
{
\boxed{
\begin{matrix}
{
\boxed{
\begin{matrix}
{\boxed{b_{11}}}&{}\\
{}&{\ddots}
\end{matrix}
}
}&{}\\
{}&{B_k}
\end{matrix}
}
}&{}\\
{}&{\ddots}
\end{matrix}
}
}&{}\\
{}&{}
\end{pmatrix}
\]
То есть $B_k$ -- подматрица состоящая из первых $k$ строк и столбцов.
Определим подпространства $U_k = \langle e_1,\ldots,e_k\rangle$.
Тогда $B_k$ -- матрица формы $\beta|_{U_k}$ в базисе $e_1,\ldots,e_k$.
Обозначим $\det B_k$ через $\Delta_k$.
Наша задача найти базис $e_1',\ldots,e_n'$ такой, чтобы
\[
\begin{pmatrix}
{e_1'}&{\ldots}&{e_n'}
\end{pmatrix}
=
\begin{pmatrix}
{e_1}&{\ldots}&{e_n}
\end{pmatrix}
\begin{pmatrix}
{1}&{*}&{\ldots}&{*}\\
{}&{1}&{\ldots}&{*}\\
{}&{}&{\ddots}&{\vdots}\\
{}&{}&{}&{1}\\
\end{pmatrix}
\]
и при этом форма $\beta$ была диагональная в базисе $e_1',\ldots,e_n'$.
Заметим, что в силу специального вида замены базиса мы имеем $\langle e_1,\ldots,e_k \rangle = \langle e_1', \ldots,e_k'\rangle$.
Более того, в этом случае верно
\[
\begin{pmatrix}
{e_1'}&{\ldots}&{e_k'}
\end{pmatrix}
=
\begin{pmatrix}
{e_1}&{\ldots}&{e_k}
\end{pmatrix}
\begin{pmatrix}
{1}&{*}&{\ldots}&{*}\\
{}&{1}&{\ldots}&{*}\\
{}&{}&{\ddots}&{\vdots}\\
{}&{}&{}&{1}\\
\end{pmatrix}
\]
В частности, если $B'$ -- матрица билинейной формы в базисе $e_1',\ldots,e_n'$ и $B_k'$ -- матрица ее ограничения на $U_k$ в базисе $e_1',\ldots,e_k'$, то $B_k' = C_k^* B_k C_k$, где $C_k$ -- верхнетреугольная матрица с единицами на диагонали из формулы выше.
То есть $\det B_k' = \det B_k$.
В частности $B_k'$ всегда будет невырожденная матрица.

Будем искать векторы $e_i'$ по очереди в виде:
\[
e_k' = e_k + \lambda_1 e_1' + \ldots + \lambda_{k-1}e_{k-1}'
\]
Кроме этого, будем показывать, что $\beta(e_k',e_k')\neq 0$.
Последнее равенство позволяет находить их по индукции, положив $e_1' = e_1$.
В этом случае $\beta(e_1',e_1') = \det B_1 \neq 0$.
Пусть мы уже нашли векторы $e_1',\ldots,e_{k-1}'$ (и показали, что $\beta(e_1',e_1')\neq 0,\ldots,\beta(e_{k-1}',e_{k-1}')\neq 0$), давайте предъявим формулу для $e_k'$ и покажем, что $\beta(e_k',e_k')\neq 0$.
У нас должно получиться
\[
e_k' = e_k + \lambda_1 e_1' + \ldots + \lambda_{k-1}e_{k-1}'
\]
Вектор $e_k'$ должен быть ортогонален всем построенным $e_i'$.
Умножим предыдущее равенство относительно $\beta$ на $e_i'$ слева (то есть применим $\beta(e_i',{-})$),%
\footnote{Обратите внимание, что в отличие от случая билинейной формы, тут мы должны умножить слева.
Это нужно, чтобы коэффициенты $\lambda_i$ из полуторалинейной формы вынеслись без комплексного сопряжения.}
получим
\[
0 = \beta(e_i',e_k') = \beta(e_i',e_k) +\sum_{j=1}^{k-1}\lambda_j \beta(e_i', e_j')
= \beta(e_i', e_k) + \lambda_i \beta(e_i', e_i')
\]
Так как по индуктивному предположению все числа $\beta(e_i',e_i') \neq 0$ при $i< k$, то мы получаем формулу
\[
e_k' = e_k - \frac{\beta(e_1', e_k)}{\beta(e_1',e_1')} e_1' - \ldots - \frac{\beta(e_{k-1}', e_k)}{\beta(e_{k-1}',e_{k-1}')} e_{k-1}'
\]
Осталось проверить, что $\beta(e_k', e_k')\neq 0$.
По построению матрица $B_k'$ является диагональной с числами $\beta(e_i',e_i')$ на диагонали.
Как было отмечено выше, в силу особенностей замены $\det B_k' = \det B_k\neq 0$.
С другой стороны $\det B_k'$ равен произведению диагональных элементов, значит они все должны быть ненулевыми.
В частности $\beta(e_k',e_k')$ тоже не ноль.
Кроме того, это рассуждение показывает, что диагональные элементы $B'$ считаются по формулам $\beta(e_i',e_i') = \frac{\Delta_i}{\Delta_{i-1}}$, где $\Delta_i = \det B_i$ и $\Delta_0 = 1$.


\subsection{Критерий Сильвестра для полуторалинейных форм}

Как и в случае вещественных билинейных форм из метода Якоби можно вытащить критерий положительной определенности для эрмитовых форм.
Он называется критерием Сильвестра.

В  начале сделаем одно наблюдение.
Пусть $\beta\colon V\times V\to \mathbb C$ -- некоторая полуторалинейная форма.
И пусть фиксированы два базиса с матрицей перехода: $(e_1',\ldots,e_n') = (e_1,\ldots,e_n)C$.
Обозначим матрицы формы $\beta$ через $B'$ и $B$ в соответствующих базисах.
Тогда мы знаем, что $B' = C^* B C$.
В частности
\[
\det B' = \det C^*\det B \det C = \det\bar C^t \det C\det B = \det \bar C\det C\det B = \overline{\det C}\det C \det B = |\det C|^2 \det B
\]
То есть определитель полуторалинейной формы (не обязательно эрмитовой) определен однозначно с точностью до умножения на положительное вещественное число.
Это означает, что либо определитель ноль, либо у определителя не меняется аргумент (имеется в виду аргумент комплексного числа).
В частности, если определитель $\beta$ является вещественным положительным числом в некотором базисе, то он остается положительным вещественным в любом другом базисе.

\begin{claim}
[Критерий Сильвестра]
Пусть $\beta\colon V\times V\to \mathbb C$ -- эрмитова форма и пусть в некотором базисе $e_1,\ldots,e_n$ она записывается в виде $\beta(x, y) = \bar x^t B y$, где $B\in\operatorname{M}_n (\mathbb C)$ -- самосопряженная матрица, то есть $B^* = B$.
Обозначим ее угловые миноры через $\Delta_1,\ldots,\Delta_n$.
Тогда
\begin{enumerate}
\item Форма $\beta$ положительно определена тогда и только тогда, когда $\Delta_i > 0$ для любого $i$.

\item Форма $\beta$ отрицательно определена тогда и только тогда, когда $\sgn \Delta_i = (-1)^i$ для любого $i$.
\end{enumerate}
\end{claim}
\begin{proof}
(2) выводится из (1) заменой формы $\beta$ на $-\beta$.
При этом $\Delta_i(-\beta) = (-1)^i \Delta_i(\beta)$.
Потому нам достаточно доказать только первый пункт.

(1) $\Rightarrow$ Если форма $\beta$ положительно определена, то ее ограничение $\beta|_{U_k}$, где $U_k = \langle e_1,\ldots,e_k\rangle$, тоже положительно определено.
Тогда в некотором базисе $\beta|_{U_k}$ задается единичной матрицей.
А значит ее определитель положительное число.
Значит и в любом другом базисе ее определитель положительное число, например, в базисе $e_1,\ldots,e_k$.
Но этот определитель равен $\Delta_k$.

(1)$\Leftarrow$ В этом случае выполнены условия для выполнимости метода Якоби, а именно, $\Delta_i\neq 0$.
Значит можно диагонализировать нашу форму с числами $\frac{\Delta_i}{\Delta_{i-1}} > 0$ на диагонали.
\end{proof}

\subsection{Эрмитово векторное пространство}

\begin{definition}
Пусть $V$ -- векторное пространство над $\mathbb C$ и $({-},{-})\colon V\times V\to \mathbb C$ -- полуторалинейная форма.
Форма $({-},{-})$ называется эрмитовым скалярным произведением если
\begin{enumerate}
\item $({-},{-})$ эрмитова.

\item $({-},{-})$ положительна определена.
\end{enumerate}

Пространство $V$ вместе с эрмитовым скалярным произведением называется эрмитовым пространством.%
\footnote{Это прямой аналог евклидова пространства в комплексном мире.}
\end{definition}

Благодаря тому, что мы грамотно определили эрмитовы скалярные произведения, теперь для любого вектора $v\in V$ число $(v,v)$ является вещественным и более того $(v,v) \geqslant 0$, причем равенство достигается только в случае $v=0$.
А значит можно вводить все те же самые геометрические понятия, что мы вводили в евклидовом случае.
Этим безобразием мы сейчас и займемся.
Главная неприятная особенность эрмитовых пространств -- тут не работает сведение к школьной геометрии.
Однако работает сведение к эрмитовым пространствам малой размерности.
Да, они уже не из знакомого со школы геометрического мира, но все же это лучше, чем работать в произвольной размерности.

\begin{definition}
Пусть $V$ -- эрмитово пространство.
Тогда базис $e_1,\ldots,e_n$ называется ортогональным, если  $(e_i, e_j) = 0$ для всех $i\neq j$.
Он называется ортонормированным, если он ортогональный и $(e_i, e_i) = 1$.
\end{definition}

\begin{definition}
Пусть $V, ({-},{-})_V$ и $U, ({-},{-})_U$ -- два эрмитовых пространства.
Тогда отображение $\phi\colon V\to U$ называется изоморфизмом эрмитовых пространств, если $\phi$ -- изоморфизм векторных пространств, сохраняющий скалярное произведение, то есть $(\phi(v), \phi(u))_U = (v, u)_V$ для всех $v, u \in V$.
В этом случае эрмитовы пространства называются изоморфными.
\end{definition}

Как и в случае евклидовых пространств верно следующее утверждение.

\begin{claim}
Два эрмитовых пространства $V, ({-},{-})_V$ и $U, ({-},{-})_U$  изоморфны тогда и только тогда, когда они имеют одинаковую размерность.
\end{claim}
\begin{proof}
Мы должны слово в слово повторить доказательство утверждения~\ref{claim::EuclideanIsom}.
Если два эрмитовых пространства изоморфны, то их подлежащие пространства $V$ и $U$ изоморфны как векторные пространства, а значит имеют одинаковую размерность.
В обратную сторону.
Выберем в пространстве $V$ ортонормированный базис $e_1,\ldots,e_n$ и в пространстве $U$ ортонормированный базис $f_1,\ldots, f_n$.
Они существуют, потому что для любой положительно определенной эрмитовой формы можно выбрать базис, в котором его матрица единичная.
Тогда ясно, что линейное отображение отправляющее $e_i$ в $f_i$ удовлетворяет нужным свойствам.
\end{proof}

Еще одно замечание.
Как и в случае евклидовых пространств.
Формулы из метода Якоби в эрмитовом пространстве задают процесс называемый ортогонализацией Грама-Шмидта.


\begin{definition}
Пусть $V$ -- эрмитово векторное пространство и $v\in V$ определим длину вектора $v$ по формуле $|v| = \sqrt{(v,v)}$.
\end{definition}

\begin{claim}
[Неравенство Коши-Буняковского]
Пусть $V$ -- эрмитово пространство и $v,u\in V$ -- произвольные векторы.
Тогда $|(v,u)|\leqslant |v| |u|$, причем равенство достигается тогда и только тогда, когда векторы $v$ и $u$ лежат на одной прямой.
\end{claim}
\begin{proof}
Доказательство один в один повторяет вещественный случай.
Если хотя бы один из векторов нулевой, то неравенство превращается в верное равенство и в этом случае $v$ и $u$ лежат на одной прямой.
Потому достаточно считать, что оба вектора не нулевые.
Тогда выберем $e_1$ -- единичный вектор на прямой $\langle v\rangle$, а вектор $e_2$ выберем в плоскости $\langle v, u \rangle$ длины один и ортогональным к $e_1$ (воспользуемся методом ортогонализации Грама-Шмидта).
Тогда можно считать, что $v,u\in \mathbb C^2$ и скалярное произведение является стандартным, то есть задается $(x, y) = \bar x^t y$.
В силу выбора базиса мы знаем, что 
\[
v=
\begin{pmatrix}
{a}\\{0}
\end{pmatrix}
\quad \text{и} \quad
u =
\begin{pmatrix}
{b}\\{c}
\end{pmatrix}
\]
Тогда $|(v,u)| = |ab|$ и $|v||u| = |a|\sqrt{|b|^2 + |c^2|}$.
Доказываемое неравенство принимает вид $|ab|\leqslant |a|\sqrt{|b|^2+|c|^2}$, что очевидно.

Теперь надо понять, когда в этом неравенстве достигается равенство.
Причем мы считаем, что $a\neq 0 $ (так как оба вектора ненулевые).
В этом случае равенство $|b| = \sqrt{|b|^2+|c|^2}$ достигается тогда и только тогда, когда $c = 0$.
То есть равенство достигается тогда и только тогда, когда $ v$ и $u$ лежат на одной прямой.
\end{proof}

\paragraph{Замечания про углы}

% TO DO
% Переписать про углы!
Давайте в начале посмотрим на ситуацию в евклидовом пространстве.
Пусть у нас есть два вектора $v, u\in V$ как на картинке ниже.
\[
\xymatrix@R=10pt{
	{}&{}&{}&{}&{}\\
	{}&{}&{}\ar[rr]_v\ar@{--}[ll]\ar[rru]^u&{}&{}\\
	{}&{}&{}&{}&{}\\
}
\quad
\quad
\quad
\xymatrix@R=10pt{
	{}&{}&{}&{}&{}\\
	{}&{}&{}\ar[rr]_v\ar@{--}[ll]\ar[lld]^{-u}&{}&{}\\
	{}&{}&{}&{}&{}\\
}
\]
Тогда мы можем посмотреть на угол между прямыми $\langle v\rangle$ и $\langle u\rangle$.
Это по определению меньший угол из двух на картинках, он измеряется в диапазоне $[0, \pi / 2]$ и его можно найти по формуле $\cos\alpha = \frac{|(v, u)|}{|v| |u|}$.
Однако ситуации на картинках отличаются так: слева косинус положительный, а справа отрицательный.
То есть у $\cos\alpha$ есть знак, этот знак не чувствует угол между прямыми, но отвечает в некотором смысле за ориентацию векторов по отношению к тому углу, который мы замерили.
А так как вещественная прямая является линейно упорядоченным множеством, то на нем есть всего два направления, которые и соответствуют знакам плюс и минус у скалярного произведения $(v, u)$.
На этот знак еще можно смотреть так, мы берем ортогональную проекцию $u$ на $\langle v\rangle$ и проверяем сонаправлены векторы или нет.

Если мы возьмем на вооружение эту точку зрения, то ее можно распространить на комплексный случай.
То есть мы будем мерить угол между двумя прямыми натянутыми на вектор, а потом замерять расхождение между направлениями одного вектора и ортогональной проекции другого вектора на первую прямую.
Тут еще важно понимать, что из-за несимметричности эрмитова произведения в полном смысле $(v, u) = \overline{(u, v)}$ тут важен порядок!
Мы проектируем именно второй вектор на первую прямую.
Угол начинает зависеть от порядка векторов.

В итоге мы приходим к таким рассуждениям.
Из неравенства Коши-Буняковского следует, что для любых двух векторов $v,u\in V$ верно $-1\leqslant \frac{|(v,u)|}{|v| |u|}\leqslant 1$.
А значит найдется единственное число $\alpha\in [0,\pi/2]$ такое, что $\cos \alpha = \frac{|(v,u)|}{|v| |u|}$.
Это число называется углом между прямыми $\langle v\rangle$ и $\langle u \rangle$ и не зависит от порядка векторов.
Кроме того, выражение $\frac{(v, u)}{|v| |u|}$ можно представить в тригонометрической форме $r e^{i\varphi}$, где $r = \cos \alpha$ -- модуль, а $\varphi \in [0,2\pi)$ -- аргумент.
Выражение $e^{i\varphi}$ -- это поляризационный фактор, который измеряет отклонение от сонаправленности упорядоченной пары векторов $v, u$.
Он аналогичен знаку $\pm$ из вещественного случая, но так как комплексная прямая не упорядочена, то на ней есть много разных причин быть не сонаправленными.
Все отклонения задаются аргументом скалярного произведения.

\begin{definition}
Пусть $V$ -- эрмитово пространство и $v,u\in V$ -- два вектора.
Тогда найдутся такие числа $\alpha\in[0,\pi/2]$ и $\varphi\in [0, 2\pi)$ такие, что $\cos \alpha\cdot e^{i\varphi} = \frac{(v,u)}{|v| |u|}$.
Тогда $\alpha$ называется углом между прямыми $\langle v\rangle$ и $\langle u\rangle$ и обозначается $\angle(v, u)$, а $e^{i\varphi}$ -- это поляризационный множитель, а $\varphi$ -- поляризационный угол.
\end{definition}

\begin{remark}
\begin{itemize}
\item
Обратите внимание, что поляризационный множитель зависит от порядка векторов.
Действительно, если $\frac{(v, u)}{|v| |u|} = \cos \alpha \cdot e^{i\varphi}$, то 
\[
\frac{(u, v)}{|v| |u|} = \frac{\overline{(u, v)}}{|v| |u|} = \cos \alpha\cdot e^{-i\varphi}
\]
Таким образом поляризационный угол $\varphi$ сменит знак на противоположный.
Эта ситуация аналогична ориентированному объему, который зависит от порядка, в котором рассматриваются векторы в параллелепипеде.

\item
Если записывать скалярное произведение через угол между прямыми и поляризацию, то в евклидовом случае получается формула
\[
(v, u) = |v| |u| \cos \alpha \sgn
\]
где $\sgn$ обозначает знак $\pm 1$ в зависимости от положения векторов.
А в эрмитовом случае получается формула
\[
(v, u) = |v| |u| \cos \alpha\cdot  e^{i\varphi}
\]
где $\varphi$ -- поляризационный угол.
В этом смысле эрмитов случай расширяет евклидов, в котором возможны только два угла $0$ и $\pi$.
\end{itemize}
\end{remark}

\begin{definition}
Матрица $C\in \operatorname{M}_n(\mathbb C)$ называется унитарной, если $C^* C = E$.
\end{definition}

Эквивалентные определения унитарности: $CC^* = E$ или $C^* = C^{-1}$.

\begin{claim}
Пусть $V$ -- эрмитово пространство и $e_1,\ldots,e_n$ -- ортонормированный базис.
Тогда
\begin{enumerate}
\item Для любой унитарной матрицы $C\in \operatorname{M}_n(\mathbb C)$ векторы $(e_1,\ldots,e_n)C$ являются ортонормированным базисом.

\item Если $f_1,\ldots,f_n$ -- любой другой ортонормированный базис, то матрица перехода $C$, то есть $(f_1,\ldots,f_n) = (e_1,\ldots,e_n)C$, является унитарной.
\end{enumerate}
\end{claim}
\begin{proof}
Доказательство полностью аналогично доказательству евклидового случая (утверждение~\ref{claim::OrthoBasisDiscrEucl}) и потому оставляется в качестве упражнения.
\end{proof}


\subsection{Обзор геометрических понятий в эрмитовом пространстве}

\paragraph{Ортогональные проекции}

Если $V$ -- эрмитово пространство и $U\subseteq V$ -- некоторое подпространство, то $V = U\oplus U^\bot$.
Это значит, что любой вектор раскладывается единственным образом в виде $v = \pr_U v + \ort_U v$, где $\pr_U v\in U$ и $\ort_U v \in U^\bot$.
Как и в евклидовом случае их называют проекцией и ортогональным дополнением вектора $v$.

\paragraph{Углы и расстояния}

Как и в случае вещественного пространства определяется расстояние между векторами $\rho(v,u) = |v - u|$, где $v,u\in V$.
И расстояние между множествами $\rho(X, Y) = \inf_{x\in X, y\in Y}\rho(x,y)$, где $X,Y\subseteq V$.
С углами приходится говорить лишь про углы между прямыми, а не векторами из-за поляризационного множителя их нельзя сравнивать между собой.
Потому угол между вектором и подпространством определяется так $\angle(v,L) = \inf_{u\in L}\angle(v,u)$.
Я оставлю в качестве упражнения показать, следующее.

\begin{claim}
\label{claim::DistAngleHerm}
Пусть $V$ -- эрмитово пространство, $L\subseteq V$ -- подпространство, $v\in V$ -- некоторый вектор.
Тогда
\begin{enumerate}
\item $\rho(v, L) = |\ort_L v|$.

\item $\angle(v, L) = \angle(v, \pr_L v)$.%
\footnote{Если $\pr_L v = 0$, то надо считать косинус угла нулевым, то есть угол равным $\pi/2$.}
\end{enumerate}
\end{claim}


\paragraph{Метод наименьших квадратов}

Хочу отметить, что в эрмитовом пространстве так же можно применять метод наименьших квадратов.
То есть метод для решения систем вида $Ax = b$, где $A\in \operatorname{M}_{m\,n}(\mathbb C)$, $b\in \mathbb C^m$ и $x\in\mathbb C^n$ -- столбец неизвестных, в случае, когда данная система не имеет решения.
В этом случае надо минимизировать $\rho(Ax, b)$ по $x$.
Если минимум достигается на $x_0$, то $b_0 = Ax_0$ является ортогональной проекцией $b$ на пространство $\langle A \rangle$.
Если столбцы матрицы $A$ линейно независимы, то явные формулы для $x_0$ и $b_0$ следующие: $b_0 = A(A^*A)^{-1}A^*b$ и $x_0 = (A^*A)^{-1}A^*b$.
Это аналог формулы <<Атата>>.%
\footnote{Так как транспонирование в эрмитовом пространстве заменяется звездочкой, то может быть имеет смысл называть эту формулу <<Азаза>>?..}

\paragraph{Матрица Грама и формальный объем}

Пусть $V$ -- эрмитово пространство.
Если $v_1,\ldots,v_k\in V$, то матрица $G(v_1,\ldots,v_k)$ с элементами $(v_i, v_j)$ называется матрицей Грама.
Эта матрица самосопряжена в смысле $G(v_1,\ldots,v_k)^* = G(v_1,\ldots,v_k)$.
При этом $\det G(v_1,\ldots,v_k)\geqslant 0$ причем равенство достигается тогда и только тогда, когда $v_1,\ldots,v_k$ линейно зависимы.

Сказать, что такое параллелепипед в комплексном пространстве сложно, потому объем определяется формально для набора векторов $v_1,\ldots,v_k\in V$.
А именно
\[
\Vol_k(v_1,\ldots,v_k) = \sqrt{\det G(v_1,\ldots,v_k)}
\]
Для данного объема также выполняется формула через площадь основания на высоту:
\[
\Vol_k(v_1,\ldots,v_k) = \Vol_{k-1}(v_1,\ldots,v_{k-1}) \rho(v_k, \langle v_1,\ldots,v_{k-1}\rangle)
\]
Можно определить поляризованный объем, пользуясь определителем.
Делается это аналогично вещественному случаю, с той лишь разницей, что базисы будут отличаться  не знаком, а комплексным аргументом и у нас получается много поляризаций (а не ориентаций) для базисов.
Я не буду здесь вдаваться в подробности.
