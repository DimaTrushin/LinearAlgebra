\ProvidesFile{lecture04.tex}[Лекция 4]


\subsection{Полиномиальное исчисление от матриц}

Обозначим множество всех многочленов с вещественными коэффициентами через $\mathbb R[x]$.
Формально это значит: $\mathbb R[x]=\{a_0+a_1x + \ldots + a_n x^n\mid n\in \mathbb Z_{+},\, a_i\in \mathbb R\}$.
Аналогично можно обозначать многочлены с рациональными, целыми, комплексными и т.д. коэффициентами.

\paragraph{Подстановка матриц в многочлены}

Пусть $p(x) = a_0+a_1x+\ldots a_n x^n$ -- многочлен с вещественными коэффициентами, а $A\in\Matrix{n}$.
Тогда можно определить $f(A)= a_0 E + a_1 A^1 + \ldots + a_n A^n\in\Matrix{n}$.
Если определить $A^0 = E$, то формула становится более единообразной $f(A)= a_0 A^0 + a_1 A^1 + \ldots + a_n A^n$.
Однако, психологически проще думать так: вместо $x$ подставляем $A$, а свободный член отождествляем со скалярными матрицами.
Отметим, что если два многочлена равны, то и их значения на матрице $A$ тоже равны.

\begin{claim*}
Пусть $A\in\Matrix{n}$ и $f,g\in\mathbb R[x]$ -- два произвольных многочлена, тогда:
\begin{enumerate}
\item $(f+g)(A) = f(A) + g(A)$.

\item $(fg)(A) = f(A)g(A)$.

\item $f(\lambda E) = f(\lambda)E$.

\item $f(C^{-1}AC) = C^{-1}f(A)C$ для любой обратимой $C\in \Matrix{n}$

\item Матрицы $f(A)$ и $g(A)$ коммутируют между собой.
\end{enumerate}
\end{claim*}
\begin{proof}
Все это делается прямой проверкой по определению.
Давайте объясним свойства (2) и (4).

(2) Пусть 
\[
f = \sum_{k=0}^na_k x^k\text{ и }g = \sum_{k=0}^m b_k x^k
\]
тогда 
\[
fg = \sum_{k=0}^{n + m} \left(\sum_{s + t = k }a_s b_t\right) x^k
\]
Потому надо проверить равенство:
\[
\left(\sum_{k=0}^n a_k A^k\right)\left(\sum_{k=0}^mb_k A^k\right) = \sum_{k=0}^{n+m}\left(\sum_{s+t = k} a_s b_t\right)A^k
\]
которое следует из перестановочности $A$ со своими степенями и коэффициентами.

(4) Заметим, что
\[
(C^{-1}AC)^n = C^{-1}ACC^{-1}AC\ldots C^{-1}AC = C^{-1}A^nC
\]
Осталось воспользоваться дистрибутивностью умножения, т.е. $C^{-1}(A + B)C = C^{-1}AC + C^{-1}BC$.
\end{proof}

\paragraph{Обнуляющий многочлен}

\begin{claim}
\label{claim::PolyAnnihilator}
Пусть $A\in\Matrix{n}$, тогда:
\begin{enumerate}
\item Существует многочлен $f\in\mathbb R[x]$ не равный тождественно нулю степени не больше $n^2$ такой, что $f(A) = 0$.

\item Если для какого-то многочлена $g\in\mathbb R[x]$ имеем $g(A) = 0$, а для $\lambda\in\mathbb R$ имеем $g(\lambda)\neq 0$, то $A-\lambda E$ является обратимой матрицей.
\end{enumerate}
\end{claim}
\begin{proof}
(1) Давайте искать многочлен $f$ с неопределенными коэффициентами в виде $f = a_0 + a_1 x + \ldots + a_{n^2}x^{n^2}$.
Надо чтобы было выполнено равенство $a_0 E + a_1 A + \ldots + a_{n^2}A^{n^2} = 0$.
Последнее равенство означает равенство матрицы слева нулевой матрице справа.
Это условие задается равенством всех $n^2$ ячеек матриц: $(a_0 E + a_1 A + \ldots + a_{n^2}A^{n^2})_{ij} = 0$ для всех $i,j$.
Каждое из этих условий является линейным уравнением вида $a_0 (E)_{ij} + a_1 (A)_{ij} + \ldots + a_{n^2}(A^{n^2})_{ij} = 0$.
То есть у нас есть система с $n^2$ уравнениями и $n^2 + 1 $ неизвестной.
А значит при приведении этой системы к ступенчатому виду у нас обязательно будет свободная переменная, а значит мы сможем найти ненулевое решение.

(2) Разделим многочлен $g$ на $x - \lambda$ с остатком, получим $g(x) = h(x) (x-\lambda) + g(\lambda)$.
Теперь в левую и правую часть равенства подставим $A$.
Получим 
\[
0 = g(A) = h(A)(A - \lambda E) + g(\lambda)E
\]
Перенесем $g(\lambda)E$ в другую сторону и поделим на $-g(\lambda)$, получим
\[
E = -\frac{1}{g(\lambda)}h(A)(A-\lambda E)
\]
То есть $-\frac{1}{g(\lambda)}h(A)$ является обратным к $A-\lambda E$.
\end{proof}

На самом деле можно показать, что найдется многочлен степени не больше $n$, зануляющий нашу матрицу.
Однако, мы пока не в состоянии этого сделать.

\paragraph{Спектр}

Пусть $A\in\Matrix{n}$ определим вещественный спектр матрицы $A$ следующим образом:
\[
\spec_\mathbb R A =\{\lambda \in \mathbb R\mid A - \lambda E\text{ не обратима}\}
\]
Аналогично определяются спектры в рациональном, комплексном и прочих случаях.

\begin{claim}
Пусть $A\in\Matrix{n}$ и пусть $f\in\mathbb R[x]$ такой, что $f(A) = 0$.
Тогда $|\spec_\mathbb R A|\leqslant \deg f$.
В частности спектр всегда конечен.
\end{claim}
\begin{proof}
Покажем, что любой элемент спектра является корнем $f$.
Для этого достаточно показать двойственное утверждение, если $\lambda$ не корень, то $\lambda$ не в спектре.
Но это в точности Утверждение~\ref{claim::PolyAnnihilator} пункт~(2).
\end{proof}

Так как у нас для любой матрицы найдется многочлен степени $n^2$ ее зануляющий, то спектр всегда конечен и его размер не превосходит $n^2$.
Как говорилось выше, на самом деле, можно найти многочлен степени $n$, потому спектр всегда не превосходит по мощности $n$.

\paragraph{Примеры}

\begin{enumerate}
\item Пусть $A\in\Matrix{n}$ -- диагональная матрица с числами $\lambda_1,\ldots, \lambda_n$ на диагонали, т.е.
\[
A = 
\begin{pmatrix}
{\lambda_1}&{}&{}\\
{}&{\ddots}&{}\\
{}&{}&{\lambda_n}
\end{pmatrix}
\]
Так как диагональные матрицы складываются и умножаются поэлементно
\begin{align*}
\begin{pmatrix}
{\lambda_1}&{}&{}\\
{}&{\ddots}&{}\\
{}&{}&{\lambda_n}
\end{pmatrix}
+
\begin{pmatrix}
{\mu_1}&{}&{}\\
{}&{\ddots}&{}\\
{}&{}&{\mu_n}
\end{pmatrix}
&=
\begin{pmatrix}
{\lambda_1 + \mu_1}&{}&{}\\
{}&{\ddots}&{}\\
{}&{}&{\lambda_n + \mu_n}
\end{pmatrix}\\
\begin{pmatrix}
{\lambda_1}&{}&{}\\
{}&{\ddots}&{}\\
{}&{}&{\lambda_n}
\end{pmatrix}
\begin{pmatrix}
{\mu_1}&{}&{}\\
{}&{\ddots}&{}\\
{}&{}&{\mu_n}
\end{pmatrix}
&=
\begin{pmatrix}
{\lambda_1 \mu_1}&{}&{}\\
{}&{\ddots}&{}\\
{}&{}&{\lambda_n \mu_n}
\end{pmatrix}
\end{align*}
То для любого многочлена $f\in\mathbb R[x]$ верно
\[
f
\begin{pmatrix}
{\lambda_1}&{}&{}\\
{}&{\ddots}&{}\\
{}&{}&{\lambda_n}
\end{pmatrix}
=
\begin{pmatrix}
{f(\lambda_1)}&{}&{}\\
{}&{\ddots}&{}\\
{}&{}&{f(\lambda_n)}
\end{pmatrix}
\]
То есть многочлен $f$ зануляет $A$ тогда и только тогда, когда он зануляет все $\lambda_i$.
Например, в качестве такого многочлена подойдет $f(x) = (x-\lambda_1)\ldots(x-\lambda_n)$.


Давайте покажем, что $\spec_\mathbb R A = \{\lambda_1,\ldots, \lambda_n\}$.
Так как многочлен $f$ зануляет $A$, утверждение~\ref{claim::PolyAnnihilator} пункт~(2) влечет, что спектр содержится среди его корней.
Значит, надо показать, что $A-\lambda_i E$ необратим для любого $i$.
Последнее легко видеть, так как $A-\lambda_i$ содержит $0$ на $i$-ом месте на диагонали.

\item Пусть $A=\left(\begin{smallmatrix}{0}&{-1}\\{1}&{0}\end{smallmatrix}\right)\in\Matrix{2}$.
Прямое вычисление показывает, что $A^2 = -E$, то есть многочлен $f(x) = x^2 + 1$ зануляет $A$.
Покажем, что $\spec_\mathbb R A = \varnothing$.
Действительно, по утверждению~\ref{claim::PolyAnnihilator} пункт~(2) спектр должен содержаться среди корней многочлена $f(x) = x^2 + 1$.
Однако, этот многочлен не имеет вещественных корней.
Этот пример объясняет, почему вещественных чисел иногда не достаточно и мы хотим работать с комплексными числами.
Например, в комплексном случае $\spec_\mathbb C A = \{i, - i\}$.
\end{enumerate}

\paragraph{Минимальный многочлен}

Пусть $A\in\Matrix{n}$ -- некоторая матрица.
Рассмотрим множество всех ненулевых многочленов зануляющих $A$.
Формально мы смотрим на множество
\[
M = \{f\in\mathbb R[x]\mid f(A)=0,\,f\neq 0\}
\]
Пусть $f_{min}\in M$ -- многочлен самой маленькой степени со старшим коэффициентом $1$.
Тогда он называется минимальным многочленом матрицы $A$.

\begin{claim}
\label{claim::MinPoly}
Пусть $A\in \Matrix{n}$, тогда верны следующие утверждения:
\begin{enumerate}
\item Минимальный многочлен $f_{min}$ существует.

\item Минимальный многочлен делит любой другой многочлен зануляющий $A$.

\item Минимальный многочлен единственный.

\item $\lambda\in\spec_\mathbb R A$ тогда и только тогда, когда $f_{min}(\lambda) = 0$.
\end{enumerate}
\end{claim}
\begin{proof}
(1).
По утверждению~\ref{claim::PolyAnnihilator} пункт~(1) у нас всегда найдется многочлен зануляющий $A$, а значит $M$ не пусто.
Так как степень не может убывать бесконечно, то мы обязательно найдем многочлен самой маленькой степени, который зануляет $A$.
Осталось разделить его на старший коэффициент.

(2).
Пусть $f\in M$ -- произвольный многочлен, а $f_{min}$ -- какой-то минимальный.
Тогда разделим $f$ на $f_{min}$ с остатком, получим 
\[
f(x) = h(x)f_{min}(x) + r(x)
\]
где $\deg r < \deg f_{min}$.
Подставим в это равенство матрицу $A$, получим
\[
0 = f(A) = h(A)f_{min}(A) + r(A) = r(A)
\]
Значит мы нашли многочлен $r$, который зануляет $A$ и меньше $f_{min}$ по степени.
Такое может быть только если $r(x) = 0$.

(3).
Пусть $f_{min}$ и $f'_{min}$ -- два минимальных многочлена матрицы $A$.
Тогда у них по определению одинаковая степень.
Рассмотрим $r(x) = f_{min}(x) - f'_{min}(x)$.
Многочлен $r(x)$ степени строго меньше, так как оба минимальных имеют старший коэффициент $1$.
Кроме того, $r(A) = f_{min }(A) = f'_{min}(A) = 0$.
А значит $r(x) = 0$.

(4).
Мы уже знаем, что $\spec_\mathbb RA$ лежит среди корней $f_{min}$ (утверждение~\ref{claim::PolyAnnihilator} пункт~(2)).
Осталось показать обратное включение.
Предположим обратное, что есть $\lambda\in \mathbb R$ такое, что $f_{min}(\lambda) = 0$, но $\lambda\notin\spec_\mathbb RA$.
Тогда $f_{min}(x) = (x-\lambda)h(x)$.
Подставим в это равенство матрицу $A$ и получим 
\[
0 = f_{min}(A) = (A - \lambda E)h(A)
\]
Так как $\lambda\notin\spec_\mathbb R A$, то матрица $A-\lambda E$ обратима, а значит на нее можно сократить, то есть $h(A) = 0$ и степень $h$ строго меньше степени $f_{min}$, хотя сам $h$ -- ненулевой многочлен.
Последнее противоречит с нашим предположением о том, что $f_{min}$ минимальный.
\end{proof}

\paragraph{Поиск минимального многочлена}

Пусть задана матрица $A\in \Matrix{n}$.
То мы знаем, что найдется многочлен $f\in\mathbb R[x]$ такой, что $f(A) = 0$.
Кроме того, я сообщил, что $\deg f\leqslant n$.
Давайте обсудим, как найти подобный многочлен.
Будем искать его с неопределенными коэффициентами $f(x) = a_0 + a_1 x + \ldots + a_n x^n$.
Подставим в многочлен матрицу $A$ и приравняем результат к нулю.
\[
f(A) = a_0 E + a_1 A + \ldots + a_n A^n = 0
\]
Тогда то, что написано, является системой из $n^2$ уравнений, а именно
\[
\left\{_{1\leqslant i,j\leqslant n}
E_{ij}a_0 + A_{ij}a_1 + \ldots + (A^n)_{ij}a_n = 0
\right.
\]
Здесь через $B_{ij}$ обозначены коэффициенты матрицы $B$, например, $E_{ij}$ -- это $ij$-ый коэффициент единичной матрицы, а $(A^n)_{ij}$ -- $ij$-ый коэффициент матрицы $A^n$.

Теперь нас интересует ненулевое решение этой системы, у которого как можно больше нулей справа.
Давайте поясню.
Такое решение отвечает зануляющему многочлену.
Мы хотим выбрать такой многочлен как можно меньшей степени.
То есть мы хотим по возможности занулить $a_n$, потом $a_{n-1}$, потом $a_{n-2}$ и так далее, пока находится ненулевое решение.
Предположим, что мы привели систему к ступенчатому виду и $a_k$ -- самая левая свободная переменная.
Я утверждаю, что $k$ и будет степенью минимального многочлена, а чтобы его найти надо положить $a_k = 1$, и все остальные свободные переменные равными нулю.

Действительно, если мы сделали, как описано, то все главные переменные правее $a_k$ тоже равны нулю, ибо они зависят от свободных переменных, стоящих правее, а они в нашем случае нулевые.
То есть $a_k$ будет старший ненулевой коэффициент в искомом многочлене, а значит $k$ будет его степенью.
Почему нельзя найти меньше.
Чтобы найти меньше надо занулить еще и $a_k$.
То есть все свободные переменные в этом случае будут нулевыми, а тогда и все главные будут нулевыми, а это даст нулевое решение, что противоречит нашим намерениям найти ненулевой многочлен.

\paragraph{Вычленение из какого-то зануляющего}

Предположим, что вы угадали какой-нибудь зануляющий многочлен для вашей матрицы $A\in\Matrix{n}$, а именно, нашли какой-то $f\in \mathbb R[x]$ такой, что $f(A) = 0$.
Тогда можно попытаться найти минимальный многочлен среди делителей многочлена $f$.
Эта процедура требует уметь искать эти самые делители.
Но в некоторых ситуациях эта процедура тоже бывает полезна.
Например, в случае большой блочной матрицы $A$ бывает проще найти зануляющий многочлен.

\paragraph{Замечание о спектре}

Можно показать, что любой вещественный многочлен $f\in\mathbb R[x]$ единственным образом разваливается в произведение 
\[
f(x) = (x-\lambda_1)\ldots (x-\lambda_k) q_1(x)\ldots q_r(x)
\]
где числа $\lambda_i\in\mathbb R$ могут повторяться, а $q_i(x)$ -- многочлены второй степени с отрицательным дискриминантом (то есть без вещественных корней).

Пусть теперь $f_{min}$ -- минимальный многочлен некоторой матрицы $A$.
Разложим его подобным образом.
Тогда мы видим из предыдущего утверждения, что $\spec_\mathbb RA$ помнит информацию только о первой половине сомножителей и теряет информацию о квадратичных многочленах.
Однако, если бы мы рассмотрели $f_{min}$ как многочлен с комплексными коэффициентами, то мы бы могли доразложить все $q_i(x)$ на линейные множители и $\spec_\mathbb CA$ помнит информацию о всех сомножителях $f_{min}$.
Еще надо понимать, что каждое $x-\lambda$ может несколько раз участвовать в разложении $f_{min}$, но спектр не помнит это количество, он лишь знает был ли там данный $x-\lambda$ или нет.

\paragraph{Замечание об арифметических свойствах матриц}

Если вы работаете с матрицами, то готовьтесь к тому, чтобы думать про них как про более сложную версию чисел.
А значит, вы будете писать с ними различного рода алгебраические выражения.
Например, для какой-нибудь матрицы $A\in\Matrix{n}$ можно написать $A^3 + 2 A - 3E$.
И предположим вы хотите упростить это выражение как-нибудь, не зная как именно выглядит ваша матрица $A$.
Единственное, что вам поможет в этом случае -- зануляющий многочлен.
Пусть, например, $f(x) = x^2 - 3$ зануляет $A$.
Это значит, что $A^2 = 3 E$.
Тогда выражение выше можно упростить так
\[
A^3 + 2 A - 3 E = 3A + 2 A - 3 E = 5A - 3 E
\]
Роль минимального многочлена заключается в том, что это <<самый лучший>> многочлен, который помнит как можно больше соотношений на матрицу $A$, чтобы можно было упрощать выражения.
Более того, минимальный многочлен автоматически говорит, когда можно делить на выражение от матрицы, а когда нет.
Например, на $A - E$ поделить можно, так как $1$ не является корнем $f$, с другой стороны на матрицы $A \pm\sqrt{3}E$ делить нельзя.

\paragraph{Обратимость и минимальный многочлен}

Обратимость матрицы по определению равносильна тому, что в ее спектре нет нуля, а это то же самое, что у минимального многочлена свободный член отличен от нуля.
В этом случае мы можем явно выразить обратную матрицу через исходную.
Действительно, пусть $f_{min} = a_0 + a_1 x + \ldots + a_m x^m$ для некоторой матрицы $A\in \Matrix{n}$.
Тогда
\[
a_0E + a_1 A + \ldots + a_m A^m =  0 \quad\Rightarrow\quad  A (a_1 E + \ldots + a_m A^{m-1}) =  -a_0 E \quad\Rightarrow\quad A \left(-\frac{a_1}{a_0} E - \ldots -\frac{ a_m}{a_0} A^{m-1}\right) = E
\]
То есть по определению
\[
A^{-1} = -\frac{a_1}{a_0} E - \ldots -\frac{ a_m}{a_0} A^{m-1}
\]
Обратите внимание, что данная формула работает при условии, что $a_0 \neq 0$.
Эта процедура похожа на процедуру избавления от иррациональности в знаменателе дробей или избавления от мнимой части в знаменателе в комплексных дробях.
Это не спроста, это в точности тот же самый метод.


\subsection{Матричные нормы}

Здесь нас ждет пример первого абстрактного определения.
Любое такое определение устроено одинаково, оно состоит из двух частей: первая часть содержит данные, а вторая аксиомы на них.

\paragraph{Нормы}

Будем через $\mathbb R_+$ обозначать множество неотрицательных вещественных чисел, т.е. $\mathbb R_+ = \{r\in \mathbb R\mid r \geqslant 0\}$.

Пусть задано отображение 
\[
\MatrixDim{m}{n}\to \mathbb R_+
\]
т.е. это правило, которое по матрице $A$ выдает некоторое неотрицательное вещественное число, которое будет обозначаться $|A|\in\mathbb R_+$.
Такое отображение называется нормой, если выполнены следующие аксиомы
\begin{enumerate}
\item Для любой матрицы $A\in\MatrixDim{m}{n}$, $|A| = 0$ тогда и только тогда, когда $A = 0$.

\item Для любой матрицы $A\in\MatrixDim{m}{n}$ и любого числа $\lambda\in\mathbb R$ выполнено $|\lambda A| = |\lambda| \cdot |A|$.%
\footnote{Здесь $|\lambda|$ означает модуль числа, а $|A|$ -- норма от матрицы.}

\item Для любых двух матриц $A, B \in\MatrixDim{m}{n}$ выполнено $|A + B|\leqslant |A| + |B|$.
\end{enumerate}


Стоит отметить, что $\mathbb R^n$ можно отождествить с матрицами $\MatrixDim{n}{1}$.
Потому определение выше дает понятие нормы на векторах из $\mathbb R^n$.

\paragraph{Субмультипликативность}

Пусть на квадратных матрицах $\Matrix{n}$ задана некоторая норма.
Тогда она называется субмультипликативной, если выполнено следующее свойство: для любых матриц $A, B\in\Matrix{n}$ выполнено $|AB|\leqslant |A|\cdot |B|$.

\paragraph{Простые примеры}

\begin{enumerate}
\item $1$-норма на $\Matrix{n}$:
\[
|A|_1 = \sum_{ij}|a_{ij}|,\quad A\in\Matrix{n}
\]

\item $\infty$-норма на $\Matrix{n}$:
\[
|A|_\infty = \max_{ij}|a_{ij}|,\quad A\in\Matrix{n}
\]

\item Норма Фробениуса или $2$-норма на $\Matrix{n}$:
\[
|A|_F = |A|_2 = \sqrt{\sum_{ij}|a_{ij}|^2},\quad A\in\Matrix{n}
\]

\item $p$-норма на $\Matrix{n}$:
\[
|A|_p = \sqrt[p\vphantom{\int}]{\sum_{ij}|a_{ij}|^p}
\]
\end{enumerate}

Выясните в качестве упражнения, какие из этих норм являются субмультипликативными.

\paragraph{Индуцированная (согласованная) норма}

Пусть $|{-}|\colon \mathbb R^n \to \mathbb R_+$ -- некоторая фиксированная норма.
Определим индуцированную ей норму $\|{-}\|$ на $\Matrix{n}$ следующим образом:%
\footnote{Можно определить норму на прямоугольных матрицах, но тогда на до иметь две нормы одну на $\mathbb R^n$, а другую на $\mathbb R^m$.
В этом случае индуцированная норма зависит от двух норм, одна фигурирует в знаменателе, другая в числителе.}
\[
\|A\| = \sup_{\substack{x\in\mathbb R^n\\x\neq 0}}\frac{|Ax|}{|x|},\quad A\in\Matrix{n}
\]
Методом пристального взгляда мы замечаем, что отображение $\|{-}\|\colon \Matrix{n}\to \mathbb R_+$ удовлетворяет первым трем аксиомам нормы, а значит действительно является матричной нормой.
Более того, верно следующее.

\begin{claim*}
Для любой нормы $|{-}|\colon \mathbb R^n\to \mathbb R_+$ индуцированная ей норма $\|{-}\|\colon \Matrix{n}\to \mathbb R_+$ является субмультипликативной.
\end{claim*}
\begin{proof}
Из определения индуцированной нормы следует, что $|Ax|/|x|\leqslant \|A\|$ для любого ненулевого $x\in\mathbb R^n$.
Ясно, что тогда для любого $x\in\mathbb R^n$, верно $|Ax|\leqslant \|A\|\cdot|x|$.

Пусть теперь $A, B\in\Matrix{n}$ и нам надо показать, что $\|AB\|\leqslant \|A\|\cdot \|B\|$.
Рассмотрим произвольный $x\in\mathbb R^n$, тогда
\[
|ABx| = |A (Bx)|\leqslant \|A\|\cdot |Bx|\leqslant \|A\| \cdot \|B\|\cdot |x|
\]
Значит
\[
\frac{|ABx|}{|x|}\leqslant \|A\|\cdot\|B\|
\]
для любого ненулевого $x\in\mathbb R^n$.
А значит, можно перейти к супремуму по таким $x$, и следовательно
\[
\|AB\| = \sup_{\substack{x\in\mathbb R^n\\x\neq 0}}\frac{|ABx|}{|x|}\leqslant \|A\|\cdot \|B\|
\]
\end{proof}

\paragraph{Примеры индуцированных норм}

Индуцированные нормы хороши тем, что они субмультипликативны.
Однако, обычно для них не существует явных формул для вычисления.
Ниже мы приведем несколько случаев, когда такие формулы все же возможны.
Все примеры будут даны без доказательств.
\begin{enumerate}
\item Пусть на $\mathbb R^n$ дана $1$-норма $|x| = \sum_i |x_i|$.
Тогда индуцированная норма $\|{-}\|_1$ на матрицах $\Matrix{n}$ будет задаваться по формуле 
\[
\|A\|_1 = \max_j\sum_i|a_{ij}|
\]

\item Пусть теперь на $\mathbb R^n$ дана $\infty$-норма $|x| = \max_i |x_i|$.
Тогда индуцированная норма $\|{-}\|_\infty$ на матрицах $\Matrix{n}$ будет задаваться по формуле
\[
\|A\|_\infty = \max_i\sum_j|a_{ij}|
\]

\item И наконец, пусть на $\mathbb R^n$ дана $2$-норма $|x| = \sqrt{\sum_i |x_i|^2}$.
Тогда индуцированная норма $\|{-}\|_2$ на матрицах $\Matrix{n}$ уже считается более хитрым способом.
Пусть $A\in\Matrix{n}$.
Если взять матрицу $A^tA$, то окажется, что ее спектр состоит целиком из неотрицательных вещественных чисел.
Пусть $\sigma_1$ -- максимальное такое число, тогда $\|A\|_2 = \sqrt{\sigma_1}$.%
\footnote{К этому явлению надо относиться так: есть спектр -- объект из мира алгебры и есть норма -- объект из мира анализа.
Оказывается, что между анализом и алгеброй есть мостик через спектр и индуцированную $2$-норму.
Это позволяет задачи про спектр изучать аналитическими методами и наоборот задачи про сходимости изучать алгебраическими.}
\end{enumerate} 

\subsection{Обзор применения матричных норм}

Для простоты изложения, я буду рассматривать лишь квадратные матрицы ниже.
Хотя какие-то вопросы и можно формулировать и для прямоугольных матриц, это не сделает материал более интересным.

\paragraph{Сходимость}

Основная задача нормы -- дать понятие о близости матриц друг к другу.
А именно, если есть норма $|{-}|\colon \Matrix{n}\to \mathbb R_+$, то можно определить расстояние между матрицами $A, B\in\Matrix{n}$ следующим образом $\rho(A, B) = |A - B|$.
А как только у нас есть понятие расстояния между объектами, мы можем ввести понятие предела и сходимости, а именно: пусть задана последовательность матриц $A_n\in\Matrix{n}$, тогда скажем, что она сходится к матрице $A\in\Matrix{n}$ и будем писать $A_n\to A$, $n\to \infty$ (или $\lim_n A_n = A$), если $\rho(A_n, A)\to 0$ как последовательность чисел при условии $n\to \infty$.

\paragraph{Эквивалентность норм}

Тут встает законный вопрос: у нас есть много различных норм на матрицах, а потому много расстояний, а значит получается огромное количество разных сходимостей (по одной на каждый вид нормы).
Оказывается, что все возможные нормы на матрицах дают расстояния приводящие к одинаковому определению предела.
Ключом к пониманию этого явления является определение эквивалентности норм.
Пусть $|{-}|$ и $|{-}|'$ -- две разные нормы на $\Matrix{n}$.
Будем говорить, что они эквивалентны, если существуют две положительные константы $c_1, c_2\in\mathbb R$ такие, что $c_1 |A|\leqslant |A|'\leqslant c_2|A|$ для всех матриц $A\in \Matrix{n}$.
Если две нормы эквивалентны, то несложно углядеть, что расстояние $\rho(A_n,A)$ в смысле нормы $|{-}|$ стремится к нулю  тогда и только тогда, когда расстояние $\rho'(A_n,A)$ в смысле нормы $|{-}|'$ стремится к нулю.
А значит эквивалентные нормы дают одну и ту же сходимость.
Второй ключевой факт -- все матричные нормы между собой эквивалентны.
Это не очень сложный результат и по сути связан с тем, что единичный куб в $\mathbb R^n$ является компактным множеством.

\paragraph{Анализ для матриц}

Как только у нас есть понятие предела для матриц, мы можем с помощью него развивать анализ аналогичный анализу для обычных чисел.
Например, можно определить хорошо известные гладкие функции от матриц.
Скажем, пусть $A\in\Matrix{n}$, тогда можно сказать, что значит $e^A$, $\ln A$, $\sin A$ или $\cos A$.
Конечно, $\ln A$ будет существовать не для всех матриц $A$, так же как и обычный логарифм существует только для положительных чисел.
Знакомые тождества вроде $e^{\ln A} = A$ и $\ln e^A = A$ будут оставаться справедливыми.
Свойства $e^{A+B}= e^A e^B$ будет верным, в случае если $A$ и $B$ коммутируют.

Одним из простейших подходов к определению таких функций -- использование степенных рядов.
Например, $e^x = \sum_{k\geqslant 0} x^k/k!$.
Тогда можно определить $e^A = \sum_{k\geqslant 0} A^k/k!$.
Доказательство свойств экспоненты тогда сводится к игре в раскрытие скобок со степенными рядами.
И в этой игре нам важно, чтобы символы были перестановочны между собой, потому какие-то свойства могут нарушиться, если исходные матрицы не коммутируют.

Еще стоит отметить такой момент.
Так как для любой матрицы $A$ существует минимальный многочлен ее зануляющий $f_{min}$, то, оказывается, что любую гладкую функцию от $A$ можно приблизить многочленом.
А именно, если $\varphi$ -- некоторая гладкая функция, то для любой матрицы $A$ найдется такой многочлен $f$ (зависящий от $A$) степени меньше, чем $\deg f_{min}$, что $\varphi(A) = f(A)$.
Более того, существует общая алгоритмическая процедура по нахождению такого многочлена $f$.
Эта процедура является эффективным способом вычисления гладких функций от матриц.
