\ProvidesFile{lecture14.tex}[Лекция 14]


\subsection{Оценки ранга суммы и произведения}

Давайте начнем с простой оценки, которая не требует серьезных знаний.

\begin{claim}
Пусть $A,B\in \operatorname{M}_{m\, n}(F)$.
Тогда
\[
|\rk A - \rk B| \leqslant \rk(A + B) \leqslant \rk A + \rk B
\]
\end{claim}
\begin{proof}
Докажем сначала верхнюю оценку.
Пусть $\rk A = r$ и $\rk B = s$, тогда по определению тензорного ранга существуют разложения
\[
A = x_1 y_1^t + \ldots + x_r y_r^t\quad \text{и}\quad
B = u_1 v_1^t + \ldots + u_s v_s^t,\quad x_i, u_i\in F^m,\;y_i,v_i\in F^n
\]
Тогда
\[
A + B = x_1 y_1^t + \ldots + x_r y_r^t + u_1 v_1^t + \ldots + u_s v_s^t
\]
То есть мы получили какое-то разложение матрицы $A+ B$ в сумму матриц ранга $1$ из $r+s$ слагаемых.
Но по определению тензорный ранг -- это длина самого короткого разложения, значит $\rk(A+B) \leqslant r + s = \rk A + \rk B$.

А теперь выведем нижнюю оценку из верхней.
Давайте для определенности считать, что  $\rk A \geqslant \rk B$.
Тогда нам надо доказать, что $\rk A - \rk B \leqslant \rk(A + B)$ или что то же самое, что $\rk A \leqslant \rk (A+B) + \rk B$.
Но в этом случае
\[
\rk (A) = \rk(A + B + (-B)) \leqslant \rk(A+B) +\rk(-B) = \rk (A+B) + \rk(B)
\]
Здесь мы воспользовались верхней оценкой.
\end{proof}


А теперь давайте продемонстрируем, как можно применить векторные пространства и линейные отображения для доказательства более хитрых неравенств на ранги матриц.

\begin{claim}
Пусть $A\in \operatorname{M}_{m\,k}(F)$ и $B\in\operatorname{M}_{k\,n}(F)$.
Тогда
\[
\rk A +\rk B - k \leqslant \rk (AB )\leqslant \min(\rk A, \rk B)
\]
\end{claim}
\begin{proof}
Правая оценка -- не самый большой сюрприз.
Заметим, что столбцы $AB$ есть линейная комбинация столбцов $A$, потому ранг $AB$ не превосходит ранга $A$.
С другой стороны, строки $AB$ есть линейная комбинация строк $B$, потому ранг $AB$ не превосходит ранга $B$.

Теперь перейдем к интересной части доказательства.
Давайте заменим матрицы на линейные отображения следующим образом.
Рассмотрим последовательность 
\[
F^n \stackrel{B}{\longrightarrow} F^k \stackrel{A}{\longrightarrow} F^m
\]
Здесь линейные отображения я буду обозначать теми же самыми буквами, что и матрицы.
Это окажется удобным и не приведет к путанице.
В этом случае доказываемое неравенство превращается в такое:
\[
\dim_F \Im A + \dim_F \Im B - \dim_F F^k \leqslant \dim_F\Im AB
\]

Заметим, что $\Im AB = A(\Im B)$.
Потому мы можем ограничить $A$ со всего пространства $F^k$ только на кусочек $\Im B$, то есть рассмотрим отображение
\[
\Im B \stackrel{A|_{\Im B}}{\longrightarrow} F^m
\]
которое каждый вектор $u$ переводит в $Au$, но только мы рассматриваем только те $u$, что лежат в $\Im B$.%
\footnote{Такое линейное отображение $A|_{\Im B}$ называется ограничением $A$ на $\Im B$.}
Мы выбрали $A|_{\Im B}$ так, что выполнено равенство $\Im A|_{\Im B} = \Im AB$.
Теперь применим утверждение~\ref{claim::ImKer} пункт~(3) на связь размерности ядра и образа к $A|_{\Im B}$, получим
\[
\dim_F \Im AB = \dim_F \Im A|_{\Im B} = \dim_F \Im B - \dim_F \ker A|_{\Im B}
\]
Теперь наша задача оценить $\ker A|_{\Im B}$.
По определению это векторы из $\Im B$, которые под действием $A$ идут в ноль.
То есть это $\Im B \cap \ker A$ по определению.
В частности $\ker A|_{\Im B}\subseteq \ker A$, а значит можно продолжить равенство выше
\[
\dim_F \Im B - \dim_F \ker A|_{\Im B}\geqslant \dim_F \Im B - \dim_F \ker A = \dim_F \Im B - (\dim_F F^k - \dim_F \Im A)
\]
в последнем равенстве мы воспользовались утверждением~\ref{claim::ImKer} пункт~(3) еще раз для оператора $A\colon F^k \to F^m$.
Объединяя полученные равенства и оценку, мы приходим к требуемому результату.
\end{proof}

Доказательство оценки в этом случае получается технически несложным.
Не надо рассматривать дурацкие линейные комбинации строк или столбцов от произведения матриц, которые не пойми как выражаются всякими непотребными формулами из исходных столбцов и строк матриц $A$ и $B$.
Это бонус абстрактного языка и правильного использования нужных объектов.
Расплатой за это является идейная сложность.
Тут надо сообразить и осознать, что мы вообще сделали, но как только вы с этим справитесь, то никаких проблем с доказательством у вас не будет.


\subsection{Классификация для линейных отображений}

Напомню, что если $\varphi \colon V\to U$ -- линейное отображение между векторными пространствами над некоторым полем $F$.
То после выбора базиса $e$ в $V$ и базиса $f$ в $U$ линейное отображение $\varphi$ превращается в матрицу $A\in \operatorname{M}_{m\,n}(F)$, где $n = \dim_F V$ и $m = \dim_F U$.
Если же мы выберем другие базисы $e'$ и $f'$ в пространствах $V$ и $U$, соответственно, то $\varphi$ превратится в матрицу $A'$.
Если $e' = eC$ и $f' = fD$, где $C\in \operatorname{M}_n(F)$ и $D\in\operatorname{M}_m(F)$ -- матрицы перехода к новым базисам, то $A' = D^{-1}A C$.

\begin{claim}
\label{claim::HomClassification}
Пусть $V$ и $U$ -- векторные пространства над полем $F$ размерностей $n$ и $m$, соответственно, и пусть нам даны матрицы $A, B\in \operatorname{M}_{m\,n}(F)$.
Тогда следующие условия эквивалентны:
\begin{enumerate}
\item Существует линейное отображение $\varphi\colon V\to U$ и базисы $e$ и $e'$ в $V$, $f$ и $f'$ в $U$ такие, что $A$ будет матрицей $\varphi$ в базисах $e$ и $f$, а $B$ будет матрицей $\varphi$ в базисах $e'$ и $f'$.

\item $\rk A = \rk B$.
\end{enumerate}
\end{claim}
\begin{proof}
(1)$\Rightarrow$(2).
Здесь есть два доказательства: идейное и техническое.
Я приведу оба.
Давайте начнем с технического.
Оно проще в понимании.

\textbf{Техническое доказательство.} Если такой $\varphi$ и базисы существуют, то $B = D^{-1}AC$ для некоторых невырожденных матриц $C$ и $D$ подходящего размера.
Тогда мы знаем по утверждению~\ref{claim::rkInvariance}, что $\rk A = \rk B$, так как ранг не меняется при умножении на обратимую матрицу слева и справа.

\textbf{Идейное доказательство.} Если зафиксировать базисы $e$ и $f$ в пространствах $V$ и $U$ соответственно, то $\varphi \colon V\to U$ превращается в $A\colon F^n \to F^m$.
Тогда образ $\varphi$ совпадает с линейной оболочкой столбцов матрицы $A$.
А значит $\rk A = \dim_F \Im \varphi$.
Аналогично, $\rk B = \dim_F \Im \varphi$.

(2)$\Rightarrow$(1).
Нам дано, что у матриц $A$ и $B$ равны ранги, а нам надо построить линейное отображение $\varphi\colon V\to U$ и еще пары базисов, чтобы в них матрицы $\varphi$ совпали с $A$ и $B$.

Так как $\rk A = \rk B$, мы можем найти обратимую матрицу $D\in \operatorname{M}_m(F)$ и обратимую матрицу $C\in \operatorname{M}_n(F)$ такие, что $B = D^{-1}AC$.
 Действительно, мы можем преобразованиями строк и столбцов матрицу $A$ привести к виду $R = \left(\begin{smallmatrix}{E}&{0}\\{0}&{0}\end{smallmatrix}\right)$, где $E$ имеет размер $\rk A$.
 То есть $A = D_1 R C_1$.
 Аналогично, $B = D_2 R C_2$.
 Выразим $R$ из первого равенства и подставим во второе.
Получим требуемое.

Теперь выберем произвольный базис $e$ в $V$ и произвольный базис $f$ в $U$.
Чтобы задать линейное отображение из $V$ в $U$ нам надо отправить каждый базисный вектор из $e$ куда-то в $U$ (утверждение~\ref{claim::LinMapExist}).
Сделаем это так: $\varphi e = f A$.
Тогда мы задали линейное отображение $\varphi \colon V\to U$ такое, что в базисах $e$ и $f$ он имеет матрицу $A$.

Далее положим $e' = eC$ и $f' = fD$.
По утверждению~\ref{claim::BasisClassification} о классификации базисов, из обратимости $C$ и $D$ следует, что $e'$ и $f'$ -- тоже базисы.
Тогда оператор $\varphi$ в этих базисах будет иметь матрицу $D^{-1}AC$, которая равна $B$ по построению.
Мы сделали все, что требовалось.
\end{proof}


\newpage
\section{Операции над подпространствами}

До этого мы с вами работали с векторными пространствами <<в терминах элементов>>, то есть основные модификации производились на языке векторов и вектора являлись основным объектом, к которому применялись операции.
Настало время все изменить в своей жизни и сделать шаг вперед в прекрасный новый мир абстракций.
Теперь мы хотим, чтобы основным объектом для нас было векторное пространство, потому мы хотим определить операции над самими векторными пространствами.

\subsection{Сумма и пересечение}

Пусть $V$ -- некоторое векторное пространство над полем $F$ и пусть $U, W \subseteq V$ -- некоторые его подпространства.

\paragraph{Пересечение}

Так как $U$ и $W$ являются подмножествами в $V$, то для них определено теоретико множественное пересечение $U\cap W$.
Легкая проверка показывает, что такое пересечение обязательно является подпространством (оно в частности никогда не пусто, потому что $0$ обязательно лежит в их пересечении).

Чтобы лучше себе представить пересечение, представьте себе трехмерное пространство $V = \mathbb R^3$ и в нем две различные плоскости $U,W\subseteq V$ проходящие через ноль.
Тогда эти плоскости обязательно пересекаются по прямой $U\cap W$.

Пересечение подпространств $U$ и $W$ обладает следующим свойством: это наибольшее подпространство, которое одновременно лежит и в $U$ и в $W$.
Потому про него надо думать, как про НОД векторных подпространств.

\paragraph{Сумма}

Если мы возьмем объединение двух подпространств $U$ и $W$, то это хозяйство уже не обязательно будет подпространством.
Простейший пример $V = \mathbb R^2$ -- плоскость, $U = \langle e_1\rangle$ и $W = \langle e_2 \rangle$ -- координатные прямые.
Тогда объединение $U\cup W$ -- это крест, состоящий из двух прямых.
Но это не векторное подпространство, так как $e_1 + e_2$ там не лежит.

Потому мы определяем сумму подпространств $U + W = \{u + w\mid u\in U,\, w\in W\}$.
То есть мы берем по вектору из каждого подпространства и рассматриваем все их возможные суммы.
Легкая проверка показывает, что $U+W$ обязательно является подпространством в $V$.

Чтобы лучше себе представить сумму, давайте рассмотрим трехмерное пространство $V = \mathbb R^3$, а в качестве $U$ и $W$ -- две произвольные прямые в нем проходящие через ноль.
Тогда сумма $U$ и $W$ -- это плоскость натянутая на эти две прямые.

Сумма подпространств $U$ и $W$ обладает следующим свойством: это наименьшее подпространство, которое одновременно содержит и $U$ и $W$.
Потому про него надо думать, как про НОК векторных подпространств.

\begin{claim}
Пусть $V$ -- векторное пространство над полем $F$ и $U,W\subseteq V$ -- некоторые подпространства, тогда 
\[
\dim_F (U + W) = \dim_F U + \dim_F W - \dim_F (U\cap W)
\]
\end{claim}
\begin{proof}
Пусть $e=(e_1,\ldots,e_r)$ -- базис пересечения $U\cap W$.
Теперь вспомним, что это линейно независимое подмножество во всем $U$ и дополним его там до базиса $U$ с помощью векторов $f=(f_1,\ldots, f_p)$.
Аналогично, базис $U\cap W$ будет линейно независимым подмножеством в $W$, а значит его можно дополнить до базиса $W$ векторами $h=(h_1,\ldots,h_t)$.
Давайте покажем, что множество $e_1,\ldots,e_r, f_1,\ldots,f_p,h_1,\ldots,h_t$ является базисом подпространства $U + W$.
Тогда из этого и будет следовать необходимое утверждение.

Любой вектор из $U+W$ имеет вид $u+w$.
Тогда $u$ раскладывается по $e$ и $f$, а вектор $w$ раскладывается через $e$ и $h$.
А значит система $e\cup f\cup h$ порождает $U + W$.
Теперь надо показать, что она линейно независима.
Рассмотрим произвольную линейную комбинацию
\[
e x + fy + hz = 0, \text{ где }x\in F^r,\, y\in F^p,\, z\in F^t
\]
Тогда
\[
U \ni ex +fy = -hz \in W
\]
а значит лежит в пересечении $U\cap W$.
В частности $hz \in U\cap W$.
Но все что попадает в пересечение раскладывается по $e$.
Значит найдется какое-то $z'\in F^r$ такое, что $hz = ez'$.
Но это означает, что линейная комбинация $h\cup e$ равна нулю, так как они образовывали базис $W$, то $z =0$ и $z' = 0$.
А значит $-hz = 0$.
Что влечет $ex + fy = 0$.
Так как $e \cup f$ образовывали базис $U$, последнее означает, что $x = 0$ и $y = 0$.
То есть все коэффициенты линейной комбинации на $e\cup f\cup h$ равны нулю, что и требовалось.
\end{proof}


\paragraph{Бесконечные суммы и пересечения}

Если $V$ -- векторное пространство над полем $F$ и в нем дано семейство подпространств $U_\alpha \subseteq V$, где $\alpha\in X$, то можно определить пересечение и сумму этого семейства.
С пересечением все просто, это обычное теоретико-множественное пересечение $\bigcap_{\alpha} U_\alpha$ и как можно заметить, это подмножество является подпространством.
Сумма же определяется следующим образом
\[
\sum_{\alpha \in X} U_\alpha = \{u_{\alpha_1}+\ldots+u_{\alpha_k} \mid k\in\mathbb Z_{\geqslant 0},\; u_{\alpha_i}\in U_{\alpha_i}\}
\]
То есть мы берем все возможные конечные суммы элементов из пространств $U_\alpha$ и складываем в один мешок.
Как мы можем заметить, сумма таких выражений снова выражение такого вида и после умножения такого выражения на скаляр опять остается выражение такого вида.
Значит, только что определенное подмножество является подпространством.
В случае конечного числа слагаемых получаем следующее определение
\[
U_1 + \ldots + U_k = \{u_1 + \ldots + u_k \mid u_i\in U_i\}
\]

Определенные выше пересечение и сумма семейства $U_\alpha$ обладают следующим свойством:
\begin{enumerate}
\item Пересечение $\bigcap_{\alpha} U_\alpha$ является наибольшим подпространством, содержащимся во всех $U_\alpha$.
Здесь под наибольшим имеется в виду самое большое относительно порядка включения подпространств, то есть такое подпространство, что любое подпространство содержащееся во всех $U_\alpha$ в нем содержится.
В частности пересечение можно определить, как объединение (или сумму) всех подпространств лежащих во всех $U_\alpha$.

\item Сумма $\sum_\alpha U_\alpha$ является наименьшим подпространством, содержащим все $U_\alpha$.
Здесь под наименьшим имеется в виду самое маленькое относительно порядка включения подпространств, то есть такое подпространство, которое содержится в любом содержащем все $U_\alpha$.
В частности сумму можно определить как пересечение всех подпространств, содержащих все $U_\alpha$.

\item Кроме того, отметим, что $\sum_{\alpha} U_\alpha$ совпадает с линейной оболочкой $\langle \bigcup_\alpha U_\alpha \rangle$.
В частности для двух подпространств $U,W\subseteq V$ верно $U + W = \langle U, W\rangle = \langle U\cup W\rangle$.
Таким образом к сумме можно относиться как к более удобному синтаксису задания линейных оболочек.
\end{enumerate}




\subsection{Прямые суммы}

Если $V$ -- векторное пространство над полем $F$ и $U_1,\ldots,U_k\subseteq V$ -- его подпространства такие, что $U_1 + \ldots + U_k = V$.
Тогда ясно, что можно не экономить на $U_i$ и, заменив каждое из них на большее подпространство, равенство сохранится.
Потому интересно в таких суммах выбирать $U_i$ как можно меньше и быть экономными.
Вопрос о том на сколько экономно и как можно и нужно выбирать $U_i$ в таких ситуациях, мы и обсудим в этом разделе.
Но в начале новая операция над пространствами.

\begin{definition}
\label{def::IndepSpaces}
Пусть $V$ -- векторное пространство и $U_1,\ldots,U_k\subseteq V$ -- его некоторые подпространства.
В этом случае $U_1,\ldots, U_k$ называются линейно независимыми, если для любых элементов $u_1\in U_1, \ldots, u_k\in U_k$ условие $u_1 + \ldots + u_k = 0$ влечет $u_i = 0$ для всех $i$.
\end{definition}

\begin{definition}
Если нам даны произвольные векторные пространства $V_1,\ldots, V_k$, то их декартово произведение $V_1\times\ldots\times V_k$ обладает структурой векторного пространства.
Действительно, его элементы -- это наборы векторов $(v_1,\ldots,v_k)$.
Тогда относительно поэлементных операций -- это будет векторное пространство, то есть
$(v_1,\ldots,v_k) + (u_1,\ldots,u_k) = (v_1 + u_1,\ldots,v_k + u_k)$ и $\lambda(v_1,\ldots,v_k) = (\lambda v_1, \ldots, \lambda v_k)$.
Пространство $V_1\times\ldots \times V_k$ называется внешней прямой суммой пространств $V_1,\ldots, V_k$.
\end{definition}

Предположим, что у нас есть некоторое векторное пространство $V$ и его подпространства $U_1,\ldots,U_k\subseteq V$.
Тогда можно определить отображение $U_1\times \ldots \times U_k \to V$ по правилу $(u_1,\ldots,u_k) \mapsto u_1 + \ldots + u_k$.
Заметим, что это отображение будет линейным и образом этого отображения будет сумма подпространств $U_1 + \ldots + U_k$.

\begin{claim}
\label{claim::DirectSum}
Пусть $V$ -- векторное пространство над полем $F$ и $U_1,\ldots,U_k \subseteq V$ -- его подпространства такие, что $V = U_1+\ldots + U_k$.
Тогда следующие условия эквивалентны
\begin{enumerate}
\item $U_1,\ldots,U_k$ -- линейно независимые подпространства.

\item Любой вектор $v\in V$ единственным образом представляется в виде суммы $v = u_1 + \ldots + u_k$, где $u_i \in U_i$.

\item Если $e_i$ -- базис $U_i$, то $\bigcup_{i=1}^k e_i$ -- базис $V$.

\item $\dim_F V = \sum_{i=1}^k \dim_F U_i$.

\item $U_i \cap (\sum_{j\neq i}U_j) = 0$ для любого $i$.

\item Отображение $U_1\times \ldots \times U_k\to V$ по правилу $(u_1,\ldots,u_k)\mapsto u_1 + \ldots + u_k$ является изоморфизмом.

\end{enumerate}
\end{claim}
\begin{proof}
(1)$\Leftrightarrow$(2).
($\Leftarrow$) Если любой вектор единственным образом представляется в виде суммы $u_i$, то в частности это верно для $0$, но он уже представляется в виде $0 = 0 + \ldots + 0$, а значит никаких других представлений у него нет.
($\Rightarrow$) Если $v = v_1 + \ldots + v_k$ и $v = u_1 + \ldots + u_k$, то, вычтя из одного другое, получим $0 = (v_1 - u_1) + \ldots + (v_k - u_k)$.
А значит $u_i = v_i$, что и требовалось.

(1)$\Leftrightarrow$(3).
($\Rightarrow$) Достаточно показать, что $\bigcup_i e_i$ является линейно независимым.
Пусть $\sum_i e_i x_i = 0$ -- некоторая линейная комбинация, где $x_i\in F^{\dim_F U_i}$.
Но тогда по (1) все $e_i x_i = 0$.
А так как $e_i$ линейно независимо, то $x_i = 0$, что и требовалось.
($\Leftarrow$) Пусть $u_1 + \ldots + u_k = 0$.
Разложим каждый из них по базису $u_i = e_i x_i$.
Тогда $\sum_i e_i x_i = 0$.
Так как объединение всех $e_i$ -- базис, то $x_i = 0$, то есть $u_i = e_i x_i = 0$, что и требовалось.

(3)$\Leftrightarrow$(4).
($\Rightarrow$) Выполнено по определению, так как размерность -- это количество векторов в любом базисе.
($\Leftarrow$) Если $e_i$ -- это базис $U_i$, то система $\bigcup_{i=1}^k e_i$ порождает $V$.
Чтобы проверить, что это базис, достаточно показать, что в ней $\dim_F V$ элементов.
Но так как эта система порождающая, то достаточно проверить, что в ней не больше $\dim_F V$ элементов.
Теперь прямое вычисление показывает, что
\[
|\bigcup_{i=1}^k e_i|\leqslant \sum_{i=1}^k |e_i| = \sum_{i=1}^k \dim_F U_i = \dim_F V
\]


(1)$\Leftrightarrow$(5).
($\Rightarrow$) Пусть $u\in U_i\cap (\sum_{j\neq i} U_j)$, тогда $u = u_i$ и $u = \sum_{j\neq i} u_j$, а значит $u_i = \sum_{j\neq i} u _j$.
Перенесем все в одну сторону, получим $\sum_{j\neq i} u _j - u_i = 0$.
А значит все $u_i = 0$ по (1).
А значит $u = u_i = 0$, что и требовалось.
($\Leftarrow$) Пусть $u_1 + \ldots + u_k = 0$ и какой-нибудь $u_i\neq 0$.
Тогда $u_i = - \sum_{j\neq i}u_j$.
Мы получили ненулевой вектор в пересечении $U_i \cap (\sum_{j\neq i}U_j)$, противоречие.

(2)$\Leftrightarrow$(6).
Это переформулировка одного и того же свойства.

\end{proof}

\begin{definition}
Пусть $V$ -- векторное пространство над полем $F$ и $U_1,\ldots,U_k \subseteq V$ -- его подпространства такие, что $V = U_1+\ldots + U_k$ обладающие одним из эквивалентных свойств из предыдущего утверждения.
Тогда сумма $V = U_1+\ldots + U_k$  называется прямой и обозначается $V = U_1\oplus\ldots\oplus U_k$.
Тогда говорят, что $V$ является внутренней прямой суммой подпространств $U_1,\ldots,U_k$.
\end{definition}

Прямая сумма -- это обычная сумма подпространств, только с условием, что эти подпространства удовлетворяют некоторому дополнительному свойству.
Кроме того, свойство (6) из предыдущего утверждения означает, что прямая сумма векторных подпространств совпадает с внешней прямой суммой этих же подпространств рассматриваемых как абстрактные векторные пространства.
Бонус от этого вот какой: с внешней прямой суммой работать очень просто, так как это наборы векторов, их легко складывать, умножать на числа и сравнивать друг с другом.
А так как внутренняя прямая сумма от этой не отличается (с точностью до изоморфизма), то изучать одно это все равно, что изучать другое.


\paragraph{Примеры}

\begin{enumerate}
\item Пусть $V$ -- векторное пространство с базисом $e_1,\ldots,e_n$.
Положим $U_i = \langle e_i \rangle$, тогда $V = U_1 \oplus \ldots \oplus U_n$.
То есть мы раскладываем все пространство в прямую сумму прямых натянутых на базисные векторы.

\item Условие (5) очень просто переформулируется в случае двух подпространств.
Пусть $U, W\subseteq V$, тогда $V = U \oplus W$ тогда и только тогда, когда $V = U + W$ и $U \cap W = 0$.

\item Давайте посмотрим на предыдущий пример в конкретном случае.
Пусть $V=\mathbb R^3$, $U$ -- некоторая плоскость проходящая через $0$, а $W$ -- прямая проходящая через $0$ и не содержащаяся в $U$.
Тогда пересечение прямой и плоскости есть ноль, а наименьшее подпространство, которое их содержит -- это все пространство $V$.
Значит $V = U \oplus W$.

\item Условие (5) сильнее условия $U_i \cap U_j = 0$.
Вот пример.
Пусть $V = \mathbb R^2$, $U_1 = \langle e_1\rangle$, $U_2 = \langle e_2\rangle$, $U_3 = \langle e_1 + e_2\rangle$.
То есть я беру две координатные прямые на плоскости и прямую под углом $45$ градусов через первый квадрант.
Тогда все попарные пересечения прямых есть ноль.
Но $U_i + U_j = V$ для любой пары прямых, потому условие (5) не выполнено.
\end{enumerate}
