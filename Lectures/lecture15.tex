\ProvidesFile{lecture15.tex}[Лекция 15]


\paragraph{Связь матрицы отображения с операциями}

\begin{claim}
Пусть $V$ и $U$ -- некоторые векторные пространства над полем $F$ размерностей $n$ и $m$ соответственно и пусть $e=(e_1,\ldots,e_n)$ и $f = (f_1,\ldots,f_m)$ -- базисы пространств $V$ и $U$.
Тогда отображение
\begin{align*}
\Hom_F (V,U) &\to \operatorname{M}_{m\,n}(F)\\
\varphi &\mapsto A_\varphi
\end{align*}
является изоморфизмом векторных пространств, то есть выполнено
\begin{enumerate}
\item $A_{\varphi + \psi} = A_\varphi + A_\psi$.

\item $A_{\lambda \varphi} = \lambda A_\varphi$.
\end{enumerate}
\end{claim}
\begin{proof}
Биективность этого отображения мы уже знаем в других терминах: при зафиксированных базисах $e$ и $f$ в обоих пространствах для любого линейного отображения $\varphi$ существует единственная матрица $A_\varphi$ такая, что $\varphi e = f A_\varphi$.

Теперь надо проверить линейность этого отображения.
По определению
$(\varphi + \psi)e = f A_{\varphi + \psi}$.
С другой стороны
\[
(\varphi+\psi)e = \varphi e + \psi e = f A_\varphi + f A_\psi = f(A_\varphi + A_\psi)
\]
Из единственности следует, что $A_{\varphi + \psi} = A_\varphi + A_\psi$.
Аналогично, $(\lambda \varphi) e = f A_{\lambda \varphi}$ с одной стороны и
\[
(\lambda \varphi) e = \lambda (\varphi e) = \lambda f A_\varphi = f (\lambda A_\varphi)
\]
с другой.
Потому из единственности получаем $A_{\lambda \varphi} = \lambda A_\varphi$.
\end{proof}

Таким образом изучать линейные отображения между двумя векторными пространствами -- это все равно что изучать матрицы, причем с учетом операций на матрицах, а не просто как множество.

\begin{claim}
Пусть $V$, $U$ и $W$ -- векторные пространства размерностей $m$, $n$ и $k$ соответственно с базисами $e$, $f$ и $h$ соответственно.
Пусть $\varphi\colon V\to U$ и $\psi \colon U\to W$, тогда $A_{\psi \varphi} = A_\psi A_\varphi$.
\end{claim}
\begin{proof}
Доказательство -- прямая проверка в лоб по определению.
С одной стороны $(\psi \varphi) e = h A_{\psi \varphi}$.
С другой
\[
(\psi\varphi) e = \psi (\varphi e) = \psi (f A_\varphi) = (\psi f) A_\varphi = h A_\psi A_\varphi
\]
И результат следует из единственности.
\end{proof}

Все эти результаты вместе взятые означают, что выбрав базис, мы можем отождествить все конечномерные пространства с какими-то конкретными пространствами вида $F^n$, а линейные отображения между ними на матрицы соответствующих размеров.
Тогда изучать конечно мерные векторные пространства -- это то же самое, что изучать конкретные векторные пространства столбцов с матричными отображениями между ними.
Потому, если что-то глобально доказано для вектор столбцов, оно автоматом есть и для конечно мерных векторных пространств.
Более того, если какой-то факт о векторах бесконечномерного векторного пространства требует лишь конечного набора векторов из него, то они живут в конечномерном подпространстве, а значит подобные факты для бесконечно мерных пространств автоматически следуют из случая конечномерных, а значит и из случая вектор столбцов.

\subsection{Ядро и образ}

\begin{definition}
Пусть $V$ и $U$ -- векторные пространства над некоторым полем $F$ и $\varphi\colon V\to U$ -- линейное отображение.
Тогда ядром $\varphi$ называется следующее множество
\[
\ker \varphi = \{v\in V \mid \varphi(v) = 0\} = \varphi^{-1}(0)
\]
-- прообраз нуля, а образом $\varphi$ называется
\[
\Im \varphi = \{\varphi(v)\mid v\in V\} = \varphi(V)
\]
-- теоретико множественный образ отображения $\varphi$.
\end{definition}

Отметим, что ядро и образ никогда не пусты, они всегда содержат $0$.
Кроме того, простая проверка показывает, что оба этих множества являются подпространствами, а именно: $\ker\varphi$ -- подпространство в $V$, а $\Im \varphi $ -- подпространство в $U$.

\paragraph{Пример}

Пусть $\varphi \colon F^n\to F^m$ -- линейное отображение задаваемое матрицей $A\in\operatorname{M}_{m\,n}(F)$, и пусть $A = (A_1|\ldots|A_n)$, где $A_i\in F^m$ -- столбцы матрицы $A$.
Тогда
\begin{itemize}
\item $\Im \varphi = \langle A_1,\ldots,A_n\rangle$.

\item $\ker \varphi = \{y\in F^n\mid Ay = 0\}$.
\end{itemize}
Второе получается просто по определению.
Для того чтобы увидеть первое, поймем, что образ $\varphi$ состоит из векторов вида $Ax = x_1 A_1 + \ldots + x_n A_n$.


\begin{claim}
\label{claim::ImKer}
Пусть $V$ и $U$ -- векторные пространства над полем $F$ и $\varphi \colon V\to U$ -- линейное отображение.
Тогда
\begin{enumerate}
\item $\varphi$ сюръективно тогда и только тогда, когда $\Im \varphi = U$.

\item $\varphi$ инъективно тогда и только тогда, когда $\ker \varphi = 0$.

\item $\dim_F \ker \varphi + \dim_F \Im \varphi = \dim_F V$.
\end{enumerate}
\end{claim}
\begin{proof}
(1) Это просто переформулировка сюръективности на другом языке.

(2) Так как $\ker \varphi = \varphi^{-1}(0)$ и прообраз всегда содержит $0$, то из инъективности вытекает, что $\ker \varphi = 0$.
Наоборот, пусть $\varphi (v) = \varphi(v')$, тогда $\varphi(v) - \varphi (v') = 0$.
А значит,  $\varphi(v - v') = 0$.
То есть $v - v'$ лежит в ядре, а значит равен $0$, что и требовалось.

(3) Это самое интересное.
Выберем базис ядра $\ker \varphi$, пусть это будет $e_1,\ldots, e_k$.
Тогда дополним его до базиса всего пространства $V$ с помощью векторов $e_{k+1}, \ldots, e_n$.
Тогда образ $\varphi$ является линейной оболочкой векторов $\varphi(e_1),\ldots, \varphi(e_n)$.
Так как первые $k$ из них лежат в ядре и идут в ноль, то $\Im \varphi = \langle \varphi(e_{k+1}), \ldots, \varphi(e_n)\rangle$.
Потому если мы покажем, что $\varphi(e_{k+1}), \ldots,\varphi(e_n)$ является базисом $\Im\varphi$, то мы получим требуемое.

Для доказательства последнего достаточно показать линейную независимость $\varphi(e_{k+1}),\ldots,\varphi(e_n)$.
Рассмотрим их какую-нибудь линейную комбинацию равную нулю
\[
\lambda_{k+1}\varphi(e_{k+1})+\ldots+\lambda_n\varphi(e_n) = \varphi(\lambda_{k+1}e_{k+1}+\ldots+\lambda_n e_n) = 0
\]
Значит $\lambda_{k+1}e_{k+1}+\ldots+\lambda_n e_n\in \ker \varphi$.
А все что лежит в ядре раскладывается по базису ядра $e_1,\ldots, e_k$, значит найдется выражение вида
\[
\lambda_{k+1}e_{k+1}+\ldots+\lambda_n e_n = \lambda_1 e_1 + \ldots + \lambda_k e_k
\] 
Перенеся все в одну сторону, мы получим линейную комбинацию на $e_1,\ldots,e_n$, который по построению базис, значит, все $\lambda_i$ равны нулю.
Откуда следует требуемое.
\end{proof}


\subsection{Оценки ранга суммы и произведения}

Давайте начнем с простой оценки, которая не требует серьезных знаний.

\begin{claim}
Пусть $A,B\in \operatorname{M}_{m\, n}(F)$.
Тогда
\[
|\rk A - \rk B| \leqslant \rk(A + B) \leqslant \rk A + \rk B
\]
\end{claim}
\begin{proof}
Докажем сначала верхнюю оценку.
Пусть $\rk A = r$ и $\rk B = s$, тогда по определению тензорного ранга существуют разложения
\[
A = x_1 y_1^t + \ldots + x_r y_r^t\quad \text{и}\quad
B = u_1 v_1^t + \ldots + u_s v_s^t,\quad x_i, u_i\in F^m,\;y_i,v_i\in F^n
\]
Тогда
\[
A + B = x_1 y_1^t + \ldots + x_r y_r^t + u_1 v_1^t + \ldots + u_s v_s^t
\]
То есть мы получили какое-то разложение матрицы $A+ B$ в сумму матриц ранга $1$ из $r+s$ слагаемых.
Но по определению тензорный ранг -- это длина самого короткого разложения, значит $\rk(A+B) \leqslant r + s = \rk A + \rk B$.

А теперь выведем нижнюю оценку из верхней.
Давайте для определенности считать, что  $\rk A \geqslant \rk B$.
Тогда нам надо доказать, что $\rk A - \rk B \leqslant \rk(A + B)$ или что то же самое, что $\rk A \leqslant \rk (A+B) + \rk B$.
Но в этом случае
\[
\rk (A) = \rk(A + B + (-B)) \leqslant \rk(A+B) +\rk(-B) = \rk (A+B) + \rk(B)
\]
Здесь мы воспользовались верхней оценкой.
\end{proof}


А теперь давайте продемонстрируем, как можно применить векторные пространства и линейные отображения для доказательства более хитрых неравенств на ранги матриц.

\begin{claim}
Пусть $A\in \operatorname{M}_{m\,k}(F)$ и $B\in\operatorname{M}_{k\,n}(F)$.
Тогда
\[
\rk A +\rk B - k \leqslant \rk (AB )\leqslant \min(\rk A, \rk B)
\]
\end{claim}
\begin{proof}
Правая оценка -- не самый большой сюрприз.
Заметим, что столбцы $AB$ есть линейная комбинация столбцов $A$, потому ранг $AB$ не превосходит ранга $A$.
С другой стороны, строки $AB$ есть линейная комбинация строк $B$, потому ранг $AB$ не превосходит ранга $B$.

Теперь перейдем к интересной части доказательства.
Давайте заменим матрицы на линейные отображения следующим образом.
Рассмотрим последовательность 
\[
F^n \stackrel{B}{\longrightarrow} F^k \stackrel{A}{\longrightarrow} F^m
\]
Здесь линейные отображения я буду обозначать теми же самыми буквами, что и матрицы.
Это окажется удобным и не приведет к путанице.
В этом случае доказываемое неравенство превращается в такое:
\[
\dim_F \Im A + \dim_F \Im B - \dim_F F^k \leqslant \dim_F\Im AB
\]

Заметим, что $\Im AB = A(\Im B)$.
Потому мы можем ограничить $A$ со всего пространства $F^k$ только на кусочек $\Im B$, то есть рассмотрим отображение
\[
\Im B \stackrel{A|_{\Im B}}{\longrightarrow} F^m
\]
которое каждый вектор $u$ переводит в $Au$, но только мы рассматриваем только те $u$, что лежат в $\Im B$.%
\footnote{Такое линейное отображение $A|_{\Im B}$ называется ограничением $A$ на $\Im B$.}
Мы выбрали $A|_{\Im B}$ так, что выполнено равенство $\Im A|_{\Im B} = \Im AB$.
Теперь применим утверждение~\ref{claim::ImKer} пункт~(3) на связь размерности ядра и образа к $A|_{\Im B}$, получим
\[
\dim_F \Im AB = \dim_F \Im A|_{\Im B} = \dim_F \Im B - \dim_F \ker A|_{\Im B}
\]
Теперь наша задача оценить $\ker A|_{\Im B}$.
По определению это векторы из $\Im B$, которые под действием $A$ идут в ноль.
То есть это $\Im B \cap \ker A$ по определению.
В частности $\ker A|_{\Im B}\subseteq \ker A$, а значит можно продолжить равенство выше
\[
\dim_F \Im B - \dim_F \ker A|_{\Im B}\geqslant \dim_F \Im B - \dim_F \ker A = \dim_F \Im B - (\dim_F F^k - \dim_F \Im A)
\]
в последнем равенстве мы воспользовались утверждением~\ref{claim::ImKer} пункт~(3) еще раз для оператора $A\colon F^k \to F^m$.
Объединяя полученные равенства и оценку, мы приходим к требуемому результату.
\end{proof}

Доказательство оценки в этом случае получается технически несложным.
Не надо рассматривать дурацкие линейные комбинации строк или столбцов от произведения матриц, которые не пойми как выражаются всякими непотребными формулами из исходных столбцов и строк матриц $A$ и $B$.
Это бонус абстрактного языка и правильного использования нужных объектов.
Расплатой за это является идейная сложность.
Тут надо сообразить и осознать, что мы вообще сделали, но как только вы с этим справитесь, то никаких проблем с доказательством у вас не будет.


\subsection{Классификация для линейных отображений}

Напомню, что если $\varphi \colon V\to U$ -- линейное отображение между векторными пространствами над некоторым полем $F$.
То после выбора базиса $e$ в $V$ и базиса $f$ в $U$ линейное отображение $\varphi$ превращается в матрицу $A\in \operatorname{M}_{m\,n}(F)$, где $n = \dim_F V$ и $m = \dim_F U$.
Если же мы выберем другие базисы $e'$ и $f'$ в пространствах $V$ и $U$, соответственно, то $\varphi$ превратится в матрицу $A'$.
Если $e' = eC$ и $f' = fD$, где $C\in \operatorname{M}_n(F)$ и $D\in\operatorname{M}_m(F)$ -- матрицы перехода к новым базисам, то $A' = D^{-1}A C$.

\begin{claim}
\label{claim::HomClassification}
Пусть $V$ и $U$ -- векторные пространства над полем $F$ размерностей $n$ и $m$, соответственно, и пусть нам даны матрицы $A, B\in \operatorname{M}_{m\,n}(F)$.
Тогда следующие условия эквивалентны:
\begin{enumerate}
\item Существует линейное отображение $\varphi\colon V\to U$ и базисы $e$ и $e'$ в $V$, $f$ и $f'$ в $U$ такие, что $A$ будет матрицей $\varphi$ в базисах $e$ и $f$, а $B$ будет матрицей $\varphi$ в базисах $e'$ и $f'$.

\item $\rk A = \rk B$.
\end{enumerate}
\end{claim}
\begin{proof}
(1)$\Rightarrow$(2).
Здесь есть два доказательства: идейное и техническое.
Я приведу оба.
Давайте начнем с технического.
Оно проще в понимании.

\textbf{Техническое доказательство.} Если такой $\varphi$ и базисы существуют, то $B = D^{-1}AC$ для некоторых невырожденных матриц $C$ и $D$ подходящего размера.
Тогда мы знаем по утверждению~\ref{claim::rkInvariance}, что $\rk A = \rk B$, так как ранг не меняется при умножении на обратимую матрицу слева и справа.

\textbf{Идейное доказательство.} Если зафиксировать базисы $e$ и $f$ в пространствах $V$ и $U$ соответственно, то $\varphi \colon V\to U$ превращается в $A\colon F^n \to F^m$.
Тогда образ $\varphi$ совпадает с линейной оболочкой столбцов матрицы $A$.
А значит $\rk A = \dim_F \Im \varphi$.
Аналогично, $\rk B = \dim_F \Im \varphi$.

(2)$\Rightarrow$(1).
Нам дано, что у матриц $A$ и $B$ равны ранги, а нам надо построить линейное отображение $\varphi\colon V\to U$ и еще пары базисов, чтобы в них матрицы $\varphi$ совпали с $A$ и $B$.

Так как $\rk A = \rk B$, мы можем найти обратимую матрицу $D\in \operatorname{M}_m(F)$ и обратимую матрицу $C\in \operatorname{M}_n(F)$ такие, что $B = D^{-1}AC$.
 Действительно, мы можем преобразованиями строк и столбцов матрицу $A$ привести к виду $R = \left(\begin{smallmatrix}{E}&{0}\\{0}&{0}\end{smallmatrix}\right)$, где $E$ имеет размер $\rk A$.
 То есть $A = D_1 R C_1$.
 Аналогично, $B = D_2 R C_2$.
 Выразим $R$ из первого равенства и подставим во второе.
Получим требуемое.

Теперь выберем произвольный базис $e$ в $V$ и произвольный базис $f$ в $U$.
Чтобы задать линейное отображение из $V$ в $U$ нам надо отправить каждый базисный вектор из $e$ куда-то в $U$ (утверждение~\ref{claim::LinMapExist}).
Сделаем это так: $\varphi e = f A$.
Тогда мы задали линейное отображение $\varphi \colon V\to U$ такое, что в базисах $e$ и $f$ он имеет матрицу $A$.

Далее положим $e' = eC$ и $f' = fD$.
По утверждению~\ref{claim::BasisClassification} о классификации базисов, из обратимости $C$ и $D$ следует, что $e'$ и $f'$ -- тоже базисы.
Тогда оператор $\varphi$ в этих базисах будет иметь матрицу $D^{-1}AC$, которая равна $B$ по построению.
Мы сделали все, что требовалось.
\end{proof}


\newpage
\section{Операции над подпространствами}

До этого мы с вами работали с векторными пространствами <<в терминах элементов>>, то есть основные модификации производились на языке векторов и вектора являлись основным объектом, к которому применялись операции.
Настало время все изменить в своей жизни и сделать шаг вперед в прекрасный новый мир абстракций.
Теперь мы хотим, чтобы основным объектом для нас было векторное пространство, потому мы хотим определить операции над самими векторными пространствами.

\subsection{Сумма и пересечение}

Пусть $V$ -- некоторое векторное пространство над полем $F$ и пусть $U, W \subseteq V$ -- некоторые его подпространства.

\paragraph{Пересечение}

Так как $U$ и $W$ являются подмножествами в $V$, то для них определено теоретико множественное пересечение $U\cap W$.
Легкая проверка показывает, что такое пересечение обязательно является подпространством (оно в частности никогда не пусто, потому что $0$ обязательно лежит в их пересечении).

Чтобы лучше себе представить пересечение, представьте себе трехмерное пространство $V = \mathbb R^3$ и в нем две различные плоскости $U,W\subseteq V$ проходящие через ноль.
Тогда эти плоскости обязательно пересекаются по прямой $U\cap W$.

Пересечение подпространств $U$ и $W$ обладает следующим свойством: это наибольшее подпространство, которое одновременно лежит и в $U$ и в $W$.
Потому про него надо думать, как про НОД векторных подпространств.

\paragraph{Сумма}

Если мы возьмем объединение двух подпространств $U$ и $W$, то это хозяйство уже не обязательно будет подпространством.
Простейший пример $V = \mathbb R^2$ -- плоскость, $U = \langle e_1\rangle$ и $W = \langle e_2 \rangle$ -- координатные прямые.
Тогда объединение $U\cup W$ -- это крест, состоящий из двух прямых.
Но это не векторное подпространство, так как $e_1 + e_2$ там не лежит.

Потому мы определяем сумму подпространств $U + W = \{u + w\mid u\in U,\, w\in W\}$.
То есть мы берем по вектору из каждого подпространства и рассматриваем все их возможные суммы.
Легкая проверка показывает, что $U+W$ обязательно является подпространством в $V$.

Чтобы лучше себе представить сумму, давайте рассмотрим трехмерное пространство $V = \mathbb R^3$, а в качестве $U$ и $W$ -- две произвольные прямые в нем проходящие через ноль.
Тогда сумма $U$ и $W$ -- это плоскость натянутая на эти две прямые.

Сумма подпространств $U$ и $W$ обладает следующим свойством: это наименьшее подпространство, которое одновременно содержит и $U$ и $W$.
Потому про него надо думать, как про НОК векторных подпространств.

\begin{claim}
Пусть $V$ -- векторное пространство над полем $F$ и $U,W\subseteq V$ -- некоторые подпространства, тогда 
\[
\dim_F (U + W) = \dim_F U + \dim_F W - \dim_F (U\cap W)
\]
\end{claim}
\begin{proof}
Пусть $e=(e_1,\ldots,e_r)$ -- базис пересечения $U\cap W$.
Теперь вспомним, что это линейно независимое подмножество во всем $U$ и дополним его там до базиса $U$ с помощью векторов $f=(f_1,\ldots, f_p)$.
Аналогично, базис $U\cap W$ будет линейно независимым подмножеством в $W$, а значит его можно дополнить до базиса $W$ векторами $h=(h_1,\ldots,h_t)$.
Давайте покажем, что множество $e_1,\ldots,e_r, f_1,\ldots,f_p,h_1,\ldots,h_t$ является базисом подпространства $U + W$.
Тогда из этого и будет следовать необходимое утверждение.

Любой вектор из $U+W$ имеет вид $u+w$.
Тогда $u$ раскладывается по $e$ и $f$, а вектор $w$ раскладывается через $e$ и $h$.
А значит система $e\cup f\cup h$ порождает $U + W$.
Теперь надо показать, что она линейно независима.
Рассмотрим произвольную линейную комбинацию
\[
e x + fy + hz = 0, \text{ где }x\in F^r,\, y\in F^p,\, z\in F^t
\]
Тогда
\[
U \ni ex +fy = -hz \in W
\]
а значит лежит в пересечении $U\cap W$.
В частности $hz \in U\cap W$.
Но все что попадает в пересечение раскладывается по $e$.
Значит найдется какое-то $z'\in F^r$ такое, что $hz = ez'$.
Но это означает, что линейная комбинация $h\cup e$ равна нулю, так как они образовывали базис $W$, то $z =0$ и $z' = 0$.
А значит $-hz = 0$.
Что влечет $ex + fy = 0$.
Так как $e \cup f$ образовывали базис $U$, последнее означает, что $x = 0$ и $y = 0$.
То есть все коэффициенты линейной комбинации на $e\cup f\cup h$ равны нулю, что и требовалось.
\end{proof}

\paragraph{Бесконечные суммы и пересечения}

Если $V$ -- векторное пространство над полем $F$ и в нем дано семейство подпространств $U_\alpha \subseteq V$, где $\alpha\in X$, то можно определить пересечение и сумму этого семейства.
С пересечением все просто, это обычное теоретико-множественное пересечение $\bigcap_{\alpha} U_\alpha$ и как можно заметить, это подмножество является подпространством.
Сумма же определяется следующим образом
\[
\sum_{\alpha \in X} U_\alpha = \{u_{\alpha_1}+\ldots+u_{\alpha_k} \mid k\in\mathbb Z_{\geqslant 0},\; u_{\alpha_i}\in U_{\alpha_i}\}
\]
То есть мы берем все возможные конечные суммы элементов из пространств $U_\alpha$ и складываем в один мешок.
Как мы можем заметить, сумма таких выражений снова выражение такого вида и после умножения такого выражения на скаляр опять остается выражение такого вида.
Значит, только что определенное подмножество является подпространством.
В случае конечного числа слагаемых получаем следующее определение
\[
U_1 + \ldots + U_k = \{u_1 + \ldots + u_k \mid u_i\in U_i\}
\]

Определенные выше пересечение и сумма семейства $U_\alpha$ обладают следующим свойством:
\begin{enumerate}
\item Пересечение $\bigcap_{\alpha} U_\alpha$ является наибольшим подпространством, содержащимся во всех $U_\alpha$.
Здесь под наибольшим имеется в виду самое большое относительно порядка включения подпространств, то есть такое подпространство, что любое подпространство содержащееся во всех $U_\alpha$ в нем содержится.
В частности пересечение можно определить, как объединение (или сумму) всех подпространств лежащих во всех $U_\alpha$.

\item Сумма $\sum_\alpha U_\alpha$ является наименьшим подпространством, содержащим все $U_\alpha$.
Здесь под наименьшим имеется в виду самое маленькое относительно порядка включения подпространств, то есть такое подпространство, которое содержится в любом содержащем все $U_\alpha$.
В частности сумму можно определить как пересечение всех подпространств, содержащих все $U_\alpha$.

\item Кроме того, отметим, что $\sum_{\alpha} U_\alpha$ совпадает с линейной оболочкой $\langle \bigcup_\alpha U_\alpha \rangle$.
В частности для двух подпространств $U,W\subseteq V$ верно $U + W = \langle U, W\rangle = \langle U\cup W\rangle$.
Таким образом к сумме можно относиться как к более удобному синтаксису задания линейных оболочек.
\end{enumerate}
