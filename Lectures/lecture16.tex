\ProvidesFile{lecture14.tex}[Лекция 14]


\subsection{Прямые суммы}

Если $V$ -- векторное пространство над полем $F$ и $U_1,\ldots,U_k\subseteq V$ -- его подпространства такие, что $U_1 + \ldots + U_k = V$.
Тогда ясно, что можно не экономить на $U_i$ и, заменив каждое из них на большее подпространство, равенство сохранится.
Потому интересно в таких суммах выбирать $U_i$ как можно меньше и быть экономными.
Вопрос о том на сколько экономно и как можно и нужно выбирать $U_i$ в таких ситуациях, мы и обсудим в этом разделе.
Но в начале новая операция над пространствами.

\begin{definition}
\label{def::IndepSpaces}
Пусть $V$ -- векторное пространство и $U_1,\ldots,U_k\subseteq V$ -- его некоторые подпространства.
В этом случае $U_1,\ldots, U_k$ называются линейно независимыми, если для любых элементов $u_1\in U_1, \ldots, u_k\in U_k$ условие $u_1 + \ldots + u_k = 0$ влечет $u_i = 0$ для всех $i$.
\end{definition}

\begin{definition}
Если нам даны произвольные векторные пространства $V_1,\ldots, V_k$, то их декартово произведение $V_1\times\ldots\times V_k$ обладает структурой векторного пространства.
Действительно, его элементы -- это наборы векторов $(v_1,\ldots,v_k)$.
Тогда относительно поэлементных операций -- это будет векторное пространство, то есть
$(v_1,\ldots,v_k) + (u_1,\ldots,u_k) = (v_1 + u_1,\ldots,v_k + u_k)$ и $\lambda(v_1,\ldots,v_k) = (\lambda v_1, \ldots, \lambda v_k)$.
Пространство $V_1\times\ldots \times V_k$ называется внешней прямой суммой пространств $V_1,\ldots, V_k$.
\end{definition}

Предположим, что у нас есть некоторое векторное пространство $V$ и его подпространства $U_1,\ldots,U_k\subseteq V$.
Тогда можно определить отображение $U_1\times \ldots \times U_k \to V$ по правилу $(u_1,\ldots,u_k) \mapsto u_1 + \ldots + u_k$.
Заметим, что это отображение будет линейным и образом этого отображения будет сумма подпространств $U_1 + \ldots + U_k$.

\begin{claim}
\label{claim::DirectSum}
Пусть $V$ -- векторное пространство над полем $F$ и $U_1,\ldots,U_k \subseteq V$ -- его подпространства такие, что $V = U_1+\ldots + U_k$.
Тогда следующие условия эквивалентны
\begin{enumerate}
\item $U_1,\ldots,U_k$ -- линейно независимые подпространства.

\item Любой вектор $v\in V$ единственным образом представляется в виде суммы $v = u_1 + \ldots + u_k$, где $u_i \in U_i$.

\item Если $e_i$ -- базис $U_i$, то $\bigcup_{i=1}^k e_i$ -- базис $V$.

\item $\dim_F V = \sum_{i=1}^k \dim_F U_i$.

\item $U_i \cap (\sum_{j\neq i}U_j) = 0$ для любого $i$.

\item Отображение $U_1\times \ldots \times U_k\to V$ по правилу $(u_1,\ldots,u_k)\mapsto u_1 + \ldots + u_k$ является изоморфизмом.

\end{enumerate}
\end{claim}
\begin{proof}
(1)$\Leftrightarrow$(2).
($\Leftarrow$) Если любой вектор единственным образом представляется в виде суммы $u_i$, то в частности это верно для $0$, но он уже представляется в виде $0 = 0 + \ldots + 0$, а значит никаких других представлений у него нет.
($\Rightarrow$) Если $v = v_1 + \ldots + v_k$ и $v = u_1 + \ldots + u_k$, то, вычтя из одного другое, получим $0 = (v_1 - u_1) + \ldots + (v_k - u_k)$.
А значит $u_i = v_i$, что и требовалось.

(1)$\Leftrightarrow$(3).
($\Rightarrow$) Достаточно показать, что $\bigcup_i e_i$ является линейно независимым.
Пусть $\sum_i e_i x_i = 0$ -- некоторая линейная комбинация, где $x_i\in F^{\dim_F U_i}$.
Но тогда по (1) все $e_i x_i = 0$.
А так как $e_i$ линейно независимо, то $x_i = 0$, что и требовалось.
($\Leftarrow$) Пусть $u_1 + \ldots + u_k = 0$.
Разложим каждый из них по базису $u_i = e_i x_i$.
Тогда $\sum_i e_i x_i = 0$.
Так как объединение всех $e_i$ -- базис, то $x_i = 0$, то есть $u_i = e_i x_i = 0$, что и требовалось.

(3)$\Leftrightarrow$(4).
($\Rightarrow$) Выполнено по определению, так как размерность -- это количество векторов в любом базисе.
($\Leftarrow$) Если $e_i$ -- это базис $U_i$, то система $\bigcup_{i=1}^k e_i$ порождает $V$.
Чтобы проверить, что это базис, достаточно показать, что в ней $\dim_F V$ элементов.
Но так как эта система порождающая, то достаточно проверить, что в ней не больше $\dim_F V$ элементов.
Теперь прямое вычисление показывает, что
\[
|\bigcup_{i=1}^k e_i|\leqslant \sum_{i=1}^k |e_i| = \sum_{i=1}^k \dim_F U_i = \dim_F V
\]

(1)$\Leftrightarrow$(5).
($\Rightarrow$) Пусть $u\in U_i\cap (\sum_{j\neq i} U_j)$, тогда $u = u_i$ и $u = \sum_{j\neq i} u_j$, а значит $u_i = \sum_{j\neq i} u _j$.
Перенесем все в одну сторону, получим $\sum_{j\neq i} u _j - u_i = 0$.
А значит все $u_i = 0$ по (1).
А значит $u = u_i = 0$, что и требовалось.
($\Leftarrow$) Пусть $u_1 + \ldots + u_k = 0$ и какой-нибудь $u_i\neq 0$.
Тогда $u_i = - \sum_{j\neq i}u_j$.
Мы получили ненулевой вектор в пересечении $U_i \cap (\sum_{j\neq i}U_j)$, противоречие.

(2)$\Leftrightarrow$(6).
Это переформулировка одного и того же свойства.

\end{proof}

\begin{definition}
Пусть $V$ -- векторное пространство над полем $F$ и $U_1,\ldots,U_k \subseteq V$ -- его подпространства такие, что $V = U_1+\ldots + U_k$ обладающие одним из эквивалентных свойств из предыдущего утверждения.
Тогда сумма $V = U_1+\ldots + U_k$  называется прямой и обозначается $V = U_1\oplus\ldots\oplus U_k$.
Тогда говорят, что $V$ является внутренней прямой суммой подпространств $U_1,\ldots,U_k$.
\end{definition}

Прямая сумма -- это обычная сумма подпространств, только с условием, что эти подпространства удовлетворяют некоторому дополнительному свойству.
Кроме того, свойство (6) из предыдущего утверждения означает, что прямая сумма векторных подпространств совпадает с внешней прямой суммой этих же подпространств рассматриваемых как абстрактные векторные пространства.
Бонус от этого вот какой: с внешней прямой суммой работать очень просто, так как это наборы векторов, их легко складывать, умножать на числа и сравнивать друг с другом.
А так как внутренняя прямая сумма от этой не отличается (с точностью до изоморфизма), то изучать одно это все равно, что изучать другое.

\paragraph{Примеры}

\begin{enumerate}
\item Пусть $V$ -- векторное пространство с базисом $e_1,\ldots,e_n$.
Положим $U_i = \langle e_i \rangle$, тогда $V = U_1 \oplus \ldots \oplus U_n$.
То есть мы раскладываем все пространство в прямую сумму прямых натянутых на базисные векторы.

\item Условие (5) очень просто переформулируется в случае двух подпространств.
Пусть $U, W\subseteq V$, тогда $V = U \oplus W$ тогда и только тогда, когда $V = U + W$ и $U \cap W = 0$.

\item Давайте посмотрим на предыдущий пример в конкретном случае.
Пусть $V=\mathbb R^3$, $U$ -- некоторая плоскость проходящая через $0$, а $W$ -- прямая проходящая через $0$ и не содержащаяся в $U$.
Тогда пересечение прямой и плоскости есть ноль, а наименьшее подпространство, которое их содержит -- это все пространство $V$.
Значит $V = U \oplus W$.

\item Условие (5) сильнее условия $U_i \cap U_j = 0$.
Вот пример.
Пусть $V = \mathbb R^2$, $U_1 = \langle e_1\rangle$, $U_2 = \langle e_2\rangle$, $U_3 = \langle e_1 + e_2\rangle$.
То есть я беру две координатные прямые на плоскости и прямую под углом $45$ градусов через первый квадрант.
Тогда все попарные пересечения прямых есть ноль.
Но $U_i + U_j = V$ для любой пары прямых, потому условие (5) не выполнено.
\end{enumerate}

\newpage
\section{Линейные операторы}

В этом разделе я наконец-то вам начну рассказывать о самых важных объектах в линейной алгебре -- линейных операторах.

\subsection{Определение и базовые свойства}
\label{section::LinearOpDef}

\begin{definition}
Пусть $V$ -- векторное пространство над полем $F$, тогда линейным оператором на $V$ называется линейное отображение $\varphi \colon V\to V$.
\end{definition}

Так как линейный оператор -- это частный случай линейного отображения, то для него применимо все, о чем мы уже говорили в случае отображений.
Про линейный оператор надо думать как про деформацию пространства $V$.

\paragraph{Примеры}

\begin{enumerate}
\item $\Identity\colon V\to V$, $v\mapsto v$.
Тождественный линейный оператор, ничего не деформирует.

\item $0\colon V\to V$, $v \mapsto 0$.
Нулевой линейный оператор, который все отправляет в ноль.

\item $A\colon \mathbb R^3 \to \mathbb R^3$, $x\mapsto Ax$, где $A\in \Matrix{3}$ задана так
\[
A = 
\begin{pmatrix}
{1}&{0}&{0}\\
{0}&{\cos \alpha}&{-\sin \alpha}\\
{0}&{\sin \alpha}&{\cos \alpha}\\
\end{pmatrix}
\]
-- поворот на угол $\alpha$ вокруг оси $\langle e_1\rangle$.

\item Пусть $V = U\oplus W$, тогда зададим $\pi\colon V\to V$ по правилу $v = u + w \mapsto u$.
Так как разложение в прямой сумме однозначно, то это корректно задает линейный оператор, который называется проектором на $U$ вдоль $W$.
Обратите внимание, что $\ker \pi = W$ и $\Im \pi = U$.
При этом для любого $u\in \Im\pi$ верно $\pi u = u$.
\end{enumerate}

\begin{claim}
\label{claim::Projector}
Пусть $V$ -- векторное пространство над полем $F$ и $\pi\colon V\to V$ -- линейный оператор.
Тогда следующие свойства эквивалентны:
\begin{enumerate}
\item Существуют подпространства $U,W\subseteq V$ такие, что $V = U\oplus W$ и $\pi$ является проектором на $U$ вдоль $W$.

\item $\pi^2 = \pi$.
\end{enumerate}
\end{claim}
\begin{proof}
(1)$\Rightarrow$(2).
Рассмотрим произвольный $v\in V$, тогда $\pi^2(v) = \pi(\pi(v))$.
Но вектор $\pi(v)$ лежит в образе $\pi$, то есть в $U$.
Как я уже отмечал в замечании выше, на векторах из образа проектор $\pi$ действует тождественно, то есть $\pi(\pi(v)) = \pi(v)$, что и требовалось.

(2)$\Rightarrow$(1).
Пусть $\pi^2 = \pi$.
Для начала нам  надо откуда-то взять подпространства $U$ и $W$.
Замечание выше подсказывает, что надо положить $U = \Im \pi$ и $W = \ker \pi$.
Теперь надо показать две вещи: (1) $V$ раскладывается в прямую сумму $U$ и $W$, (2) действие $\pi$ совпадает с действием проектора на $U$ вдоль $W$.

Для (1) нам надо показать, что $U\cap W = 0$ и $U + W = V$.
Начнем с пересечения.
Пусть $v\in U\cap W$ -- произвольный вектор.
Тогда с одной стороны $v\in U = \Im \pi$, а значит $v = \pi(v')$ и $v'\in V$.
С другой стороны, $v\in W = \ker \pi$, а значит $\pi(v) = 0$.
Но тогда
\[
0 = \pi(v) = \pi(\pi(v')) = \pi^2(v') = \pi(v') = v
\]
Значит в пересечении лежит только нулевой вектор.

Теперь займемся суммой.
Мы должны показать, что любой вектор из $V$ представляется в виде суммы векторов из $U$ и $W$.
Пусть $v\in V$, рассмотрим следующее разложение
\[
v = \pi (v) + (\Identity - \pi) (v) = \pi(v) + (v - \pi(v))
\]
Первый вектор $\pi(v)$ по определению попадает в $\Im\pi = U$.
Проверим, что второй лежит в ядре:
\[
\pi((\Identity - \pi)(v)) = \pi(v - \pi(v)) = \pi(v) - \pi^2(v) = 0
\]
Значит $V = U + W$.

Теперь мы знаем, что $V = U\oplus W = \Im \pi \oplus \ker \pi$.
Давайте покажем, что $\pi$ действует как проектор.
Возьмем $v\in V$, тогда он представляется в виде $v = u + w$, где $u = \pi(v)$ и $w = v - \pi(v)$.
Применим $\pi$ к $v$ и видим, что получаем $u$.
По определению действие $\pi$ совпадает с действием проектора на $U$ вдоль $W$.
\end{proof}

\paragraph{Замечание}

\begin{itemize}
\item Таким образом, если мы хотим разложить какое-то пространство $V$ в прямую сумму подпространств, нам достаточно найти оператор на $V$, который в квадрате равен самому себе.

\item Обратите внимание, что $\Identity$ является по определению проектором на все пространство вдоль  нулевого подпространства, а $0$ является проектором на нулевое подпространство вдоль всего пространства.
Эти операторы дают тривиальное разложение пространства $V$ в прямую сумму $0 \oplus V$.
Эти случаи надо иметь в виду.
\end{itemize}

\subsection{Матрица линейного оператора}
\label{section::LinearOpMatrix}

Пусть в векторном пространстве $V$ задан  некоторый базис $e_1,\ldots, e_n$ и пусть $\varphi \colon V\to V$ -- линейный оператор.
Так как у оператора пространство из которого он бьет и то в которое он бьет совпадают, то мы фиксируем всего лишь один базис (пространство-то у нас одно).
Тогда по определению матрица линейного оператора $\varphi$ -- это такая матрица $A_\varphi\in \operatorname{M}_{n}(F)$, что выполнено $\varphi e = e A_\varphi$, где $e = (e_1,\ldots,e_n)$.

Пусть теперь у нас задан другой базис $e_1',\ldots,e_n'$ в пространстве $V$ с матрицей перехода $C\in \operatorname{M}_n(F)$, то есть $(e_1',\ldots,e_n') = (e_1,\ldots,e_n)C$.
Пусть так же $e' = (e_1',\ldots,e_n')$.
Тогда матрица $\varphi$ в базисе $e'$ пусть будет $A_\varphi'$, то есть $\varphi e' = e' A_\varphi'$.
В этом случае связь между матрицами следующая $A_\varphi' = C^{-1}A_\varphi C$.
То есть матрица $A_\varphi$ сопряжена матрице $A_\varphi'$.%
\footnote{Напомню, что квадратные матрицы $B$ и $D$ называются сопряженными, если найдется обратимая матрица $C$ такая, что $D= C^{-1}BC$.}

\paragraph{Замечания}

\begin{itemize}
\item Отметим, что матрица линейного оператора обязательно квадратная.
Таким образом, изучение линейного отображения -- это изучение прямоугольной матрицы, а изучение линейного оператора -- это всегда изучение только квадратной матрицы.

\item Если линейное отображение $\psi\colon V\to U$ бьет между двумя разными пространствами одинаковой размерности, то ему тоже соответствует квадратная матрица.
Но принципиальная разница с линейным оператором заключается в том, что для линейного отображения мы можем независимо менять базисы в $V$ и $U$, что соответствует замене $A_\psi' = C^{-1}A_\psi D$, а для линейного оператора, так как пространство одно и то же, базисы меняются одновременно, что соответствует $A_\varphi' = C^{-1}A_\varphi C$.

\item Так как линейные операторы -- это линейные отображения, то задавать их можно так же как и линейные отображения, например: либо с помощью образа базисных векторов, либо с помощью матрицы в фиксированном базисе.
\end{itemize}
